{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52247847-6c7f-4dbb-bd1b-eff25970e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"/work/frink/models/alpaca-13b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"/work/frink/models/alpaca-13b\", torch_dtype=torch.bfloat16, \n",
    "#     device_map = \"auto\")\n",
    "# model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b9fc75-20e7-4d3e-b847-b7649209ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = 'cuda'\n",
    "class AlpacaInference():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"/work/frink/models/alpaca-13b\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\"/work/frink/models/alpaca-13b\", torch_dtype=torch.bfloat16)\n",
    "        self.model.to(device)\n",
    "\n",
    "    \n",
    "    def get_response(self, prompt):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs.input_ids.to('cuda')\n",
    "        generate_ids = self.model.generate(input_ids, max_length=2000)\n",
    "        # generate_ids.to(device)\n",
    "        response = self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ff8735-9696-448d-b389-e5742331f14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Model</th>\n",
       "      <th>Summary</th>\n",
       "      <th>w/ Error</th>\n",
       "      <th>CorefE</th>\n",
       "      <th>CorefE_text</th>\n",
       "      <th>CircE</th>\n",
       "      <th>CircE_text</th>\n",
       "      <th>...</th>\n",
       "      <th>GramE_text</th>\n",
       "      <th>PredE</th>\n",
       "      <th>PredE_text</th>\n",
       "      <th>SubjObjE</th>\n",
       "      <th>SubjObjE_text</th>\n",
       "      <th>OtherE</th>\n",
       "      <th>OtherE_text</th>\n",
       "      <th>LinkE</th>\n",
       "      <th>LinkE_text</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>human_ref</td>\n",
       "      <td>Louisa will lend Thelma her red velvet dress.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     DocID                                           Dialogue  \\\n",
       "0           0  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "\n",
       "       Model                                        Summary  w/ Error  CorefE  \\\n",
       "0  human_ref  Louisa will lend Thelma her red velvet dress.         0     NaN   \n",
       "\n",
       "  CorefE_text  CircE CircE_text  ...  GramE_text PredE  PredE_text SubjObjE  \\\n",
       "0         NaN    NaN        NaN  ...         NaN   NaN         NaN      NaN   \n",
       "\n",
       "   SubjObjE_text OtherE  OtherE_text LinkE  LinkE_text   origin  \n",
       "0            NaN    0.0          NaN   NaN         NaN  FacEval  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ramprasad.sa/factual_evaluation_source_based/datasets/sota_annotations/dialogue_aggrefact.csv')\n",
    "df.head()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e8c7a0-2e17-49f4-9810-12bbce329526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13828456\n",
      "13828456\n",
      "13828456\n",
      "13828456\n",
      "13727579\n",
      "13727579\n",
      "13727579\n",
      "13727579\n",
      "13863223\n",
      "13863223\n",
      "13863223\n",
      "13863223\n",
      "13809978\n",
      "13809978\n",
      "13809978\n",
      "13809978\n",
      "13729525\n",
      "13729525\n",
      "13729525\n",
      "13729525\n",
      "13681886\n",
      "13681886\n",
      "13681886\n",
      "13681886\n",
      "13611442\n",
      "13611442\n",
      "13611442\n",
      "13611442\n",
      "13828797\n",
      "13828797\n",
      "13828797\n",
      "13828797\n",
      "13611370\n",
      "13611370\n",
      "13611370\n",
      "13611370\n",
      "13815679\n",
      "13815679\n",
      "13815679\n",
      "13815679\n",
      "13680611\n",
      "13680611\n",
      "13680611\n",
      "13680611\n",
      "13680757\n",
      "13680757\n",
      "13680757\n",
      "13680757\n",
      "13811786\n",
      "13811786\n",
      "13811786\n",
      "13811786\n",
      "13611426\n",
      "13611426\n",
      "13611426\n",
      "13611426\n",
      "13680874\n",
      "13680874\n",
      "13680874\n",
      "13680874\n",
      "13864408\n",
      "13864408\n",
      "13864408\n",
      "13864408\n",
      "13863131\n",
      "13863131\n",
      "13863131\n",
      "13863131\n",
      "13681870\n",
      "13681870\n",
      "13681870\n",
      "13681870\n",
      "13829083\n",
      "13829083\n",
      "13829083\n",
      "13829083\n",
      "13829773\n",
      "13829773\n",
      "13829773\n",
      "13829773\n",
      "13819472\n",
      "13819472\n",
      "13819472\n",
      "13819472\n"
     ]
    }
   ],
   "source": [
    "df_annotations = {'DocID': [], \n",
    "                  'Dialogue': [],\n",
    "                  'origin': [],\n",
    "                 }\n",
    "                  \n",
    "                  \n",
    "for idx, row in df.iterrows():\n",
    "    docid = row['DocID']\n",
    "    dialogue = row['Dialogue']\n",
    "    origin = row['origin']\n",
    "\n",
    "    if docid not in df_annotations['DocID']:\n",
    "        df_annotations['DocID'].append(docid)\n",
    "        df_annotations['Dialogue'].append(dialogue)\n",
    "        df_annotations['origin'].append(origin)\n",
    "    else:\n",
    "        if dialogue not in df_annotations['Dialogue']:\n",
    "            print(docid)\n",
    "df_annotations = pd.DataFrame(df_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e58a21-b401-46d7-8ec5-36cad7ed98e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b6857b-9ae5-4dc9-93fe-43e45d05127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def make_alpaca_summaries(df_annotations):\n",
    "    alpaca_model = AlpacaInference()\n",
    "    df_dict = {\n",
    "        'DocID': [],\n",
    "        'Dialogue': [],\n",
    "        'Model': [],\n",
    "        'Summary': [],\n",
    "        'origin': []\n",
    "        \n",
    "    }\n",
    "    for idx, row in tqdm(df_annotations.iterrows(), total=df_annotations.shape[0]):\n",
    "        docid = row['DocID']\n",
    "        dialogue = row['Dialogue']\n",
    "        origin = row['origin']\n",
    "        instr = 'Generate a summary of the dialogue snippet provided above'\n",
    "        prompt = f'{dialogue}\\n{instr}\\nSummary:'\n",
    "        response = alpaca_model.get_response(prompt)\n",
    "        summary = response.split('Summary:')[-1].strip()\n",
    "\n",
    "        df_dict['DocID'].append(docid)\n",
    "        df_dict['Dialogue'].append(dialogue)\n",
    "        df_dict['Model'].append('gpt4-32k-0613')\n",
    "        df_dict['Summary'].append(summary)\n",
    "        df_dict['origin'].append(origin)\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    # df.to_csv(out_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d67f0cb-cf6c-4924-841e-aac4304cb3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab76f77211914262baa1a4de6893a130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                                             | 64/325 [04:53<16:37,  3.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [24:34<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "df_alpaca_summaries= make_alpaca_summaries(df_annotations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebedde8a-93b3-4273-a1e2-cb9c1fec3bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sarah requested a PTO but was denied due to her low seniority. Boris offered her the first choice of dates the week after, and Sarah asked if she could amend her request for the following week. Boris agreed and thanked Sarah for being flexible.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpaca_summaries.iloc[[13]]['Summary'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b5571d-318b-47a7-92f5-b5f1cff2506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpaca_summaries.to_csv('/home/ramprasad.sa/factual_evaluation_source_based/annotations/round1_aggrefact/alpaca13b_summaries_short.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8e5667-1459-4a74-8ed1-c98a30ebab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derek: Judy, r you leaving for the weekend?\n",
      "Judy: Nah\n",
      "Derek: So can you feed my animals on Friday and Saturday?\n",
      "Judy: sure, no problem\n",
      "Derek: Thank you :) Maybe on Thursday I would give you my keys?\n",
      "Judy: Ok\n",
      "Derek: Thanks :) Later I will tell you the details :)\n",
      "Judy: surely\n",
      "Derek asked Judy if she was leaving for the weekend and if she could feed his animals on Friday and Saturday. Judy agreed to both and Derek thanked her, also mentioning that he would give her his keys on Thursday.\n",
      "Poppy: Yeah. I definitely prefer Lisbon\n",
      "Harry: Yeah me too, principally the night\n",
      "Poppy: To party?\n",
      "Harry: Yup\n",
      "Poppy: I don''t like parties. They make me tired\n",
      "Harry: Really?!\n",
      "Poppy: I don''t like crowd, drunk people\n",
      "Harry: Oh OK. It makes sense. That''s the worst part of it. What you like to do for having fun?\n",
      "Poppy: Travelling. Sightseeing\n",
      "Harry: For sure that''s on the top of my list too\n",
      "Poppy and Harry are talking about their favorite places to visit. Poppy prefers Lisbon, while Harry prefers the nightlife. Poppy doesn't like parties, while Harry enjoys them. Poppy likes to travel and sightsee, while Harry enjoys partying.\n",
      "Helen: Hey, Simo, are you there?\n",
      "Simon: Yep babe, what''s up?\n",
      "Helen: I was calling you before...\n",
      "Simon: Sorry I was on the phone, I didn''t hear you... Tell me.\n",
      "Helen: It''s a bit embarrassing... The toilet paper is finished, could you fetch me some tissues, please?\n",
      "Simon: Hahaha sure, no worries!\n",
      "Helen asked Simon to get her some tissues because the toilet paper was finished. Simon agreed to get them for her.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dict = {\n",
    "        'DocID': [],\n",
    "        'Dialogue': [],\n",
    "        'Model': [],\n",
    "        'Summary': [],\n",
    "        'origin': []\n",
    "        \n",
    "    }\n",
    "df_ann = pd.read_csv('/home/ramprasad.sa/factual_evaluation_source_based/annotations/round1_aggredial_llm_annotated/first_annotator/db_dump_latest.csv')\n",
    "seen_dialogues = []\n",
    "for idx, row in df_ann[:5].iterrows():\n",
    "    instr = 'Generate a summary of the dialogue snippet provided above'\n",
    "    dialogue = row['dialogue']\n",
    "    if dialogue not in seen_dialogues:\n",
    "        prompt = f'{dialogue}\\n{instr}\\nSummary:'\n",
    "        response = alpaca_model.get_response(prompt)\n",
    "        response = response.split('Summary:')[-1].strip()\n",
    "        print(dialogue)\n",
    "        print(response)\n",
    "        seen_dialogues.append(dialogue)\n",
    "\n",
    "        for column in row.keys():\n",
    "            if column not in df_dict:\n",
    "                df_dict[column] = []\n",
    "            if column not in ['summary', 'user_id:\n",
    "                df_dict[column].append(row[column])\n",
    "        df_dict['summary'].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1f6a12-ff7b-4b4c-95b4-2f19fcaeebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>docid</th>\n",
       "      <th>model</th>\n",
       "      <th>nonfactual_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b6273d21-9a0c-4033-8e2b-908d0a98c143</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13611370</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Derek asked Judy if she was leaving for the we...</td>\n",
       "      <td>Derek: Judy, r you leaving for the weekend?\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22a9198f-5a54-4d53-a630-552083d5b350</td>\n",
       "      <td>ann_ccry</td>\n",
       "      <td>13611426</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>both</td>\n",
       "      <td>principally the night</td>\n",
       "      <td>Intrinsic_Error</td>\n",
       "      <td>Poppy and Harry are talking about their favori...</td>\n",
       "      <td>Poppy: Yeah. I definitely prefer Lisbon\\r\\nHar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ef458bfe-4bef-430c-8d97-8efc30b21ded</td>\n",
       "      <td>ann_ccry</td>\n",
       "      <td>13611442</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Helen asked Simon to get her some tissues beca...</td>\n",
       "      <td>Helen: Hey, Simo, are you there?\\r\\nSimon: Yep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid   user_id     docid  \\\n",
       "0           0  b6273d21-9a0c-4033-8e2b-908d0a98c143   sanjana  13611370   \n",
       "1           2  22a9198f-5a54-4d53-a630-552083d5b350  ann_ccry  13611426   \n",
       "2           3  ef458bfe-4bef-430c-8d97-8efc30b21ded  ann_ccry  13611442   \n",
       "\n",
       "           model nonfactual_spans               evidence       error_type  \\\n",
       "0  gpt4-32k-0613              NaN                    NaN              NaN   \n",
       "1  gpt4-32k-0613             both  principally the night  Intrinsic_Error   \n",
       "2  gpt4-32k-0613              NaN                    NaN              NaN   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Derek asked Judy if she was leaving for the we...   \n",
       "1  Poppy and Harry are talking about their favori...   \n",
       "2  Helen asked Simon to get her some tissues beca...   \n",
       "\n",
       "                                            dialogue  \n",
       "0  Derek: Judy, r you leaving for the weekend?\\r\\...  \n",
       "1  Poppy: Yeah. I definitely prefer Lisbon\\r\\nHar...  \n",
       "2  Helen: Hey, Simo, are you there?\\r\\nSimon: Yep...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3e689c-0b23-43cd-9e7b-699361423f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>docid</th>\n",
       "      <th>model</th>\n",
       "      <th>nonfactual_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b6273d21-9a0c-4033-8e2b-908d0a98c143</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13611370</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Derek asks Judy if she can feed his animals on...</td>\n",
       "      <td>Derek: Judy, r you leaving for the weekend?\\r\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid  user_id     docid  \\\n",
       "0           0  b6273d21-9a0c-4033-8e2b-908d0a98c143  sanjana  13611370   \n",
       "\n",
       "           model nonfactual_spans evidence error_type  \\\n",
       "0  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Derek asks Judy if she can feed his animals on...   \n",
       "\n",
       "                                            dialogue  \n",
       "0  Derek: Judy, r you leaving for the weekend?\\r\\...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_gpt_gen = pd.read_csv('/home/ramprasad.sa/factual_evaluation_source_based/annotations/round1_aggrefact/gpt4_summaries_short.csv')\n",
    "\n",
    "df_ann = pd.read_csv('/home/ramprasad.sa/factual_evaluation_source_based/annotations/round1_aggredial_llm_annotated/first_annotator/db_dump_latest.csv')\n",
    "\n",
    "df_ann.head()[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ef59dde-d7b2-44bb-9990-4568e0021c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 325)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = {\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639a399-40c0-47d3-a21e-dffcfc33dcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ca6f3e-694a-4058-82ba-a66e55a49d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thelma: i dont have anything to wear\\nLouisa: your wardrobe is full of clothes\\nThelma: but i have to look wonderful\\nLouisa: ok i can bring you my red velvet dress\\nThelma: really? :O\\nThelma: it would be great!\\nLouisa: no problem ;)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = df['Dialogue'].values[0]\n",
    "dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f73e36-7ce8-487a-836e-c1fa2f1392a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef630734-f978-4996-9cc8-43dd04181970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "instr = 'Generate a summary of the dialogue snippet provided above'\n",
    "prompt = f'{dialogue}\\n{instr}\\nSummary:'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6946477b-a326-463b-a0c9-b35a8dc6ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   498,   295,   655, 29901,   474,  4555,   505,  3099,   304,\n",
       "         19531,    13, 20555,  8069, 29901,   596,   281,   538,   307,   915,\n",
       "           338,  2989,   310, 22095,    13,  1349,   295,   655, 29901,   541,\n",
       "           474,   505,   304,  1106, 20695,    13, 20555,  8069, 29901,  3431,\n",
       "           474,   508,  6963,   366,   590,  2654,  5343,  5990, 10714,    13,\n",
       "          1349,   295,   655, 29901,  2289, 29973,   584, 29949,    13,  1349,\n",
       "           295,   655, 29901,   372,   723,   367,  2107, 29991,    13, 20555,\n",
       "          8069, 29901,   694,  1108, 15718,    13,  5631,   403,   263, 15837,\n",
       "           310,   278,  7928,   434, 11534,  4944,  2038,    13, 26289, 29901]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89679a4e-82d7-46a9-9818-0bba1c650e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thelma: i dont have anything to wear\n",
      "Louisa: your wardrobe is full of clothes\n",
      "Thelma: but i have to look wonderful\n",
      "Louisa: ok i can bring you my red velvet dress\n",
      "Thelma: really? :O\n",
      "Thelma: it would be great!\n",
      "Louisa: no problem ;)\n",
      "Generate a summary of the dialogue snippet provided above\n",
      "Summary: Thelma is in a dilemma because she doesn't have anything to wear to the party, but Louisa offers to lend her a dress, which makes Thelma very happy.\n"
     ]
    }
   ],
   "source": [
    "generate_ids = model.generate(input_ids, max_length=1000)\n",
    "# generate_ids.to(device)\n",
    "response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853d7aef-de83-42b9-b985-3d2a48b80f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dd4b97d7e246efa72cdce2cc26adce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistral_model = MistralInference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede4ea31-57b0-45eb-b4ef-b7453fd04690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n",
      "Summarize the above:\n",
      "\n",
      "1. Greg is a father and he has a son.\n",
      "2. He has to\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/work/frink/models/llama_13b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/work/frink/models/llama_13b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2370e44-2ac6-4264-bda0-c8b35a8bda34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Factual Eval(Abridge)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
