{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470fdc07-406c-4e89-bf32-8d75cfd6491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d26503-7a77-4355-9aaa-1c8529d602c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f824bfa-5fe1-4d1e-857d-2eec42116cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_refmatters(filepath):\n",
    "    data = read_file(filepath)\n",
    "    error_type_map = {'PredE': 'PredE', \n",
    "                      'EntE': 'SubjObjE', \n",
    "                      'OutE': 'OutE', \n",
    "                      'CorefE': 'CorefE', \n",
    "                      'GramE' : 'GramE',\n",
    "                     'CircE': 'CircE',\n",
    "                     'LinkE': 'LinkE', \n",
    "                     'GramE': 'GramE', \n",
    "                     'OthE': 'OthE'}\n",
    "    \n",
    "    data_dict = {'DocID': [],\n",
    "                 'Dialogue': [],\n",
    "                 'Model': [],\n",
    "                 'Summary': [],\n",
    "                 'PredE': [],\n",
    "                 'PredE_text': [],\n",
    "                 'SubjObjE': [], \n",
    "                 'SubjObjE_text': [],\n",
    "                 'OutE': [], \n",
    "                 'OutE_text': [], \n",
    "                 'CorefE': [], \n",
    "                 'CorefE_text': [], \n",
    "                 'GramE' : [],\n",
    "                 'GramE_text' : [],\n",
    "                 'CircE': [],\n",
    "                 'CircE_text': [],\n",
    "                 'LinkE': [], \n",
    "                 'LinkE_text': [], \n",
    "                 'GramE': [], \n",
    "                 'GramE_text': [], \n",
    "                 'OthE': [],\n",
    "                'OthE_text': [],\n",
    "                'w/ Error': []}\n",
    "                 \n",
    "    \n",
    "    for doc in data:\n",
    "        DocID = doc['id']\n",
    "        Dialogue = doc['dialogue']\n",
    "        for model, model_summary_info in doc['model_summaries'].items():\n",
    "            \n",
    "            model_summary = model_summary_info['original_summary']\n",
    "            factual_label = model_summary_info['consistency']\n",
    "            factual_label = 1 if factual_label != True else 0\n",
    "            \n",
    "            append_error_info = {}\n",
    "            for k ,v in error_type_map.items():\n",
    "                append_error_info[v] = 'no'\n",
    "                append_error_info[f'{v}_text'] = None\n",
    "                \n",
    "            for errors in model_summary_info['error_categories']:\n",
    "                error_text = errors['text']\n",
    "                error_type = error_type_map[errors['type']]\n",
    "                append_error_info[error_type] = 'yes'\n",
    "                append_error_info[f'{error_type}_text']= error_text\n",
    "    \n",
    "            data_dict['DocID'].append(DocID)\n",
    "            data_dict['Dialogue'].append(Dialogue)\n",
    "            data_dict['Model'].append(model)\n",
    "            data_dict['Summary'].append(model_summary)\n",
    "            data_dict['w/ Error'].append(factual_label)\n",
    "    \n",
    "            for err, errval in append_error_info.items():\n",
    "                data_dict[err].append(errval)\n",
    "    return pd.DataFrame(data_dict)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9875ea9-7135-4994-8e9b-e69fa539c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/sanjana/factual_evaluation_source_based/dataset_creators/notebooks/reference_matters/SAMSum/train.json'\n",
    "df = make_df_refmatters(filepath)\n",
    "df.to_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/RefMatters_SAMSum_train.csv')\n",
    "\n",
    "filepath = '/home/sanjana/factual_evaluation_source_based/dataset_creators/notebooks/reference_matters/DialogSum/train.json'\n",
    "df = make_df_refmatters(filepath)\n",
    "df.to_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/RefMatters_DialogSum_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c0e53b7-a18e-4ea7-b87e-412149612f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187ed49-8255-4efe-bbb3-1ac750477abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
