{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b13b6e-4052-4725-bcd2-8710341884fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f974ec8-a2f9-45e7-988b-1843f58fd150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96ddd16-f21e-4ea1-99d2-b6be0472d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Model</th>\n",
       "      <th>Summary</th>\n",
       "      <th>w/ Error</th>\n",
       "      <th>CorefE</th>\n",
       "      <th>CorefE_text</th>\n",
       "      <th>CircE</th>\n",
       "      <th>CircE_text</th>\n",
       "      <th>...</th>\n",
       "      <th>GramE</th>\n",
       "      <th>GramE_text</th>\n",
       "      <th>PredE</th>\n",
       "      <th>PredE_text</th>\n",
       "      <th>SubjObjE</th>\n",
       "      <th>SubjObjE_text</th>\n",
       "      <th>OtherE</th>\n",
       "      <th>OtherE_text</th>\n",
       "      <th>LinkE</th>\n",
       "      <th>LinkE_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>human_ref</td>\n",
       "      <td>Louisa will lend Thelma her red velvet dress.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>bart_large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>mv-bart_large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>co-ref bart large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>condigsum bart large</td>\n",
       "      <td>Louisa will bring Thelma her red velvet dress.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     DocID                                           Dialogue  \\\n",
       "0           0  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "1           1  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "2           2  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "3           3  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "4           4  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "\n",
       "                  Model                                            Summary  \\\n",
       "0             human_ref      Louisa will lend Thelma her red velvet dress.   \n",
       "1            bart_large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "2         mv-bart_large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "3     co-ref bart large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "4  condigsum bart large     Louisa will bring Thelma her red velvet dress.   \n",
       "\n",
       "   w/ Error  CorefE CorefE_text  CircE CircE_text  ...  GramE GramE_text  \\\n",
       "0         0     NaN         NaN    NaN        NaN  ...    NaN        NaN   \n",
       "1         0     NaN         NaN    NaN        NaN  ...    NaN        NaN   \n",
       "2         0     NaN         NaN    NaN        NaN  ...    NaN        NaN   \n",
       "3         0     NaN         NaN    NaN        NaN  ...    NaN        NaN   \n",
       "4         0     NaN         NaN    NaN        NaN  ...    NaN        NaN   \n",
       "\n",
       "   PredE PredE_text  SubjObjE SubjObjE_text  OtherE OtherE_text  LinkE  \\\n",
       "0    NaN        NaN       NaN           NaN     0.0         NaN    NaN   \n",
       "1    NaN        NaN       NaN           NaN     0.0         NaN    NaN   \n",
       "2    NaN        NaN       NaN           NaN     0.0         NaN    NaN   \n",
       "3    NaN        NaN       NaN           NaN     0.0         NaN    NaN   \n",
       "4    NaN        NaN       NaN           NaN     0.0         NaN    NaN   \n",
       "\n",
       "   LinkE_text  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sanjana/explainable_factual_evaluation/datasets/fact_annotated/old_model_annotated/dialogue_aggrefact.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f233f3ba-c9e9-44e0-b0dc-bf8832e0d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_facts_gpt(gpt_model_atomic, model, text, text_type):\n",
    "    instr = f'Segment the following {text_type} into important facts'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt, model = model)\n",
    "    return gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9af5f9e-0103-4e4f-9cc4-da8b0743b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 06:54:00.902848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 06:54:02.076583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def mask_all_errtypes(text):\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "            # print(idx, origin_tokens)\n",
    "            # masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            # masked_text = ' '.join(masked_text)\n",
    "            # print(masked_text)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            \n",
    "        elif 'VERB' == token.pos_:\n",
    "            append = True \n",
    "            token_type = 'predicate'\n",
    "\n",
    "        elif 'ADV' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'ADP' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'PRON' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'coreference'\n",
    "\n",
    "        \n",
    "\n",
    "        if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "    # print([])\n",
    "    print(mask_tokens)  \n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f447a1-fd41-485f-8bde-6633addbcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_subjobj_answer(gpt_model_corruptor, dlg, text, answer):\n",
    "#     instruction = \"List other subject or object entities from the dialogue that can be used to fill in the <BLANK> in the summary\"\n",
    "#     # instruction = \"List subject or object entities that can be used to fill in the <BLANK>\"\n",
    "#     prompt_template = f'Dialogue: {dlg}\\nSummary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "#     # print(prompt_template)\n",
    "#     # print('--')\n",
    "#     # prompt_template = f'Summary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "#     answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "#     return answer\n",
    "\n",
    "def get_predicate_answer(gpt_model_corruptor, dlg, atomic_facts, summary, answer):\n",
    "    instruction_verb = f'What alternative words or phrases to \"{answer}\" can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "    instruction_tense = f'What different tenses of verbs or phrases of the word {answer} that can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "    instruction_negation = f\"What words or phrases that negate {answer} and can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.\"\n",
    "    answer_all = []\n",
    "    \n",
    "    prompt_template_verb = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction}\\nAnswer:'\n",
    "    answer_verb = gpt_model_corruptor.get_chatgpt_response(prompt_template_verb)\n",
    "    print('ANSWER VERB', answer_verb)\n",
    "    if ',' in answer_verb:\n",
    "        answer_all += answer_verb.split(',')\n",
    "    \n",
    "    prompt_template_tense  = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction}\\nAnswer:'\n",
    "    answer_tense = gpt_model_corruptor.get_chatgpt_response(prompt_template_tense)\n",
    "    print('ANSWER TENSE', answer_tense)\n",
    "    if ',' in answer_tense:\n",
    "        answer_all += answer_tense.split(',')\n",
    "    \n",
    "    prompt_template_negation = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction}\\nAnswer:'\n",
    "    answer_negation = gpt_model_corruptor.get_chatgpt_response(prompt_template_negation)\n",
    "    print('ANSWER NEGATION', answer_negation)\n",
    "    if ',' in answer_tense:\n",
    "        answer_all += answer_negation.split(',')\n",
    "        \n",
    "    answer_all = ','.join(answer_all)\n",
    "    return answer_all\n",
    "\n",
    "def get_generic_answer(gpt_model_corruptor, dlg, atomic_facts, summary, answer):\n",
    "    instruction = f'What alternative words or phrases to \"{answer}\" can be used to fill in the <BLANK> of the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "    prompt_template = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction}\\nAnswer:'\n",
    "    answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "    return answer\n",
    "    \n",
    "def check_sentence_validity(gpt_model_sentence_checker, text):\n",
    "    instruction = \"Correct the sentence for any grammatical errors without replacing any existing words\"\n",
    "    prompt_template = f'{instruction}\\nSummary: {text}\\nCorrected Summary:'\n",
    "    answer = gpt_model_sentence_checker.get_chatgpt_response(prompt_template)\n",
    "    return answer\n",
    "\n",
    "def check_entailment(gpt_model_nli, dlg, facts, text):\n",
    "    instruction = \"Does the dialogue or facts entail the sentence?\"\n",
    "    prompt_template = f'{instruction}\\nDialogue: {dlg}\\nFacts: {atomic_facts}\\nSentence: {text}\\nAnswer(yes or no):'\n",
    "    answer = gpt_model_nli.get_chatgpt_response(prompt_template)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0169ae-2f23-48d4-a7e5-f15ffd741518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2826b67-d663-4845-997f-bcb654cf5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_all_subjobj(\n",
    "gpt_model_corruptor = GPTInference()\n",
    "gpt_model_sentence_checker = GPTInference()\n",
    "gpt_model_atomic = GPTInference()\n",
    "gpt_model_nli = GPTInference()\n",
    "text = df['Summary'].values[10]\n",
    "dlg = df['Dialogue'].values[10]\n",
    "# subjobj_blanks = mask_all_subjobj(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b52f1dc2-4251-4d2a-8de9-4ddd2f512558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction_intrinsic = \"Generate a summary that misinterprets the conversation snippet\"\n",
    "# # instruction_intrinsic = \"Generate a summary of the conversation snippet below and take any creative liberties\"\n",
    "# # instruction = \"Formulate a summary and use creative liberties to make up extra information that is not found in the dialogue snippet.\"\n",
    "# # instruction = \"An inconsistent summary contains information not supported by the dialogue snippet. Generate an inconsistent summary of the dialogue snippet.\"\n",
    "# prompt = f'{instruction}\\n{dlg}'\n",
    "# print(prompt)\n",
    "# GPTInference().get_chatgpt_response(prompt)\n",
    "# ### Check if inconsistent summaries just negates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755b76e1-8303-4333-b3d5-ca71c8abed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment the following dialogue into important facts\n",
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "texts = get_atomic_facts_gpt(gpt_model_atomic, 'gpt-4-32k-0613', dlg, 'dialogue')\n",
    "texts = texts.split('\\n')\n",
    "texts = [re.sub('[1-9]', '', each) for each in texts]\n",
    "texts = [each.strip(string.punctuation).strip() for each in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7316041e-515b-4b9f-9f6e-d05aeddcf382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Greg has to stay at work after hours',\n",
       " 'Greg asks Betsy if she can pick up Johnny',\n",
       " 'Betsy initially questions her ability to pick up Johnny',\n",
       " 'It is revealed that Betsy also has to work long hours',\n",
       " \"Tuesdays are typically Greg's days to look after Johnny at kindergarten\",\n",
       " 'Greg promises Betsy that he will try to figure out a solution',\n",
       " 'Betsy insists that Greg come up with a plan for Johnny']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc665f68-cb2f-4f13-a5d5-22d2b6812578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment the following dialogue into important facts\n",
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greg needs to stay after hours',\n",
       " 'Betsy is annoyed that Greg needs to stay after hours again',\n",
       " 'Greg apologizes',\n",
       " 'Greg asks Betsy to pick up Johnny',\n",
       " 'Betsy questions if she can pick up Johnny',\n",
       " \"Betsy says she can't pick up Johnny because she also needs to work long hours\",\n",
       " 'Betsy reminds Greg that Tuesdays are his days in the kindergarten',\n",
       " 'Greg says he will see what he can do',\n",
       " 'Betsy tells Greg to think of something',\n",
       " '0. Greg tells Betsy to stop']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo-16k-0613\"\n",
    "texts = get_atomic_facts_gpt(gpt_model_atomic, model, dlg, 'dialogue')\n",
    "texts = texts.split('\\n')\n",
    "texts = [re.sub('[1-9]', '', each) for each in texts]\n",
    "texts = [each.strip(string.punctuation).strip() for each in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "599cee8e-dc38-4f2c-bc88-439d0b3547e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment the following dialogue into important facts\n",
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greg needs to stay after hours at work',\n",
       " 'Betsy is unable to pick up Johnny due to her own long work hours',\n",
       " \"Tuesdays are usually Greg's days to handle kindergarten responsibilities\",\n",
       " 'Greg plans to find a solution for picking up Johnny']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gpt-4-32k-0314\"\n",
    "texts = get_atomic_facts_gpt(gpt_model_atomic, model, dlg, 'dialogue')\n",
    "texts = texts.split('\\n')\n",
    "texts = [re.sub('[1-9]', '', each) for each in texts]\n",
    "texts = [each.strip(string.punctuation).strip() for each in texts]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c1d2952-af65-4fd8-93e3-7e1f81e38691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Greg', 'subjobj'), (1, 'needs', 'predicate'), (3, 'stay', 'predicate'), (4, 'after', 'circumstance'), (5, 'hours', 'subjobj'), (6, 'at', 'circumstance'), (7, 'work', 'subjobj')]\n"
     ]
    }
   ],
   "source": [
    "masked_summaries = mask_all_errtypes(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a7c78d0-5f03-472d-8dfc-d43557607ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BLANK> needs to stay after hours at work', 'Greg', 'subjobj'),\n",
       " ('Greg needs to stay after <BLANK> at work', 'hours', 'subjobj'),\n",
       " ('Greg needs to stay after hours at <BLANK>', 'work', 'subjobj'),\n",
       " ('Greg <BLANK> to stay after hours at work', 'needs', 'predicate'),\n",
       " ('Greg needs to <BLANK> after hours at work', 'stay', 'predicate'),\n",
       " ('Greg needs to stay <BLANK> hours at work', 'after', 'circumstance'),\n",
       " ('Greg needs to stay after hours <BLANK> work', 'at', 'circumstance')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9954961a-5943-47f4-b768-a432f3bae11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n",
      "Facts: Greg needs to stay after hours at work\n",
      "Betsy is also working long hours\n",
      "It's Greg's turn to pick up Johnny from kindergarten on Tuesdays\n",
      "Both Greg and Betsy are unable to pick up Johnny\n",
      "Greg will try to find a solution\n",
      "Summary: Greg needs to stay <BLANK> hours at work\n",
      "What alternative words or phrases to \"after\" can be used to fill in the <BLANK> of the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'before, regular, fewer, short'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = masked_summaries[5][0]\n",
    "answer = masked_summaries[5][1]\n",
    "instruction = f'What alternative words or phrases to \"{answer}\" can be used to fill in the <BLANK> of the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "source = '\\n'.join(texts)\n",
    "prompt_template = f'Dialogue: {dlg}\\nFacts: {source}\\nSummary: {text}\\n{instruction}\\nAnswer:'\n",
    "print(prompt_template)\n",
    "answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ca701ac-0c95-4d19-b51b-1ef81a8acde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "AUX\n",
      "VERB\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "PUNCT\n",
      "PRON\n",
      "AUX\n",
      "VERB\n",
      "ADV\n",
      "ADP\n",
      "PRON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Lucas is waiting at the train station. He will be there by himself')\n",
    "for idx, token in enumerate(doc):\n",
    "        # append = False\n",
    "        print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4a8c393-5084-4de3-a74e-c2f52782d0f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'ent_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnd now for something completely different after dinner she said she can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# append = False\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ment_\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'ent_'"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# doc = nlp(\"And now for something completely different after dinner she said she can't\")\n",
    "# for idx, token in enumerate(doc):\n",
    "#         # append = False\n",
    "#         print(token.ent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1fc1a96-658b-4dcb-87ed-690382660911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas 0 5 GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Lucas is waiting at the train station\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1fcad2f-b158-42a7-8c46-571e7e7ad5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Betsy', 'subjobj'), (1, 'also', 'circumstance'), (2, 'needs', 'predicate'), (4, 'work', 'predicate'), (6, 'hours', 'subjobj'), (7, 'on', 'circumstance'), (10, 'day', 'subjobj')]\n"
     ]
    }
   ],
   "source": [
    "subjobj_blanks = mask_all_errtypes(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3eb9324d-45a9-40ff-998f-860fef041a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BLANK> also needs to work long hours on the same day', 'Betsy', 'subjobj'),\n",
       " ('Betsy also needs to work long <BLANK> on the same day', 'hours', 'subjobj'),\n",
       " ('Betsy also needs to work long hours on the same <BLANK>', 'day', 'subjobj'),\n",
       " ('Betsy <BLANK> needs to work long hours on the same day',\n",
       "  'also',\n",
       "  'circumstance'),\n",
       " ('Betsy also needs to work long hours <BLANK> the same day',\n",
       "  'on',\n",
       "  'circumstance'),\n",
       " ('Betsy also <BLANK> to work long hours on the same day',\n",
       "  'needs',\n",
       "  'predicate'),\n",
       " ('Betsy also needs to <BLANK> long hours on the same day',\n",
       "  'work',\n",
       "  'predicate')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjobj_blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b45ca32-79ab-4962-926f-dd2c59058d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sanjana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def make_corrupted_summary(text_blanks, facts):\n",
    "    corrupted_err_type = {}\n",
    "    for blanked_text, answer, err_type in text_blanks:\n",
    "        if err_type == 'subjobj':\n",
    "            corrupted_answer = get_generic_answer(gpt_model_corruptor, dlg, facts, blanked_text, answer)\n",
    "            # print(blanked_text, err_type)\n",
    "            # print(answer)\n",
    "            # print(corrupted_answer)\n",
    "            # print('====')\n",
    "        if err_type == 'predicate':\n",
    "            corrupted_answer = get_verb_answer(gpt_model_corruptor, dlg, facts, blanked_text, answer)\n",
    "            print(blanked_text, err_type)\n",
    "            print(answer)\n",
    "            print(corrupted_answer)\n",
    "            print('====')\n",
    "        else:\n",
    "            \n",
    "    \n",
    "        \n",
    "        options = corrupted_answer.split(',')\n",
    "        # print(options)\n",
    "        corrupted_facts = []\n",
    "        for option in options:\n",
    "            corrupted_summary = blanked_text.replace('<BLANK>', option.strip())\n",
    "            corrected_summary = check_sentence_validity(gpt_model_sentence_checker, corrupted_summary)\n",
    "            \n",
    "            corrected_summary = [each.strip(string.punctuation) for each in corrected_summary.split(' ')]\n",
    "            corrupted_summary = [each.strip(string.punctuation) for each in corrupted_summary.split(' ')]\n",
    "            \n",
    "            word_constraints = [each for each in blanked_text.split(' ') if each != '<BLANK>' and each not in stop_words]\n",
    "            constrain_overlap = set(word_constraints) - set(corrected_summary)\n",
    "            replaced_word = ' '.join([each for each in corrected_summary if each not in blanked_text.split(' ')])\n",
    "    \n",
    "            corrected_summary = ' '.join(corrected_summary)\n",
    "            corrupted_summary = ' '.join(corrupted_summary)\n",
    "        \n",
    "            if not constrain_overlap and replaced_word: \n",
    "                entailment = check_entailment(gpt_model_nli, dlg, facts, corrected_summary)\n",
    "                # print(blanked_text)\n",
    "                # print(corrected_summary, entailment)\n",
    "                # print(replaced_word)\n",
    "                # print('----')\n",
    "                if entailment == 'no':\n",
    "                    if err_type not in corrupted_err_type:\n",
    "                        corrupted_err_type[err_type] = []\n",
    "                    corrupted_err_type[err_type] += [(corrected_summary, replaced_word)]\n",
    "    return corrupted_err_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa74f30b-43b9-40dc-97cd-541e1acffa9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Greg', 'subjobj'), (1, 'needs', 'predicate'), (3, 'stay', 'predicate'), (4, 'after', 'circumstance'), (5, 'hours', 'subjobj'), (6, 'at', 'circumstance'), (7, 'work', 'subjobj')]\n",
      "ANSWER VERB has, wants, is required, is forced\n",
      "ANSWER TENSE needed, will need, might need, has needed, requiring\n",
      "ANSWER NEGATION doesn't need, refuses, declines, avoids, has no need, is not required, denies needing, is unwilling\n",
      "Greg <BLANK> to stay after hours at work predicate\n",
      "needs\n",
      "has, wants, is required, is forced,needed, will need, might need, has needed, requiring,doesn't need, refuses, declines, avoids, has no need, is not required, denies needing, is unwilling\n",
      "====\n",
      "ANSWER VERB work, remain, stick around, linger, spend time\n",
      "ANSWER TENSE stayed, staying, will stay, was staying, has stayed, had stayed, will have stayed, would stay, would have stayed, is staying, might stay, may stay\n",
      "ANSWER NEGATION leave, depart, go away, avoid staying, exit, vacate, delay\n",
      "Greg needs to <BLANK> after hours at work predicate\n",
      "stay\n",
      "work, remain, stick around, linger, spend time,stayed, staying, will stay, was staying, has stayed, had stayed, will have stayed, would stay, would have stayed, is staying, might stay, may stay,leave, depart, go away, avoid staying, exit, vacate, delay\n",
      "====\n",
      "[(0, 'Betsy', 'subjobj'), (1, 'also', 'circumstance'), (2, 'needs', 'predicate'), (4, 'work', 'predicate'), (6, 'hours', 'subjobj'), (7, 'on', 'circumstance'), (10, 'day', 'subjobj')]\n",
      "ANSWER VERB has, wants, ought, desires, wishes\n",
      "ANSWER TENSE wanted, will need, needed, would need, must, should have\n",
      "ANSWER NEGATION doesn't need, isn't required, has no need, can avoid, doesn't have to, isn't obliged\n",
      "Betsy also <BLANK> to work long hours on the same day predicate\n",
      "needs\n",
      "has, wants, ought, desires, wishes,wanted, will need, needed, would need, must, should have,doesn't need, isn't required, has no need, can avoid, doesn't have to, isn't obliged\n",
      "====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atomic_fact_map = {}\n",
    "facts = '\\n'.join(texts)\n",
    "for atomic_fact in texts:\n",
    "    atomic_fact_blanks = mask_all_errtypes(atomic_fact)\n",
    "    atomic_fact_corrupted = make_corrupted_summary(atomic_fact_blanks, facts)\n",
    "    atomic_fact_map[atomic_fact] = atomic_fact_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "68cfea9b-5421-4236-baef-4a3d4e5241c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Greg needs to stay after hours at work': {'subjobj': [('Johnny needs to stay after hours at work',\n",
       "    'Johnny'),\n",
       "   ('Greg needs to stay after Johnny at work', 'Johnny'),\n",
       "   ('Greg needs to stay after Betsy at work', 'Betsy')],\n",
       "  'verb': [('Greg prefers to stay after hours at work', 'prefers'),\n",
       "   ('Greg volunteers to stay after hours at work', 'volunteers'),\n",
       "   (\"Greg doesn't need to stay after hours at work\", \"doesn't need\"),\n",
       "   ('Greg has no need to stay after hours at work', 'has no need'),\n",
       "   (\"Greg isn't required to stay after hours at work\", \"isn't required\"),\n",
       "   ('Greg refuses to stay after hours at work', 'refuses'),\n",
       "   (\"Greg can't stay after hours at work\", \"can't\"),\n",
       "   (\"Greg won't stay after hours at work\", \"won't\"),\n",
       "   (\"Greg shouldn't stay after hours at work\", \"shouldn't\"),\n",
       "   ('Greg declines to stay after hours at work', 'declines'),\n",
       "   ('Greg escapes to stay after hours at work', 'escapes'),\n",
       "   (\"Greg won't have to stay after hours at work\", \"won't have\"),\n",
       "   ('Greg needs to leave early after hours at work', 'leave early'),\n",
       "   ('Greg needs to avoid staying after hours at work', 'avoid staying'),\n",
       "   ('Greg needs to skip staying after hours at work', 'skip staying'),\n",
       "   ('Greg needs to refuse staying after hours at work', 'refuse staying'),\n",
       "   ('Greg needs to quit work early after hours', 'quit early'),\n",
       "   ('Greg needs to vacate after hours at work', 'vacate')]},\n",
       " 'Betsy is also working long hours that day': {'subjobj': [('Johnny is also working long hours that day',\n",
       "    'Johnny'),\n",
       "   ('Kindergarten is also working long hours that day', 'Kindergarten'),\n",
       "   ('Betsy is also working long with Greg that day', 'with Greg'),\n",
       "   ('Betsy is also working with Johnny long that day', 'with Johnny'),\n",
       "   ('Betsy is also working a long day at kindergarten that day',\n",
       "    'a at kindergarten')],\n",
       "  'verb': [('Betsy had also worked long hours that day', 'had worked'),\n",
       "   ('Betsy is also avoiding working long hours that day', 'avoiding working'),\n",
       "   ('Betsy is also taking a long break that day from hours of work',\n",
       "    'taking a break from of work'),\n",
       "   ('Betsy is also relaxing for long hours that day', 'relaxing for'),\n",
       "   ('Betsy is also on vacation with long hours that day', 'on vacation with'),\n",
       "   ('Betsy is also resting for long hours that day', 'resting for'),\n",
       "   ('Betsy is also skipping work for long hours that day',\n",
       "    'skipping work for')]},\n",
       " \"It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays\": {},\n",
       " 'Both Greg and Betsy are unable to pick up Johnny that day': {'verb': [('Both Greg and Betsy are unable to stay after hours with Johnny that day',\n",
       "    'stay after hours with'),\n",
       "   ('Both Greg and Betsy are unable to work long hours with Johnny that day',\n",
       "    'work long hours with'),\n",
       "   ('Both Greg and Betsy are unable to bypass Johnny that day', 'bypass')]},\n",
       " 'Greg will try to find a solution for picking up Johnny': {'subjobj': [('Betsy will try to find a solution for picking Johnny up',\n",
       "    'Betsy')],\n",
       "  'verb': [('Greg has tried to find a solution for picking up Johnny',\n",
       "    'has tried'),\n",
       "   ('Greg will refuse to find a solution for picking up Johnny', 'refuse'),\n",
       "   ('Greg will neglect to find a solution for picking up Johnny', 'neglect'),\n",
       "   ('Greg will bypass obstacles to find a solution for picking up Johnny',\n",
       "    'bypass obstacles'),\n",
       "   ('Greg will fail to find a solution for picking up Johnny', 'fail'),\n",
       "   ('Greg will try to ignore a solution for picking up Johnny', 'ignore'),\n",
       "   ('Greg will try to dismiss a solution for picking up Johnny', 'dismiss'),\n",
       "   ('Greg will try to disregard a solution for picking up Johnny',\n",
       "    'disregard'),\n",
       "   ('Greg will try to find a solution for cheering up Johnny', 'cheering'),\n",
       "   ('Greg will try to find a solution to stop Johnny', 'stop')]}}"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_fact_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "e0efe767-7215-47e2-867a-14be4dd42c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def get_single_err_samples(num_single_err_samples):\n",
    "# num_single_err_samples = 4\n",
    "    all_summary_sents = list(atomic_fact_map.keys())\n",
    "    \n",
    "    picked_sent_idx = sample([idx for idx in range(0, len(all_summary_sents))], num_single_err_samples)\n",
    "    \n",
    "    # corrupted_pick_sent_span = []\n",
    "    corrupted_summ_sent_spans = []\n",
    "    for pidx in picked_sent_idx:\n",
    "        picked_sent = all_summary_sents[pidx]\n",
    "        # summary = all_summary_sents[:pidx] + []\n",
    "        for k , v in atomic_fact_map[picked_sent].items():\n",
    "            # print(atomic_fact_map[picked_sent])\n",
    "            corrupted_pick_sent_span = sample(v, 1)[0]\n",
    "            print(pidx, \n",
    "            corrupted_summary = all_summary_sents[:pidx] + [corrupted_pick_sent_span[0]] + all_summary_sents[pidx:]\n",
    "            corrupted_summ_sent_spans.append(('. '.join(corrupted_summary), \n",
    "                                              [(corrupted_pick_sent_span[0], \n",
    "                                              corrupted_pick_sent_span[1])]))\n",
    "    return corrupted_summ_sent_spans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "3c054cae-b8e3-4bf1-8793-e4e92f3cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_summ_sent_spans = get_single_err_samples(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "5813a15b-6c31-45a8-8b0f-57c431fbcd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Both Greg and Betsy are unable to work long hours with Johnny that day',\n",
       "  'work long hours with')]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_summ_sent_spans[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "6ef27284-3e40-4636-b478-bbcbd1d92705",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_examples = []\n",
    "for summ_spans in corrupted_summ_sent_spans:\n",
    "    list_errors = '\\n\\n'.join([f'({each[0]} , {each[1]})' for each in summ_spans[1]])\n",
    "    ic_ex = f'Summary: {summ_spans[0]}\\nInconsistent sentence/spans:{list_errors}'\n",
    "    # print(ic_ex)\n",
    "    ic_examples += [ic_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "fc2e706e-a0e7-4820-bc42-ed61d1bb8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_instruction = 'Decide whether the summary is consistent with the dialogue. Note consistency means all the information in the summary can be found or inferred from the dialogue. A consistent summary does not contain contradictory or new information. List the inconsistent sentence and spans'\n",
    "ic_examples = '\\n\\n'.join(ic_examples)\n",
    "\n",
    "prompt_template = f'{inconsistent_instruction}\\nDialogue: {dlg}\\n\\n{ic_examples}\\n\\nSummary:{text}\\nInconsistent sentence/spans:'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "c932af15-ec32-49f2-bfb2-092f3fb742b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decide whether the summary is consistent with the dialogue. Note consistency means all the information in the summary can be found or inferred from the dialogue. A consistent summary does not contain contradictory or new information. List the inconsistent sentence and spans\n",
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n",
      "\n",
      "Summary: Greg needs to stay after hours at work. Betsy is also working long hours that day. It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays. Both Greg and Betsy are unable to work long hours with Johnny that day. Both Greg and Betsy are unable to pick up Johnny that day. Greg will try to find a solution for picking up Johnny\n",
      "Inconsistent sentence/spans:(Both Greg and Betsy are unable to work long hours with Johnny that day , work long hours with)\n",
      "\n",
      "Summary: Greg needs to stay after hours at work. Betsy is also working long hours that day. It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays. Both Greg and Betsy are unable to pick up Johnny that day. Betsy will try to find a solution for picking Johnny up. Greg will try to find a solution for picking up Johnny\n",
      "Inconsistent sentence/spans:(Betsy will try to find a solution for picking Johnny up , Betsy)\n",
      "\n",
      "Summary: Greg needs to stay after hours at work. Betsy is also working long hours that day. It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays. Both Greg and Betsy are unable to pick up Johnny that day. Greg will try to find a solution to stop Johnny. Greg will try to find a solution for picking up Johnny\n",
      "Inconsistent sentence/spans:(Greg will try to find a solution to stop Johnny , stop)\n",
      "\n",
      "Summary: Greg needs to stay after hours at work. Betsy is also working with Johnny long that day. Betsy is also working long hours that day. It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays. Both Greg and Betsy are unable to pick up Johnny that day. Greg will try to find a solution for picking up Johnny\n",
      "Inconsistent sentence/spans:(Betsy is also working with Johnny long that day , with Johnny)\n",
      "\n",
      "Summary: Greg needs to stay after hours at work. Betsy is also on vacation with long hours that day. Betsy is also working long hours that day. It is Greg's responsibility to pick up Johnny from kindergarten on Tuesdays. Both Greg and Betsy are unable to pick up Johnny that day. Greg will try to find a solution for picking up Johnny\n",
      "Inconsistent sentence/spans:(Betsy is also on vacation with long hours that day , on vacation with)\n",
      "\n",
      "Summary:Greg and Betsy have a lot of work today, so they cannot pick up Johnny from the kindergarten. However, it's Greg's turn to do it. Greg will try to find a solution.\n",
      "Inconsistent sentence/spans:\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "1f9837e8-a672-42dd-a459-2a1bcd9abf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(None)'"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPTInference().get_chatgpt_response(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e7d7c-34d3-4135-850d-263429add776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
