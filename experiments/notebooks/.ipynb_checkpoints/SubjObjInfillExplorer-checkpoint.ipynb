{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b886c8b-e237-425f-ba51-231bc39cc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25e2e3c-9b0f-43b1-89d6-076f8d991634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e3e9ff-fff2-4c85-aff1-87cd0f1b19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_facts_gpt(gpt_model_atomic, text, text_type):\n",
    "    instr = f'Segment the following {text_type} into important facts'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt)\n",
    "    return gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df16e0e-5d97-494c-a2a4-f6a546f5da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_all_errtypes(text):\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "            # print(idx, origin_tokens)\n",
    "            # masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            # masked_text = ' '.join(masked_text)\n",
    "            # print(masked_text)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            \n",
    "        elif 'VERB' in token.pos_:\n",
    "            append = True \n",
    "            token_type = 'verb'\n",
    "\n",
    "        if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "    # print([])\n",
    "    print(mask_tokens)  \n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b27a64-5bcf-41a2-9579-232c327d7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjobj_answer(gpt_model_corruptor, dlg, text, answer):\n",
    "    instruction = \"List other subject or object entities from the dialogue that can be used to fill in the <BLANK> in the summary\"\n",
    "    # instruction = \"List subject or object entities that can be used to fill in the <BLANK>\"\n",
    "    prompt_template = f'Dialogue: {dlg}\\nSummary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "    # print(prompt_template)\n",
    "    # print('--')\n",
    "    # prompt_template = f'Summary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "    answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2951b9-7563-4d26-8ab3-856a78e7cce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
