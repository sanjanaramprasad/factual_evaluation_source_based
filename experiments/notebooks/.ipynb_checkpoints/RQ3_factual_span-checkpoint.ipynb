{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3178534e-1632-42fc-ad44-d87162e780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from experiments.models.GPTModel import GPTInference\n",
    "from tqdm import tqdm\n",
    "import re, string\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3352b6-ae0f-40b4-8794-40f623d7758d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm = pd.read_csv('/home/sanjana/factual_evaluation_source_based/annotations/round1_aggredialfact_annotated/dialoguefact_two_annotators_round1.csv')\n",
    "df_llm = df_llm[df_llm['user_id'] == 'ann_wjbp']\n",
    "df_sota = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_finegrained_aggrefact.csv')\n",
    "len(df_llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db02a83-e2ae-4b80-8d4b-8e4394a6b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Helen was trying to reach Simon, but he was unavailable because he was on the phone. Once they connected, Helen asked Simon to bring her some tissues because the toilet paper had run out. He agreed with a laugh.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_idx = 2\n",
    "row = df_llm.iloc[[row_idx]]\n",
    "summ = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]\n",
    "nonfactual_span = row['nonfactual_spans'].values[0]\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cd30d3-a202-4516-9f06-b0620e17720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 21:20:33.648467: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-22 21:20:34.359324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "summ = \"Helen was trying to reach Simon, but he was not available because he was on the phone. Once they connected, Helen asked Simon to bring her some tissues because the toilet paper had run out. He agreed with a laugh.\"\n",
    "\n",
    "summ_doc =nlp(summ)\n",
    "\n",
    "sents = [sent.text for sent in summ_doc.sents]\n",
    "\n",
    "text = sents[0]\n",
    "doc = nlp(text)\n",
    "origin_tokens = [token for token in doc]\n",
    "\n",
    "def check_membership(token, compare_list):\n",
    "    for each in compare_list:\n",
    "        if token == each:\n",
    "            return True\n",
    "    return False \n",
    "    \n",
    "# origin_tokens = [token for token in doc]\n",
    "all_masked_results = []\n",
    "mask_idx = []\n",
    "mask_tokens = []\n",
    "pos_tags = {\n",
    "    'noun': ['PROPN', 'NOUN'],\n",
    "    'verb': ['VERB'],\n",
    "    'adjective': ['ADJ'],\n",
    "    'adposition': ['ADP'],\n",
    "    'pronoun': ['PRON'],\n",
    "    'adverb': ['ADV']\n",
    "                \n",
    "}\n",
    "\n",
    "dep_tags = {\n",
    "    'subjobj': ['nsubj', 'dobj', 'pobj'], \n",
    "    'negation': ['neg'],\n",
    "    'preposition': ['prep'],\n",
    "    \n",
    "}\n",
    "\n",
    "tags = {\n",
    "    'verb': ['VBZ', 'VBG', 'VB'],\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for idx, token in enumerate(doc):\n",
    "    append = False\n",
    "    # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "    if check_membership(token.dep_, dep_tags['subjobj']) and check_membership(token.pos_, pos_tags['noun']):\n",
    "        # print('SUBJOBJ')\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        append = True\n",
    "        token_type = 'subjobj'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "\n",
    "    elif check_membership(token.pos_, pos_tags['adjective']):\n",
    "        append = True\n",
    "        token_type = 'attr'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.tag_, tags['verb']) or check_membership(token.pos_, pos_tags['verb']):\n",
    "        append = True\n",
    "        token_type = 'pred'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "\n",
    "    elif check_membership(token.dep_, dep_tags['negation']):\n",
    "        append = True\n",
    "        token_type = 'neg'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.pos_, pos_tags['pronoun']):\n",
    "        append = True\n",
    "        token_type = 'coref'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.dep_, dep_tags['preposition']) or \\\n",
    "    check_membership(token.pos_, pos_tags['adverb']) or \\\n",
    "    check_membership(token.pos_, pos_tags['adposition']):\n",
    "        append = True\n",
    "        token_type = 'circ'\n",
    "        \n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "\n",
    "error_types_indices_map = {}\n",
    "for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42e54df9-927d-427d-9aa4-2e6ad2c79346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helen: Hey, Simo, are you there?\n",
      "Simon: Yep babe, what''s up?\n",
      "Helen: I was calling you before...\n",
      "Simon: Sorry I was on the phone, I didn''t hear you... Tell me.\n",
      "Helen: It''s a bit embarrassing... The toilet paper is finished, could you fetch me some tissues, please?\n",
      "Simon: Hahaha sure, no worries!\n"
     ]
    }
   ],
   "source": [
    "print(dlg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d830c7e-8422-4aac-b81d-770435216312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26319/1183722883.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  sent1.similarity(sent2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47889623839999546"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7fd62ab-b27e-4c44-8bd9-a72d8057343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1) Helen', '2) His girlfriend, Helen', \"3) Simon's girlfriend, Helen\"]\n",
      "['Simon, her boyfriend', 'Simon, the person she was speaking to', 'Simon, the other party in the conversation']\n",
      "['1) phone', '2) call', '3) line']\n",
      "['1. struggling', '2. trying ', '3. attempting']\n",
      "['1) reach', '2) contact', '3) get in touch with']\n",
      "['1) was ', '2) was', '3) was']\n",
      "['1) was busy', '2) was engaged', '3) was occupied']\n",
      "['1) he', '2) Simon', '3) her boyfriend']\n",
      "['1) he ', '2) Simon ', '3) her boyfriend']\n",
      "['1) not ', '2) unavailable ', '3) not immediately']\n",
      "['responsive', ' available', ' answering']\n",
      "['1) on', '2) using', '3) busy with']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "instruction = '''\n",
    "List three appropriate answers that can fill in the <BLANK> in the sentence based on information from the dialogue snippet. Ensure the sentence is consistent with dialogue.\n",
    "'''\n",
    "answers = []\n",
    "for sentence, answer, err_type in all_masked_results:   \n",
    "    prompt = f'{instruction}\\nSource: {dlg}\\nSentence: {sentence}'\n",
    "    response = GPTInference().get_chatgpt_response(prompt)\n",
    "    if len(response.split('\\n')) > 1:\n",
    "        response = response.split('\\n')\n",
    "    elif len(response.split(',')) > 1:\n",
    "        response = response.split(',')\n",
    "    print(response)\n",
    "    answers += [response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdf7a5b0-1930-4383-9516-9a72a900ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1) Helen\\n2) Helen\\n3) Helen',\n",
       " '1) Simon\\n2) her friend Simon\\n3) her boyfriend Simon',\n",
       " '1) phone\\n2) call\\n3) line',\n",
       " '1. trying\\n2. attempting\\n3. trying hard',\n",
       " '1) reach\\n2) contact\\n3) call',\n",
       " '1) was\\n2) was initially\\n3) was temporarily',\n",
       " '1) was busy\\n2) was engaged\\n3) was occupied',\n",
       " '1) Simon \\n2) he \\n3) her boyfriend',\n",
       " '1) he\\n2) Simon\\n3) he (Simon)',\n",
       " '1) not\\n2) unavailable\\n3) not immediately',\n",
       " '1) responsive\\n2) available\\n3) reachable',\n",
       " '1) on\\n2) using\\n3) busy with']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c15a81-ece4-43d2-8946-0b9fb641abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helen',\n",
       " 'Simon',\n",
       " 'phone',\n",
       " 'trying',\n",
       " 'reach',\n",
       " 'was',\n",
       " 'was',\n",
       " 'he',\n",
       " 'he',\n",
       " 'not',\n",
       " 'available',\n",
       " 'on']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[each[1] for each in all_masked_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f0985-039d-4905-9f1f-3c6de696990c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
