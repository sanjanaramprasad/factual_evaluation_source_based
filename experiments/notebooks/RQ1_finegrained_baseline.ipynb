{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf5048cf-ffc1-431f-95ac-1806c6695fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference\n",
    "from tqdm import tqdm\n",
    "import re, string\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fd7a5bd5-115b-42d6-ad7a-df66c7096a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_incontext_examples(df, num_samples, instruction):\n",
    "    each_sample = int(num_samples/2)\n",
    "    num_errors = []\n",
    "    print('Before sampling', len(df))\n",
    "    for ann in list(df['Annotations'].values):\n",
    "        ann = eval(ann)\n",
    "        num_errors += [sum([len(spans) for sent, spans in ann.items()])]\n",
    "    df['Errors'] = num_errors\n",
    "    df_fewshot_spans_one = df[df['Errors'] == 1].sample(each_sample )\n",
    "    df_fewshot_spans_two = df[df['Errors'] > 1].sample(each_sample )\n",
    "    df_fewshot_nospans = df[df['Errors'] == 0].sample(1)\n",
    "    df_fewshot =pd.concat([df_fewshot_spans_one, df_fewshot_spans_two, df_fewshot_nospans])\n",
    "    df_fewshot = df_fewshot.sample(len(df_fewshot))\n",
    "    df_fewshot.to_csv('fewshot_examples.csv')\n",
    "\n",
    "    prompt_strs = []\n",
    "    for idx, row in df_fewshot.iterrows():\n",
    "        df = df.drop(idx)\n",
    "        dialogue = row['Dialogue']\n",
    "        inconsistent_spans = eval(row['Annotations'])\n",
    "        inconsistent_spans = []\n",
    "        for sent, sent_spans in eval(row['Annotations']).items():\n",
    "            # sent_spans = ', '.join([each[0] for each in sent_spans])\n",
    "            sent_spans = [each[0] for each in sent_spans]\n",
    "            # inconsistent_spans += [f'SENT {sent} SPANS {sent_spans}']\n",
    "            inconsistent_spans += sent_spans\n",
    "            print(sent_spans)\n",
    "        inconsistent_spans = '\\n'.join(inconsistent_spans)\n",
    "        inconsistent_spans = inconsistent_spans if inconsistent_spans else \"None\"\n",
    "        prompt_strs.append(f'Dialogue: {dialogue}\\nSummary: {row[\"Summary\"]}\\n{instruction}\\nInconsistent Spans: {inconsistent_spans}')\n",
    "    fewshot_prompt_str = '\\n\\n'.join(prompt_strs)\n",
    "    print('After sampling', len(df))\n",
    "    return fewshot_prompt_str, df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "19378731-046c-4eaf-9ea6-5a6ad0918352",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scoring code\n",
    "'''\n",
    "\n",
    "def postprocess(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "    \n",
    "\n",
    "def get_candidate_comparison(gpt_response, annotations):\n",
    "    scores = []\n",
    "    comparisons = []\n",
    "    for k ,v in annotations.items():\n",
    "        gpt_response_processed = set(postprocess(gpt_response).split())\n",
    "        k_processed = set(postprocess(k).split())\n",
    "        sentence_overlap = 0 \n",
    "        if len(gpt_response_processed):\n",
    "            sentence_overlap = len(gpt_response_processed.intersection(k_processed))/len(gpt_response_processed)\n",
    "        scores += [sentence_overlap]\n",
    "    \n",
    "    # max_score = max(scores)\n",
    "    if scores:\n",
    "        max_scores_idx = [idx for idx, each in enumerate(scores) if each == max(scores)]     \n",
    "        v_items = list(annotations.values())\n",
    "        comparisons = v_items[max_scores_idx[0]]\n",
    "    # comparisons = [ each for idx in max_scores_idx for each in v_items[idx]]\n",
    "    return comparisons\n",
    "\n",
    "def span_scores(gpt_response, annotations):\n",
    "\n",
    "    # comparisons = get_candidate_comparison(gpt_response, annotations)\n",
    "    \n",
    "    span_accuracies = []\n",
    "    span_f1_scores = []\n",
    "    # print('COMPARISONS', comparisons, gpt_response)\n",
    "    comparisons = []\n",
    "    for each in annotations.values():\n",
    "        comparisons += each\n",
    "        \n",
    "    for comp in comparisons:\n",
    "        accuracy = 0\n",
    "        f1_score = 0\n",
    "        \n",
    "        y_text = comp[0]\n",
    "        gpt_response_processed = set(postprocess(gpt_response).split())\n",
    "        y_text_processed = set(postprocess(y_text).split())\n",
    "        \n",
    "        overlap = gpt_response_processed.intersection(y_text_processed)\n",
    "        \n",
    "        precision = len(overlap)/len(gpt_response_processed) if len(gpt_response_processed) else 0\n",
    "        recall = len(overlap)/len(y_text_processed)\n",
    "\n",
    "        # print(gpt_response, y_text, overlap, precision, recall)\n",
    "        \n",
    "        if precision + recall > 0:\n",
    "            f1_score = (2 * precision * recall)/(precision + recall)\n",
    "    \n",
    "        if len(gpt_response_processed) and len(overlap)/len(gpt_response_processed) == 1:\n",
    "            accuracy = 1\n",
    "            \n",
    "        span_accuracies += [accuracy]\n",
    "        span_f1_scores += [f1_score]\n",
    "\n",
    "    span_accuracies = span_accuracies if span_accuracies else [0]\n",
    "    span_f1_scores = span_f1_scores if span_f1_scores else [0]\n",
    "    # if comparisons:\n",
    "    # print('MOST SIM', comparisons[span_accuracies.index(max(span_accuracies))], gpt_response)\n",
    "    return max(span_accuracies), max(span_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "31937471-f103-4546-bfbf-84685c8e460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Zero shot dialogue and atomic facts prompting\n",
    "'''\n",
    "\n",
    "def gpt_text_inconsistent(gpt_response):\n",
    "    if not gpt_response.strip():\n",
    "        return True\n",
    "    elif [each  for each in ['no inconsistent', 'none', '[]'] if each in gpt_response.lower()]:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "def get_gpt_span_scores(prompt, annotations, few_shot = True):\n",
    "    gpt_response = GPTInference().get_chatgpt_response(prompt)\n",
    "    \n",
    "    # gpt_response = eval(gpt_response.split('\\n')[0])\n",
    "    # print('GPT RESPONSE', gpt_response)\n",
    "    # print('ANNOTATIONS', annotations)\n",
    "    all_spans = gpt_response.split('\\n')\n",
    "    # if few_shot:\n",
    "    #     all_spans = []\n",
    "    #     for sent_spans in gpt_response.split('\\n'):\n",
    "    #         all_spans += sent_spans.split('SPANS')[1].strip().split(', ')\n",
    "    # print('GPT RESPONSE', gpt_response, all_spans)\n",
    "    row_f1_scores = []\n",
    "    row_acc_scores = []\n",
    "    \n",
    "    if gpt_text_inconsistent(gpt_response) and not annotations:\n",
    "                row_f1_scores += [1]\n",
    "                row_acc_scores += [1]\n",
    "        \n",
    "    else:\n",
    "        for gpt_span in all_spans:\n",
    "                gpt_span_scores = span_scores(gpt_span, annotations)\n",
    "                \n",
    "                row_f1_scores += [gpt_span_scores[1]]\n",
    "                row_acc_scores += [gpt_span_scores[0]]\n",
    "                # print('SCORES', gpt_span, gpt_span_scores)\n",
    "    # print('=' * 13)\n",
    "    return np.mean(row_f1_scores), np.mean(row_acc_scores), gpt_response\n",
    "\n",
    "def get_zero_shot_scores(df, source_type = 'Dialogue'):\n",
    "    span_scores_acc = []\n",
    "    span_scores_f1 = []\n",
    "    gpt_responses = []\n",
    "    # df_sample = df.sample(20)\n",
    "    df_sample = df[df['Errors'] > 1]\n",
    "    # df_sample = df_sample.sample(10)\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "    # for idx, row in df_sample.iterrows():\n",
    "        # print(idx)\n",
    "        dlg = row['Dialogue']\n",
    "        # dlg_atomic = get_atomic_facts_gpt(dlg)\n",
    "        summ = row['Summary']\n",
    "        \n",
    "        annotations = eval(row['Annotations'])\n",
    "        # print(annotations)\n",
    "        \n",
    "        instruction = f\"Identify and list the inconsistent phrases or words in the dialogue summary. Note that consistency means all information in the summary is supported by the {source_type}. List each span in a new line\"\n",
    "        prompt_dlg = f'{instruction}\\n{source_type}: {dlg}\\nSummary: {summ}\\nInconsistent Spans:'\n",
    "\n",
    "        # source_type = 'Source'\n",
    "        # instruction = f\"Extract only the inconsistent phrases or words in the summary. Note that consistency means all information in the summary is supported by the {source_type}. List each span in a new line\"\n",
    "        # prompt_dlg_atomic = f'{instruction}\\n{source_type}: {dlg_atomic}\\nSummary: {summ}\\nInconsistent Spans:'\n",
    "        # print(prompt_dlg)\n",
    "        span_f1, span_acc, gpt_response= get_gpt_span_scores(prompt_dlg, annotations, few_shot=False)\n",
    "        span_scores_acc.append(span_acc)\n",
    "        span_scores_f1.append(span_f1)\n",
    "        gpt_responses.append(gpt_response)\n",
    "        # print('*' * 20)\n",
    "        # print(span_f1, span_acc)\n",
    "    return span_scores_f1, span_scores_acc, gpt_responses\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# get_zero_shot_scores(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "49de2b80-7ec5-4a20-8968-945124cb3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_few_shot_scores(df, fewshot_str, instruction):\n",
    "    df_sample = df.sample(1)\n",
    "    span_scores_acc = []\n",
    "    span_scores_f1 = []\n",
    "    gpt_responses = []\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        dlg = row['Dialogue']\n",
    "        # dlg_atomic = get_atomic_facts_gpt(dlg)\n",
    "        summ = row['Summary']\n",
    "        # print('SUMMARY', summ)\n",
    "        annotations = eval(row['Annotations'])\n",
    "        \n",
    "        prompt_dlg = f'{fewshot_str}\\n\\nDialogue: {dialogue}\\nSummary: {row[\"Summary\"]}\\n{instruction}\\nInconsistent Spans:'\n",
    "        # print(prompt_dlg)\n",
    "        span_f1, span_acc, gpt_response= get_gpt_span_scores(prompt_dlg, annotations)\n",
    "        span_scores_acc.append(span_acc)\n",
    "        span_scores_f1.append(span_f1)\n",
    "        gpt_responses.append(gpt_response)\n",
    "    return span_scores_f1, span_scores_acc, gpt_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "f597b358-8849-48ce-8029-c6c56641e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_few_shot_scores(df, ic_dlg, ic_summary_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "3592fecc-2781-4b3d-84e2-0fc63bd5d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling 295\n",
      "['and needs']\n",
      "['borrow']\n",
      "['Chris and Ann']\n",
      "['Mason']\n",
      "['a woman']\n",
      "['will watch']\n",
      "After sampling 290\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_finegrained_aggrefact.csv')\n",
    "source_type = \"dialogue\"\n",
    "instruction =  f\"Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the {source_type}. List each span in a new line\"\n",
    "\n",
    "fewshot_prompt_str, df  = make_incontext_examples(df, 4, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "9da769ca-546a-4ccf-834a-3de131a61eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: Derek McCarthy: Filip - are you around? Would you have an Android cable I could borrow for an hour? I'm almost out of charge and I have a power pack  but forgot my cable😭\n",
      "Tommy: I am in Poland but can ring my wife and she will give you one\n",
      "Tommy: Do you want me to?\n",
      "Tommy: 67 glenoaks close\n",
      "Derek McCarthy: That would be great if you could!! Otherwise I'm sitting here in the dark for an hour <emoticon_smile>\n",
      "Tommy: Put it in gps and start driving\n",
      "Derek McCarthy: <emoticon_thumbup>\n",
      "Tommy: She might be at work for next 15 min but will help you for sure\n",
      "Derek McCarthy: Thanks a lot mate\n",
      "Tommy: Sent her msg. She will give it to you. Approx time when she will be at home is 8:15 pm\n",
      "Derek McCarthy: Thanks again!! What's your wife's name  again??\n",
      "Tommy: Paulina\n",
      "Summary: Tommy is in Poland and needs an Android cable to power his power pack. Tommy will call his wife Paulina to borrow one.\n",
      "Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the dialogue. List each span in a new line\n",
      "Inconsistent Spans: and needs\n",
      "borrow\n",
      "\n",
      "Dialogue: Ryan: Merry Christmas everybody!\n",
      "Nick: Merry Xmas!\n",
      "Chris: Merry Xmas to you!\n",
      "Chris: Where are you btw?\n",
      "Ryan: visiting family in Manchester\n",
      "Ryan: white a disaster hahhaha\n",
      "Chris: We stayed home with Ann, first time on our own!\n",
      "Chris: and I've liked it so far very much\n",
      "Summary: Ryan is visiting family in Manchester. Chris and Ann stayed home with Ann for Christmas.\n",
      "Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the dialogue. List each span in a new line\n",
      "Inconsistent Spans: Chris and Ann\n",
      "\n",
      "Dialogue: Sophia: I'm sorry\n",
      "Mason: It's fine\n",
      "Sophia: Ok...If u was there, I would give you a hot kiss for apologize\n",
      "Mason: Hahaha. You still send me a photo one\n",
      "Sophia: What photo?\n",
      "Mason: Kiss photo. Haha\n",
      "Sophia: Hehe I sent u already such a photo\n",
      "Mason: Another one wouldn't hurt\n",
      "Sophia: Maybe later :) When I take a shower and look good\n",
      "Mason: And who says you don't look good now ?\n",
      "Sophia: Me\n",
      "Mason: Let me be the judge of that\n",
      "Sophia: No\n",
      "Mason: I'll still love you the same. Whether you have make up or not\n",
      "Sophia: Hehe but I don't  want u to see me when I do not look good\n",
      "Mason: You must\n",
      "Sophia: I must what?\n",
      "Mason: Send me the kiss now\n",
      "Sophia: Haha\n",
      "Mason: Doesn't matter how you look, you'll still look good to me\n",
      "Sophia: Hahah\n",
      "Sophia: <file_photo>\n",
      "Summary: Mason sends Sophia a Kiss photo. Sophia doesn't want Mason to see her when she doesn't look good. Mason is not going to judge Sophia.\n",
      "Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the dialogue. List each span in a new line\n",
      "Inconsistent Spans: Mason\n",
      "\n",
      "Dialogue: Lilly: Wanna go out tonight?\n",
      "Marshall: can't :( money's low\n",
      "Lilly: my treat :)\n",
      "Marshall: I wouldn't let a woman pay for me Lils\n",
      "Lilly: a woman\n",
      "Lilly: ME\n",
      "Marshall: come over and we'll watch some netflix\n",
      "Summary: Marshall can't go out tonight because he can't pay for a woman. He and a woman will watch some Netflix tonight at Marshall's.\n",
      "Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the dialogue. List each span in a new line\n",
      "Inconsistent Spans: a woman\n",
      "will watch\n",
      "\n",
      "Dialogue: Morgan: Hey gorgeous, how’s your day?\n",
      "Suzanne: Nothing special, it’s just one of many boring days at work. But… better now though!\n",
      "Morgan: Are you working at all? 😉\n",
      "Suzanne: I’m trying 😉 But you aren’t helping me, at all\n",
      "Suzanne: I’m just taking a well-deserved break 😉\n",
      "Morgan:  I miss you Suzie\n",
      "Suzanne: I miss you too Morgan\n",
      "Morgan: Do you feel like going to a concert next week? Maroon 5 is playing at the Hulu Theater at Madison Square Garden.\n",
      "Morgan: As it happens, I’ve got two tickets 😉\n",
      "Morgan: Do you want to go?\n",
      "Suzanne: Really? OMG! That’s wonderful!\n",
      "Suzanne: Thank you sweetheart!\n",
      "Morgan: Oh, nothing. I just want you to be happy 😉\n",
      "Summary: Morgan and Suzanne are going to a Maroon 5 concert next week. Morgan has two tickets.\n",
      "Identify and list inconsistent phrases or words from the dialogue summary. Note inconsistency here refers to any information in the summary not supported by the dialogue. List each span in a new line\n",
      "Inconsistent Spans: None\n"
     ]
    }
   ],
   "source": [
    "print(fewshot_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "70a5d370-0219-478f-b833-84f2d4a08cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fewshot_prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "5556d887-2ba0-4e54-b440-2018340a5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 290/290 [04:32<00:00,  1.07it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[592], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# span_scores_f1_fewshot, span_scores_acc_fewshot = get_few_shot_scores(df, fewshot_prompt_str, instruction)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m span_scores_f1, span_scores_acc \u001b[38;5;241m=\u001b[39m get_zero_shot_scores(df)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# span_scores_f1_fewshot, span_scores_acc_fewshot = get_few_shot_scores(df, fewshot_prompt_str, instruction)\n",
    "span_scores_f1, span_scores_acc = get_zero_shot_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "d7223785-91d1-4a20-85b5-04073c3949c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5386548711701515, 0.35535714285714287)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(span_scores_f1), np.mean(span_scores_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "36dcdfc2-c101-4e9e-9b06-ecaf1f6a7e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 290/290 [18:08<00:00,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "span_scores_f1_fewshot, span_scores_acc_fewshot, gpt_responses_fewshot = get_few_shot_scores(df, fewshot_prompt_str, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "54756d25-c6c8-4feb-9d2c-891b19488353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12469500482870277, 0.012471264367816091)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(span_scores_f1_fewshot), np.mean(span_scores_acc_fewshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "e5d64381-c8c9-4579-8327-e87d5265bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fewshot_span_f1'] = span_scores_f1_fewshot\n",
    "df['fewshot_span_acc'] = span_scores_acc_fewshot\n",
    "df['fewshot_gpt_text'] = gpt_responses_fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "580473bf-d5e5-4d69-b679-e3a470064f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 278/278 [03:26<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "span_scores_f1, span_scores_acc, gpt_responses = get_zero_shot_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c27b7821-49e6-4647-9885-48310ff5d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zeroshot_span_f1'] = span_scores_f1\n",
    "df['zeroshot_span_acc'] = span_scores_acc\n",
    "df['zeroshot_gpt_text'] = gpt_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "84b49a33-3779-4ce2-80f6-adfabac21b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('finegrained_gpteval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3d72511e-d62e-4b30-b13a-d753d737db68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Model</th>\n",
       "      <th>Summary</th>\n",
       "      <th>origin</th>\n",
       "      <th>Annotations</th>\n",
       "      <th>Reference_Summary</th>\n",
       "      <th>Errors</th>\n",
       "      <th>fewshot_span_f1</th>\n",
       "      <th>fewshot_span_acc</th>\n",
       "      <th>fewshot_gpt_text</th>\n",
       "      <th>zeroshot_span_f1</th>\n",
       "      <th>zeroshot_span_acc</th>\n",
       "      <th>zeroshot_gpt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>gpt3_finetune</td>\n",
       "      <td>Charles will probably arrive at the train stat...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Charles will probably arrive at the train st...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Charles\\nwill probably arrive at the train sta...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No inconsistent spans.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>pegasus</td>\n",
       "      <td>Natacha will pick Charles up at the RER at 5:3...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Natacha will pick Charles up at the RER at 5...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Natacha will pick Charles up at the RER at 5:3...</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Natacha will pick Charles up at the RER at 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>structure_aware_bart</td>\n",
       "      <td>Natacha will pick Charles up at the RER at 5:3...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Natacha will pick Charles up at the RER at 5...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Natacha will pick Charles up at the RER at 5:3...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Natacha will pick Charles up at the RER at 5:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>condigsum</td>\n",
       "      <td>Natacha will pick Charles up at the RER statio...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Natacha will pick Charles up at the RER stat...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Natacha will pick Charles up at the RER statio...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"at 5:30 pm.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>bart</td>\n",
       "      <td>Natacha will pick Charles up at the station Ve...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Natacha will pick Charles up at the station ...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Natacha will pick Charles up at the station Ve...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"at 5:30 pm\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>Mark: So, we've got our where and when. Packag...</td>\n",
       "      <td>gpt3_finetune</td>\n",
       "      <td>Mark, Anna, George and Julia are going on a pa...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{}</td>\n",
       "      <td>They are going to do some research on holiday ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Mark, Anna, George and Julia are going on a pa...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"George: Self-organised. Cheaper.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>Mark: So, we've got our where and when. Packag...</td>\n",
       "      <td>condigsum</td>\n",
       "      <td>Mark, Julia, Anna, George and George are going...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Mark, Julia, Anna, George and George are goi...</td>\n",
       "      <td>They are going to do some research on holiday ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Mark, Julia, Anna, George and George are going...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Mark, Julia, Anna, George and George are goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>Mark: So, we've got our where and when. Packag...</td>\n",
       "      <td>bart</td>\n",
       "      <td>Mark, Anna, Julia, George and Anna are going o...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Mark, Anna, Julia, George and Anna are going...</td>\n",
       "      <td>They are going to do some research on holiday ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Mark\\nAnna\\nJulia\\nGeorge\\npackage tour\\ngoing...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Mark, Anna, Julia, George and Anna are going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>Mark: So, we've got our where and when. Packag...</td>\n",
       "      <td>pegasus</td>\n",
       "      <td>Mark, Anna, George and Julia are looking for a...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{}</td>\n",
       "      <td>They are going to do some research on holiday ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Mark, Anna, George and Julia\\nlooking for a pa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>Mark: So, we've got our where and when. Packag...</td>\n",
       "      <td>structure_aware_bart</td>\n",
       "      <td>Mark, Anna, George and Julia are going to a pa...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{}</td>\n",
       "      <td>They are going to do some research on holiday ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Mark, Anna, George and Julia\\nare going to a p...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Mark, Anna, George and Julia are going to a p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           Dialogue  \\\n",
       "0             0  Natacha: hi, i can come and pick you up at the...   \n",
       "1             1  Natacha: hi, i can come and pick you up at the...   \n",
       "2             2  Natacha: hi, i can come and pick you up at the...   \n",
       "3             3  Natacha: hi, i can come and pick you up at the...   \n",
       "4             4  Natacha: hi, i can come and pick you up at the...   \n",
       "..          ...                                                ...   \n",
       "290         290  Mark: So, we've got our where and when. Packag...   \n",
       "291         291  Mark: So, we've got our where and when. Packag...   \n",
       "292         292  Mark: So, we've got our where and when. Packag...   \n",
       "293         293  Mark: So, we've got our where and when. Packag...   \n",
       "294         294  Mark: So, we've got our where and when. Packag...   \n",
       "\n",
       "                    Model                                            Summary  \\\n",
       "0           gpt3_finetune  Charles will probably arrive at the train stat...   \n",
       "1                 pegasus  Natacha will pick Charles up at the RER at 5:3...   \n",
       "2    structure_aware_bart  Natacha will pick Charles up at the RER at 5:3...   \n",
       "3               condigsum  Natacha will pick Charles up at the RER statio...   \n",
       "4                    bart  Natacha will pick Charles up at the station Ve...   \n",
       "..                    ...                                                ...   \n",
       "290         gpt3_finetune  Mark, Anna, George and Julia are going on a pa...   \n",
       "291             condigsum  Mark, Julia, Anna, George and George are going...   \n",
       "292                  bart  Mark, Anna, Julia, George and Anna are going o...   \n",
       "293               pegasus  Mark, Anna, George and Julia are looking for a...   \n",
       "294  structure_aware_bart  Mark, Anna, George and Julia are going to a pa...   \n",
       "\n",
       "     origin                                        Annotations  \\\n",
       "0    SAMSum  {'Charles will probably arrive at the train st...   \n",
       "1    SAMSum  {'Natacha will pick Charles up at the RER at 5...   \n",
       "2    SAMSum  {'Natacha will pick Charles up at the RER at 5...   \n",
       "3    SAMSum  {'Natacha will pick Charles up at the RER stat...   \n",
       "4    SAMSum  {'Natacha will pick Charles up at the station ...   \n",
       "..      ...                                                ...   \n",
       "290  SAMSum                                                 {}   \n",
       "291  SAMSum  {'Mark, Julia, Anna, George and George are goi...   \n",
       "292  SAMSum  {'Mark, Anna, Julia, George and Anna are going...   \n",
       "293  SAMSum                                                 {}   \n",
       "294  SAMSum                                                 {}   \n",
       "\n",
       "                                     Reference_Summary  Errors  \\\n",
       "0    Charles has just landed and he will be at RER ...       1   \n",
       "1    Charles has just landed and he will be at RER ...       2   \n",
       "2    Charles has just landed and he will be at RER ...       1   \n",
       "3    Charles has just landed and he will be at RER ...       1   \n",
       "4    Charles has just landed and he will be at RER ...       1   \n",
       "..                                                 ...     ...   \n",
       "290  They are going to do some research on holiday ...       0   \n",
       "291  They are going to do some research on holiday ...       1   \n",
       "292  They are going to do some research on holiday ...       1   \n",
       "293  They are going to do some research on holiday ...       0   \n",
       "294  They are going to do some research on holiday ...       0   \n",
       "\n",
       "     fewshot_span_f1  fewshot_span_acc  \\\n",
       "0           0.153846          0.000000   \n",
       "1           0.232323          0.000000   \n",
       "2           0.461538          0.000000   \n",
       "3           0.500000          0.000000   \n",
       "4           0.166667          0.000000   \n",
       "..               ...               ...   \n",
       "290         0.000000          0.000000   \n",
       "291         0.173913          0.000000   \n",
       "292         0.111111          0.166667   \n",
       "293         0.000000          0.000000   \n",
       "294         0.000000          0.000000   \n",
       "\n",
       "                                      fewshot_gpt_text  zeroshot_span_f1  \\\n",
       "0    Charles\\nwill probably arrive at the train sta...          0.000000   \n",
       "1    Natacha will pick Charles up at the RER at 5:3...          0.348485   \n",
       "2    Natacha will pick Charles up at the RER at 5:3...          0.461538   \n",
       "3    Natacha will pick Charles up at the RER statio...          0.000000   \n",
       "4    Natacha will pick Charles up at the station Ve...          0.000000   \n",
       "..                                                 ...               ...   \n",
       "290  Mark, Anna, George and Julia are going on a pa...          0.000000   \n",
       "291  Mark, Julia, Anna, George and George are going...          0.153846   \n",
       "292  Mark\\nAnna\\nJulia\\nGeorge\\npackage tour\\ngoing...          0.153846   \n",
       "293  Mark, Anna, George and Julia\\nlooking for a pa...          1.000000   \n",
       "294  Mark, Anna, George and Julia\\nare going to a p...          0.000000   \n",
       "\n",
       "     zeroshot_span_acc                                  zeroshot_gpt_text  \n",
       "0                  0.0                             No inconsistent spans.  \n",
       "1                  0.0  \"Natacha will pick Charles up at the RER at 5:...  \n",
       "2                  0.0  \"Natacha will pick Charles up at the RER at 5:...  \n",
       "3                  0.0                                      \"at 5:30 pm.\"  \n",
       "4                  0.0                                       \"at 5:30 pm\"  \n",
       "..                 ...                                                ...  \n",
       "290                0.0                 \"George: Self-organised. Cheaper.\"  \n",
       "291                0.0  \"Mark, Julia, Anna, George and George are goin...  \n",
       "292                0.0  \"Mark, Anna, Julia, George and Anna are going ...  \n",
       "293                1.0                                               None  \n",
       "294                0.0  \"Mark, Anna, George and Julia are going to a p...  \n",
       "\n",
       "[278 rows x 14 columns]"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d04e6a7e-ceed-44a6-bc24-fa032fb469f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 295/295 [50:10<00:00, 10.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_atomic_facts_gpt( text, text_type = 'dialogue'):\n",
    "        instr = f'Segment the following {text_type.lower()} into atomic facts without introducing any unsupported information'\n",
    "        prompt = f'{instr}\\nDialogue: {text}'\n",
    "        # print(prompt)\n",
    "        gpt_response = GPTInference().get_chatgpt_response(prompt)\n",
    "        return gpt_response\n",
    "\n",
    "    \n",
    "\n",
    "span_scores_acc = []\n",
    "span_scores_f1 = []\n",
    "# df_sample = df.sample(100)\n",
    "for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "    dlg = row['Dialogue']\n",
    "    dlg = get_atomic_facts_gpt(dlg)\n",
    "    summ = row['Summary']\n",
    "    annotations = eval(row['Annotations'])\n",
    "    instruction = \"Extract only the inconsistent phrases or words in the summary. Note that consistency means all information in the summary is supported by the source. List each span in a new line\"\n",
    "    \n",
    "    # prompt = f'{instruction}\\nDialogue: {dlg}\\nSummary: {summ}\\nInconsistent Spans:'\n",
    "    prompt = f'{instruction}\\nSource: {dlg}\\nSummary: {summ}\\nInconsistent Spans:'\n",
    "    # print(prompt)\n",
    "    gpt_response = GPTInference().get_chatgpt_response(prompt)\n",
    "    # print('Model: ', row['Model'])\n",
    "    # print('Dialogue', row['Dialogue'])\n",
    "    # print('SUMMARY: ', row['Summary'])\n",
    "    # print('GPT RESPONSE: ', gpt_response)\n",
    "    # print('ANNOTATIONS: ', annotations)\n",
    "    all_spans = gpt_response.split('\\n')\n",
    "    row_f1_scores = []\n",
    "    row_acc_scores = []\n",
    "\n",
    "    if [each  for each in ['no inconsistent', 'none', '[]'] if each in gpt_response.lower()] and not annotations:\n",
    "            # if not annotations:\n",
    "            row_f1_scores += [1]\n",
    "            row_acc_scores += [1]\n",
    "    \n",
    "    else:\n",
    "        for gpt_span in all_spans:\n",
    "            gpt_span_scores = span_scores(gpt_span, annotations)\n",
    "            \n",
    "            row_f1_scores += gpt_span_scores[1]\n",
    "            row_acc_scores += gpt_span_scores[0]\n",
    "            # print('SPAN', gpt_span)\n",
    "            \n",
    "    # print('Accuracy', row_acc_scores)\n",
    "    # print('F1', row_f1_scores)\n",
    "    \n",
    "    span_scores_acc += [np.mean(row_acc_scores)]\n",
    "    span_scores_f1 += [np.mean(row_f1_scores)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "557641db-1462-45c5-9ec2-c8d5c46ac6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1944632768361582"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(span_scores_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c91ba46f-fc61-4e80-b361-15da01cbe4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d938255b-ff1f-488d-8e3d-efd0304fa37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "61457086-3615-46aa-94a4-ae95e9a27e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is sleeping', 'intrinsic', 'PredE')]\n",
      "Catherine is sleeping is sleeping\n",
      "Catherine is sleeping {'Catherine is sleeping.': [('is sleeping', 'intrinsic', 'PredE')], 'Ana and Catherine are sleeping well.': [('are sleeping well', 'extrinsic', 'PredE')]} ([1], [0.8])\n",
      "[('is sleeping', 'intrinsic', 'PredE'), ('are sleeping well', 'extrinsic', 'PredE')]\n",
      " Ana is going to visit grandma tomorrow is sleeping\n",
      " Ana is going to visit grandma tomorrow are sleeping well\n",
      " Ana is going to visit grandma tomorrow {'Catherine is sleeping.': [('is sleeping', 'intrinsic', 'PredE')], 'Ana and Catherine are sleeping well.': [('are sleeping well', 'extrinsic', 'PredE')]} ([0, 0], [0.22222222222222224, 0])\n",
      "[('are sleeping well', 'extrinsic', 'PredE')]\n",
      " Ana and Catherine are sleeping well are sleeping well\n",
      " Ana and Catherine are sleeping well {'Catherine is sleeping.': [('is sleeping', 'intrinsic', 'PredE')], 'Ana and Catherine are sleeping well.': [('are sleeping well', 'extrinsic', 'PredE')]} ([1], [0.6666666666666666])\n"
     ]
    }
   ],
   "source": [
    "gpt_spans = gpt_response.split(',')\n",
    "for gpt_span in gpt_spans:\n",
    "    print(postprocess(gpt_span), annotations, span_scores(gpt_span, annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28b88b5a-e3c7-4c15-82b8-cded7490ca53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[How are you today?, I hope you have a great day]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"How are you today? I hope you have a great day\"\n",
    "tokens = nlp(text)\n",
    "list(tokens.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2fd32f4-51d7-4699-ab77-18b46c976704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\",\n",
       " Natalie told them in confidence that she's pregnant\",\"Henriette knows who's the father.\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = '''\"Natalie told them in confidence that she\\'s pregnant\",\"Henriette knows who\\'s the father.\"'''\n",
    "import nltk\n",
    "nltk.sent_tokenize(summ)\n",
    "list(nlp(summ).sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "060338c9-cec5-47fc-a994-9b369f63dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "2 == math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ac96a31-c0ff-41a1-861d-eb9584634028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6025623f-13a0-4d60-af68-107710f102f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case 1: gpt_response --> span & annotation --> span \n",
    "#case 2: \n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16ae42-8323-41ac-abf1-11cf86aaf9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7016307a-eea6-4ebb-89b2-9552268d6715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_inconsistent(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f28a440-46a6-460c-84d5-582c9f4b45e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hans will bring the ball\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "045e787b-3c95-4a1d-82c9-86f86889f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Score strategy \n",
    "1) If annotations are empty but GPT found something --> overlap spans, overlap_sents\n",
    "2) If annotation is not empty and GPT did not find something --> no overlap spans, no overlap_sents\n",
    "3) If both are present --> Find most consistent ovelrap sentence, check if in annotation\n",
    "For the sentence, check span overlap \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5d7aff75-e2e7-4e69-b951-365f03284c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(annotations, gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b2ab796f-78ed-414a-8542-df263dd64c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 ['vesinet'] \"Charles will be at the station Vesinet at 5:30 pm.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a043c9fb-5914-4be9-b635-512510550d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Natacha will pick Charles up at the RER at 5:30 pm.': [('5:30 pm',\n",
       "   'intrinsic',\n",
       "   'CirE')],\n",
       " 'Charles will be at the station Vesinet at 5:30 pm.': [('Vesinet',\n",
       "   'intrinsic',\n",
       "   'CirE')]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcc9a5cc-5614-4242-ac7b-36a525eb603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Charles',\n",
       " 'will',\n",
       " 'be',\n",
       " 'at',\n",
       " 'the',\n",
       " 'station',\n",
       " 'Vesinet',\n",
       " 'at',\n",
       " '5:30',\n",
       " 'pm.\"']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_response.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ce669f7-edd3-439e-be72-ff59a52e0946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Charles',\n",
       " 'will',\n",
       " 'be',\n",
       " 'at',\n",
       " 'the',\n",
       " 'station',\n",
       " 'Vesinet',\n",
       " 'at',\n",
       " '5:30',\n",
       " 'pm.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(annotations.keys())[1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ade1bc-8e8b-4f62-a7fe-018545372c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
