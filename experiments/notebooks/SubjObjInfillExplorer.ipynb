{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b886c8b-e237-425f-ba51-231bc39cc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25e2e3c-9b0f-43b1-89d6-076f8d991634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e3e9ff-fff2-4c85-aff1-87cd0f1b19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_facts_gpt(gpt_model_atomic, text, text_type):\n",
    "    instr = f'Segment the following {text_type} into important facts'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt)\n",
    "    texts = gpt_response.split('\\n')\n",
    "    texts = [re.sub('[1-9]', '', each) for each in texts]\n",
    "    texts = [each.strip(string.punctuation).strip() for each in texts]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df16e0e-5d97-494c-a2a4-f6a546f5da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_all_errtypes(text):\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "            # print(idx, origin_tokens)\n",
    "            # masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            # masked_text = ' '.join(masked_text)\n",
    "            # print(masked_text)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            \n",
    "        elif 'VERB' in token.pos_:\n",
    "            append = True \n",
    "            token_type = 'verb'\n",
    "\n",
    "        if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "    # print([])\n",
    "    print(mask_tokens)  \n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b27a64-5bcf-41a2-9579-232c327d7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjobj_answer(gpt_model_corruptor, dlg, text, answer):\n",
    "    instruction = \"List other subject or object entities from the dialogue that can be used to fill in the <BLANK> in the summary\"\n",
    "    # instruction = \"List subject or object entities that can be used to fill in the <BLANK>\"\n",
    "    prompt_template = f'Dialogue: {dlg}\\nSummary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "    # print(prompt_template)\n",
    "    # print('--')\n",
    "    # prompt_template = f'Summary: {text}\\n{instruction}\\nAnswer: {answer},'\n",
    "    answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2951b9-7563-4d26-8ab3-856a78e7cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_file('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_aggrefact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25db42a7-8e0c-465a-b182-2fbcbe2199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Summary'].values[10]\n",
    "dlg = df['Dialogue'].values[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a08b01-307d-42d4-b282-94d53cec8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment the following dialogue into important facts\n",
      "Dialogue: Greg: Hi, honey. I need to stay after hours :-(\n",
      "Betsy: Again?\n",
      "Greg: I'm sorry!\n",
      "Betsy: What about Johnny?\n",
      "Greg: Well, could you pick him up? \n",
      "Betsy: What if I can't?\n",
      "Greg: Betsy?\n",
      "Betsy: What if I can't?\n",
      "Greg: Can't you, really?\n",
      "Betsy: I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten.\n",
      "Greg: Talk to you later. I'll see what I can do.\n",
      "Betsy: You'd better think of something.\n",
      "Greg: Oh. Just stop it now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greg needs to stay after hours at work',\n",
       " 'Betsy also needs to work long hours today',\n",
       " \"Today is Greg's day to pick up Johnny from kindergarten\",\n",
       " 'Betsy cannot pick up Johnny today',\n",
       " 'Greg needs to find a solution to pick up Johnny']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "gpt_model_atomic = GPTInference()\n",
    "texts = get_atomic_facts_gpt(gpt_model_atomic, dlg, 'dialogue')\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb975a5-c203-481d-8f4a-75a17aa87037",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evsum_newhf",
   "language": "python",
   "name": "evsum_newhf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
