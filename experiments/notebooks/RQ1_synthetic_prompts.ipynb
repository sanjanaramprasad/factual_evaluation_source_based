{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e94ccb-d62b-4e55-9539-fd76d4c39c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 13:09:48.829732: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-13 13:09:49.616536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference\n",
    "import spacy\n",
    "import re, string\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365e5a27-2af7-4514-b23f-445508c2dcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Model</th>\n",
       "      <th>Summary</th>\n",
       "      <th>w/ Error</th>\n",
       "      <th>CorefE</th>\n",
       "      <th>CorefE_text</th>\n",
       "      <th>CircE</th>\n",
       "      <th>CircE_text</th>\n",
       "      <th>...</th>\n",
       "      <th>GramE_text</th>\n",
       "      <th>PredE</th>\n",
       "      <th>PredE_text</th>\n",
       "      <th>SubjObjE</th>\n",
       "      <th>SubjObjE_text</th>\n",
       "      <th>OtherE</th>\n",
       "      <th>OtherE_text</th>\n",
       "      <th>LinkE</th>\n",
       "      <th>LinkE_text</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>human_ref</td>\n",
       "      <td>Louisa will lend Thelma her red velvet dress.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>bart_large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>mv-bart_large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>co-ref bart large</td>\n",
       "      <td>Thelma doesn't have anything to wear. Louisa w...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13809941</td>\n",
       "      <td>Thelma: i dont have anything to wear\\nLouisa: ...</td>\n",
       "      <td>condigsum bart large</td>\n",
       "      <td>Louisa will bring Thelma her red velvet dress.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FacEval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     DocID                                           Dialogue  \\\n",
       "0           0  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "1           1  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "2           2  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "3           3  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "4           4  13809941  Thelma: i dont have anything to wear\\nLouisa: ...   \n",
       "\n",
       "                  Model                                            Summary  \\\n",
       "0             human_ref      Louisa will lend Thelma her red velvet dress.   \n",
       "1            bart_large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "2         mv-bart_large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "3     co-ref bart large  Thelma doesn't have anything to wear. Louisa w...   \n",
       "4  condigsum bart large     Louisa will bring Thelma her red velvet dress.   \n",
       "\n",
       "   w/ Error  CorefE CorefE_text  CircE CircE_text  ...  GramE_text PredE  \\\n",
       "0         0     NaN         NaN    NaN        NaN  ...         NaN   NaN   \n",
       "1         0     NaN         NaN    NaN        NaN  ...         NaN   NaN   \n",
       "2         0     NaN         NaN    NaN        NaN  ...         NaN   NaN   \n",
       "3         0     NaN         NaN    NaN        NaN  ...         NaN   NaN   \n",
       "4         0     NaN         NaN    NaN        NaN  ...         NaN   NaN   \n",
       "\n",
       "   PredE_text SubjObjE  SubjObjE_text OtherE  OtherE_text LinkE  LinkE_text  \\\n",
       "0         NaN      NaN            NaN    0.0          NaN   NaN         NaN   \n",
       "1         NaN      NaN            NaN    0.0          NaN   NaN         NaN   \n",
       "2         NaN      NaN            NaN    0.0          NaN   NaN         NaN   \n",
       "3         NaN      NaN            NaN    0.0          NaN   NaN         NaN   \n",
       "4         NaN      NaN            NaN    0.0          NaN   NaN         NaN   \n",
       "\n",
       "    origin  \n",
       "0  FacEval  \n",
       "1  FacEval  \n",
       "2  FacEval  \n",
       "3  FacEval  \n",
       "4  FacEval  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_aggrefact.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a88d007-463d-4b90-920f-05cdd72fb3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>docid</th>\n",
       "      <th>model</th>\n",
       "      <th>nonfactual_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>3cc5013c-4080-413e-aa5f-aec0dc93e349</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13681870</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miley expresses her fatigue and lack of desire...</td>\n",
       "      <td>Miley: don''t want to go to work tomorrow!\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>c094b128-08b6-4187-91cf-c44d9ab25baa</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13681871</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andy informs Sue that he will be working late ...</td>\n",
       "      <td>Andy: Working late til 4 xx\\r\\nSue: no worries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>149452c6-bf79-47b0-b0ee-ecfcf99caa7f</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13681429</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cass confirmed with Jordan that he received hi...</td>\n",
       "      <td>Cass: Hi darling, did you get your birthday ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>a8c98d99-c964-46d0-a51c-bca6569900c1</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13681439</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phoebe can''t go out because her mother is ang...</td>\n",
       "      <td>Phil: can you go out today?\\r\\nPhoebe: no\\r\\nP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>48d59334-9492-4cc1-a5ce-1b0378e34a1f</td>\n",
       "      <td>sanjana</td>\n",
       "      <td>13681441</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joanna shares with Merve that their mutual acq...</td>\n",
       "      <td>Joanna: They are sending emails about Lewandow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid  user_id     docid  \\\n",
       "0          16  3cc5013c-4080-413e-aa5f-aec0dc93e349  sanjana  13681870   \n",
       "1          27  c094b128-08b6-4187-91cf-c44d9ab25baa  sanjana  13681871   \n",
       "2          32  149452c6-bf79-47b0-b0ee-ecfcf99caa7f  sanjana  13681429   \n",
       "3          34  a8c98d99-c964-46d0-a51c-bca6569900c1  sanjana  13681439   \n",
       "4          36  48d59334-9492-4cc1-a5ce-1b0378e34a1f  sanjana  13681441   \n",
       "\n",
       "           model nonfactual_spans evidence error_type  \\\n",
       "0  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "1  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "2  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "3  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "4  gpt4-32k-0613              NaN      NaN        NaN   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Miley expresses her fatigue and lack of desire...   \n",
       "1  Andy informs Sue that he will be working late ...   \n",
       "2  Cass confirmed with Jordan that he received hi...   \n",
       "3  Phoebe can''t go out because her mother is ang...   \n",
       "4  Joanna shares with Merve that their mutual acq...   \n",
       "\n",
       "                                            dialogue  \n",
       "0  Miley: don''t want to go to work tomorrow!\\r\\n...  \n",
       "1  Andy: Working late til 4 xx\\r\\nSue: no worries...  \n",
       "2  Cass: Hi darling, did you get your birthday ca...  \n",
       "3  Phil: can you go out today?\\r\\nPhoebe: no\\r\\nP...  \n",
       "4  Joanna: They are sending emails about Lewandow...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/llm_annotations/sample/sample_annotations_sanjana.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa768183-52b4-4edb-b717-fbd56b3b0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['origin'] != 'RefMatters_DialogSu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4cf55b-209e-4c36-bba3-c0feabb490b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_atomic_facts_gpt(gpt_model_atomic, text, text_type):\n",
    "    instr = f'Segment the following {text_type} into important facts without introducing any unsupported information'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt)\n",
    "    return gpt_response\n",
    "\n",
    "def mask_all_errtypes(text):\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "            # print(idx, origin_tokens)\n",
    "            # masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            # masked_text = ' '.join(masked_text)\n",
    "            # print(masked_text)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            \n",
    "        elif 'VERB' == token.pos_:\n",
    "            append = True \n",
    "            token_type = 'predicate'\n",
    "\n",
    "        elif 'ADV' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'ADP' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'PRON' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'coreference'\n",
    "\n",
    "        \n",
    "\n",
    "        if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "    # print([])\n",
    "    # print(mask_tokens)  \n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7220bacd-258d-44c6-96ed-96655ae0df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicate_answer(gpt_model_corruptor, dlg, atomic_facts, summary, answer):\n",
    "    instruction_verb = f'List alternative words or phrases to \"{answer}\" can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue.'\n",
    "    instruction_tense = f'List different tenses of verbs or phrases of the word {answer} that can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "    instruction_negation = f\"List words or phrases that negate {answer} and can be used to fill in the <BLANK> in the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.\"\n",
    "    answer_all = []\n",
    "    \n",
    "    prompt_template_verb = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction_verb}\\nAnswer:'\n",
    "    answer_verb = gpt_model_corruptor.get_chatgpt_response(prompt_template_verb)\n",
    "    # print('ANSWER VERB', answer_verb)\n",
    "    if len(answer_verb.split(',')) == 1:\n",
    "        answer_all += answer_verb.split('\\n')\n",
    "    else:\n",
    "        answer_all += answer_verb.split(',')\n",
    "    \n",
    "    \n",
    "    prompt_template_tense  = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction_tense}\\nAnswer:'\n",
    "    answer_tense = gpt_model_corruptor.get_chatgpt_response(prompt_template_tense)\n",
    "    # print('ANSWER TENSE', answer_tense)\n",
    "    if len(answer_tense.split(',')) == 1:\n",
    "        answer_all += answer_tense.split('\\n')\n",
    "    else:\n",
    "        answer_all += answer_tense.split(',')\n",
    "    \n",
    "    prompt_template_negation = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction_negation}\\nAnswer:'\n",
    "    answer_negation = gpt_model_corruptor.get_chatgpt_response(prompt_template_negation)\n",
    "    # print('ANSWER NEGATION', answer_negation)\n",
    "    if len(answer_negation.split(',')) == 1:\n",
    "        answer_all += answer_negation.split('\\n')\n",
    "    else:\n",
    "        answer_all += answer_negation.split(',')\n",
    "        \n",
    "    answer_all = ','.join(answer_all)\n",
    "    return answer_all\n",
    "\n",
    "\n",
    "def get_generic_answer(gpt_model_corruptor, dlg, atomic_facts, summary, answer):\n",
    "    instruction = f'List alternative words or phrases to \"{answer}\" can be used to fill in the <BLANK> of the summary that would make the summary inconsistent or misleading with respect to the dialogue or facts.'\n",
    "    prompt_template = f'Dialogue: {dlg}\\nFacts: {atomic_facts}\\nSummary: {summary}\\n{instruction}\\nAnswer:'\n",
    "    answer = gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "    if len(answer.split(',')) == 1:\n",
    "        answer = ','.join(answer.split('\\n'))\n",
    "    \n",
    "    return answer\n",
    "    \n",
    "def check_sentence_validity(gpt_model_sentence_checker, text):\n",
    "    instruction = \"Correct words in the sentence that are grammatically  wrong for the sentence\"\n",
    "    prompt_template = f'{instruction}\\nSummary: {text}\\nCorrected Summary:'\n",
    "    answer = gpt_model_sentence_checker.get_chatgpt_response(prompt_template)\n",
    "    return answer\n",
    "\n",
    "def check_entailment(gpt_model_nli, dlg, atomic_facts, text):\n",
    "    instruction = \"Does the dialogue or facts entail the sentence?\"\n",
    "    prompt_template = f'{instruction}\\nDialogue: {dlg}\\nFacts: {atomic_facts}\\nSentence: {text}\\nAnswer(yes or no):'\n",
    "    answer = gpt_model_nli.get_chatgpt_response(prompt_template)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4860d2-5f75-48be-8d29-74c80f242ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sanjana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def make_corrupted_summary(gpt_model_corruptor, dlg, atomic_fact_blank, answer, err_type, facts):\n",
    "    corrupted_err_type = []\n",
    "    # for blanked_text, answer, err_type in text_blanks:\n",
    "        # if err_type == 'subjobj':\n",
    "        #     corrupted_answer = get_generic_answer(gpt_model_corruptor, dlg, facts, blanked_text, answer)\n",
    "        #     # print(blanked_text, err_type)\n",
    "        #     # print(answer)\n",
    "        #     # print(corrupted_answer)\n",
    "        #     # print('====')\n",
    "    if err_type == 'predicate':\n",
    "            corrupted_answer = get_predicate_answer(gpt_model_corruptor, dlg, facts, atomic_fact_blank, answer)\n",
    "            # print(atomic_fact_blank, err_type)\n",
    "            # print(answer)\n",
    "            # print(corrupted_answer)\n",
    "            # print('====')\n",
    "        \n",
    "    else:\n",
    "        corrupted_answer = get_generic_answer(gpt_model_corruptor, dlg, facts, atomic_fact_blank, answer)\n",
    "    \n",
    "        \n",
    "    options = corrupted_answer.split(',') \n",
    "    # if len(options) == 1:\n",
    "    #     options = corrupted_answer.split('\\n')\n",
    "    options = sample(options, 8) if len(options) >= 8 else options\n",
    "    options = [re.sub('[1-9]', '', each) for each in options]\n",
    "    # print('OPTIONS', options)\n",
    "    corrupted_facts = []\n",
    "    for option in options:\n",
    "            corrupted_summary = atomic_fact_blank.replace('<BLANK>', option.strip())\n",
    "            corrected_summary = check_sentence_validity(gpt_model_sentence_checker, corrupted_summary)\n",
    "            \n",
    "            corrected_summary = [each.strip(string.punctuation) for each in corrected_summary.split(' ') ]\n",
    "            # corrected_summary = [each for each in corrected_summary if not each.isdigit()]\n",
    "            corrupted_summary = [each.strip(string.punctuation) for each in corrupted_summary.split(' ')]\n",
    "            # corrupted_summary = [each for each in corrupted_summary if not each.isdigit()]\n",
    "            \n",
    "            # word_constraints = [each for each in atomic_fact_blank.split(' ') if each != '<BLANK>' and each not in stop_words]\n",
    "            # constrain_overlap = set(word_constraints) - set(corrected_summary)\n",
    "            replaced_word = ' '.join([each for each in corrected_summary if each.strip(string.punctuation).lower() not in atomic_fact_blank.lower()])\n",
    "    \n",
    "            corrected_summary = ' '.join(corrected_summary)\n",
    "            corrupted_summary = ' '.join(corrupted_summary)\n",
    "            # print(corrected_summary)\n",
    "            # if replaced_word: \n",
    "            entailment = check_entailment(gpt_model_nli, dlg, facts, corrected_summary)\n",
    "                \n",
    "            # print(corrected_summary, entailment)\n",
    "            # print(replaced_word)\n",
    "            # print('----')\n",
    "            if entailment == 'no' and replaced_word in corrected_summary:\n",
    "                    # if err_type not in corrupted_err_type:\n",
    "                    #     corrupted_err_type[err_type] = []\n",
    "                    corrupted_err_type += [(corrected_summary, replaced_word)]\n",
    "    return corrupted_err_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1eb60c-625f-44a6-b9e5-186cea196001",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model_corruptor = GPTInference()\n",
    "gpt_model_sentence_checker = GPTInference()\n",
    "gpt_model_atomic = GPTInference()\n",
    "gpt_model_nli = GPTInference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ca2c45-f2fe-4a59-9f7a-f76b5aa8c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import nltk\n",
    "def get_atomic_facts_gpt(gpt_model_atomic, model, text, text_type):\n",
    "    instr = f'Write the {text_type} into indirect speech without introducing any unsupported information or inferences'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt, model = model)\n",
    "    # print(nltk.sent_tokenize(gpt_response))\n",
    "    return gpt_response\n",
    "    \n",
    "class SyntheticPrompt:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gpt_model_corruptor = GPTInference()\n",
    "        self.gpt_model_sentence_checker = GPTInference()\n",
    "        self.gpt_model_atomic = GPTInference()\n",
    "        self.gpt_model_nli = GPTInference()\n",
    "\n",
    "    def get_atomic_facts(self, gpt_model_type, dlg):\n",
    "        atomic_facts = get_atomic_facts_gpt(self.gpt_model_atomic, gpt_model_type, dlg, 'dialogue')\n",
    "        atomic_facts = nltk.sent_tokenize(atomic_facts)\n",
    "        atomic_facts = [re.sub('[1-9]', '', each) for each in atomic_facts]\n",
    "        atomic_facts = [each.strip(string.punctuation).strip() for each in atomic_facts]\n",
    "        return atomic_facts\n",
    "\n",
    "    def make_masked_sentences(self, atomic_facts):\n",
    "        masked_atomic_facts_map = {}\n",
    "        for atomic_fact in atomic_facts:\n",
    "            masked_results = mask_all_errtypes(atomic_fact)\n",
    "            for sent, ans, err_type in masked_results:\n",
    "                if err_type not in masked_atomic_facts_map:\n",
    "                    masked_atomic_facts_map[err_type] = []\n",
    "                masked_atomic_facts_map[err_type].append((atomic_fact, sent, ans, err_type))\n",
    "\n",
    "        return masked_atomic_facts_map\n",
    "\n",
    "    def get_corrupted_sent_spans(self, dlg, atomic_facts, sample_facts):\n",
    "        atomic_fact_map = {}\n",
    "        facts = '\\n'.join(atomic_facts)\n",
    "        # print('SAMPLE', sample_facts)\n",
    "        for atomic_fact, atomic_fact_blank, answer, err_type in sample_facts:\n",
    "            print(err_type)\n",
    "            atomic_fact_corrupted = make_corrupted_summary(self.gpt_model_corruptor, \n",
    "                                                               dlg, \n",
    "                                                               atomic_fact_blank, \n",
    "                                                               answer, \n",
    "                                                               err_type, \n",
    "                                                               facts)\n",
    "            # print(atomic_fact_corrupted)\n",
    "            # print('======')\n",
    "            if atomic_fact not in atomic_fact_map:\n",
    "                atomic_fact_map[atomic_fact] = {}\n",
    "                \n",
    "            for corrupted_summary, replaced_span in atomic_fact_corrupted:\n",
    "                if err_type not in atomic_fact_map[atomic_fact]:\n",
    "                    atomic_fact_map[atomic_fact][err_type] = []\n",
    "                atomic_fact_map[atomic_fact][err_type] += [(corrupted_summary, replaced_span)]\n",
    "        return atomic_fact_map\n",
    "\n",
    "    def get_single_err_samples(self, num_single_err_samples, atomic_fact_map, facts_list):\n",
    "        corrupted_summ_sent_spans = []\n",
    "        all_summary_sents = list(atomic_fact_map.keys())\n",
    "        num_single_err_samples = num_single_err_samples if len(all_summary_sents) >= num_single_err_samples else len(all_summary_sents)\n",
    "        picked_sents = sample(all_summary_sents, num_single_err_samples)\n",
    "        shortlisted_err_types = []\n",
    "        for picked_sent in picked_sents:\n",
    "            picked_sent_idx = facts_list.index(picked_sent)\n",
    "            for k , v in atomic_fact_map[picked_sent].items():\n",
    "                if k not in shortlisted_err_types:\n",
    "                    corrupted_pick_sent_span = sample(v, 1)[0]\n",
    "                    corrupted_summary = facts_list[:picked_sent_idx] + [corrupted_pick_sent_span[0]] + facts_list[picked_sent_idx + 1:]\n",
    "                    corrupted_summ_sent_spans.append(('. '.join(corrupted_summary), \n",
    "                                                  [(corrupted_pick_sent_span[0], \n",
    "                                                  corrupted_pick_sent_span[1])]))\n",
    "                    shortlisted_err_types.append(k)\n",
    "        return corrupted_summ_sent_spans\n",
    "\n",
    "    def make_single_error_samples(self, dlg, summary, num_samples = 4):\n",
    "        atomic_facts_models = ['gpt-4-32k-0613', 'gpt-3.5-turbo-16k-0613', 'gpt-4-32k-0314']\n",
    "        corrupted_summ_sent_spans = []\n",
    "        for gpt_model_type in atomic_facts_models[:1]:\n",
    "            atomic_facts = self.get_atomic_facts(gpt_model_type, dlg)\n",
    "            print(gpt_model_type, atomic_facts)\n",
    "            masked_atomic_facts_map = self.make_masked_sentences(atomic_facts)\n",
    "            # print(masked_atomic_facts_map)\n",
    "            sample_facts = []\n",
    "            for k , v in masked_atomic_facts_map.items():\n",
    "                num_samples = 2 if len(v) >=2 else len(v)\n",
    "                sample_facts += sample(v, num_samples)\n",
    "\n",
    "            print('SAMPLE', sample_facts)\n",
    "            print('***'*13)\n",
    "            atomic_fact_map = self.get_corrupted_sent_spans(dlg, atomic_facts, sample_facts)\n",
    "            \n",
    "            instruction = \"Append 1-2 words or a phrase to the sentence with extra information\"\n",
    "            for atomic_fact in sample(atomic_facts, 2):\n",
    "                            # atomic_fact = atomic_fact.strip(string.punctuation)\n",
    "                            prompt_template = f'Sentence: {atomic_fact}\\n{instruction}\\n'\n",
    "                            gpt_summ = self.gpt_model_corruptor.get_chatgpt_response(prompt_template)\n",
    "                            gpt_summ = gpt_summ.strip(string.punctuation)\n",
    "                            picked_sent_idx = atomic_facts.index(atomic_fact)\n",
    "                            corrupted_summary = atomic_facts[:picked_sent_idx] + [gpt_summ] + atomic_facts[picked_sent_idx + 1:]\n",
    "                            atomic_fact = atomic_fact.strip(string.punctuation)\n",
    "                            added_span = ' '.join([each for each in gpt_summ.split(' ') if each.strip(string.punctuation).lower() not in atomic_fact.lower()])\n",
    "                            corrupted_summ_sent_spans.append((('. '.join(corrupted_summary)),\n",
    "                                                                     [(gpt_summ, added_span)]))\n",
    "                            print(\"OOE\", (('. '.join(corrupted_summary)),\n",
    "                                                                     [(gpt_summ, added_span)]))\n",
    "            corrupted_summ_sent_spans += self.get_single_err_samples(5, atomic_fact_map, atomic_facts)\n",
    "        \n",
    "        return corrupted_summ_sent_spans\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3899884d-cac5-47c9-ac1f-754e37b97fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julie: hey guys... could you just talk to me for a bit? I just watched this Japanese horror movie and I''m home alone and a little uneasy (aka scared shitless)\n",
      "Rose: Jesus, why on earth would you watch a Japanese horror, home alone at this hour?\n",
      "Julie: Cause I''m a fucking moron?\n",
      "Rose: Cause you''re a fuckin moron. \n",
      "Paula: 5 point for Gryffindor, my friend. But in your defense, I always thought you were quite unaffected by horror movies.\n",
      "Julie: That''s what I thought too!\n",
      "Paula: So what kinda movie was it?\n",
      "Julie: <file_other>\n",
      "Rose: seems pretty generic\n",
      "Julie: It''s scarier than it looks.\n",
      "Rose: you know that japanese horror are the worst ones, right?\n",
      "Julie: I know that now.\n",
      "Paula: If... you want me to come over I can.\n",
      "Julie: omg really? <3\n",
      "Paula: Yeah, sure, it''s like 20 minutes by bike to your house, we can drink cocoa and watch \"when harry met Sally\" until we fall asleep ;)\n",
      "Julie: Omg Thank you so much, I love you!\n",
      "Rose: I wish I lived in your neighborhood :(\n",
      "Paula: We can chip in for an Uber for you :D\n",
      "Julie: Let''s have a spontaneous sleepover :D\n",
      "Rose: Oh, man it''s late, but why the hell not.\n",
      "Rose: I''ll bring cookies for the cocoa :D\n",
      "Julie: yay :D\n",
      "After watching a Japanese horror movie late at night while home alone, Julie is left feeling scared and reaches out to her friends Rose and Paula for comfort. Rose criticizes Julie for watching a horror movie alone, despite being aware of their intensity. Paula offers to come over to Julie''s house to keep her company, suggesting they watch a non-scary movie and have some cocoa. Julie expresses gratitude and invites Rose over as well for a spontaneous sleepover. Despite the late hour, Rose agrees to come, promising to bring cookies.\n",
      "a non-scary movie\n"
     ]
    }
   ],
   "source": [
    "# row = df[~df['nonfactual_spans'].isnull()].sample(1)\n",
    "row = df.iloc[[166]]\n",
    "print(row['dialogue'].values[0])\n",
    "print(row['summary'].values[0])\n",
    "print(row['nonfactual_spans'].values[0])\n",
    "text = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4c90ff-4f6c-4633-bdbf-8b093056f135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['nonfactual_spans'].isnull()]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ac1f0f58-b1c2-4808-baba-6656eaf7c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the dialogue into indirect speech without introducing any unsupported information or inferences\n",
      "Dialogue: Eric: MACHINE!\n",
      "Rob: That''s so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it''s really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I''ll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I''ll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "gpt-4-32k-0613 ['Eric called out \"MACHINE', 'and Rob agreed enthusiastically that it was great', 'Eric acknowledged this agreement by explaining that it reflects how Americans perceive Russians', 'Rob echoed this sentiment, finding the whole thing quite amusing', 'Eric agreed, and expressed a particular fondness for the part with the train', 'Rob laughed and commented that no one communicates with the machine the way it was shown', 'Eric then asked if this was the only stand-up performance of this kind', \"Rob admitted he wasn't sure but promised to check\", 'He later confirmed that there were more stand-up performances by the same performer available on YouTube', 'Eric was excited to hear this and said he would watch them immediately', 'Rob agreed to do the same', 'Both exchanged a mutual cheer of \"MACHINE', 'before Eric suggested they should talk later, to which Rob agreed']\n",
      "SAMPLE [('Rob agreed to do the same', 'Rob agreed to do the <BLANK>', 'same', 'subjobj'), ('Eric agreed, and expressed a particular fondness for the part with the train', '<BLANK> agreed , and expressed a particular fondness for the part with the train', 'Eric', 'subjobj'), ('He later confirmed that there were more stand-up performances by the same performer available on YouTube', 'He later confirmed that there were more <BLANK> - up performances by the same performer available on YouTube', 'stand', 'predicate'), (\"Rob admitted he wasn't sure but promised to check\", \"Rob admitted he was n't sure but promised to <BLANK>\", 'check', 'predicate'), ('He later confirmed that there were more stand-up performances by the same performer available on YouTube', 'He later confirmed that there were more stand - up performances by the same performer available <BLANK> YouTube', 'on', 'circumstance'), ('Eric was excited to hear this and said he would watch them immediately', 'Eric was excited to hear this and said he would watch them <BLANK>', 'immediately', 'circumstance'), ('He later confirmed that there were more stand-up performances by the same performer available on YouTube', 'He later confirmed that <BLANK> were more stand - up performances by the same performer available on YouTube', 'there', 'coreference')]\n",
      "***************************************\n",
      "subjobj\n",
      "subjobj\n",
      "predicate\n",
      "predicate\n",
      "circumstance\n",
      "circumstance\n",
      "coreference\n",
      "OOE ('Eric called out \"MACHINE. and Rob agreed enthusiastically that it was great. Eric acknowledged this agreement by explaining that it reflects how Americans perceive Russians. Rob echoed this sentiment, finding the whole thing quite amusing despite the seriousness of the situation. Eric agreed, and expressed a particular fondness for the part with the train. Rob laughed and commented that no one communicates with the machine the way it was shown. Eric then asked if this was the only stand-up performance of this kind. Rob admitted he wasn\\'t sure but promised to check. He later confirmed that there were more stand-up performances by the same performer available on YouTube. Eric was excited to hear this and said he would watch them immediately. Rob agreed to do the same. Both exchanged a mutual cheer of \"MACHINE. before Eric suggested they should talk later, to which Rob agreed', [('Rob echoed this sentiment, finding the whole thing quite amusing despite the seriousness of the situation', 'despite seriousness of situation')])\n",
      "OOE ('Eric called out \"MACHINE. and Rob agreed enthusiastically that it was great. Eric acknowledged this agreement by explaining that it reflects how Americans perceive Russians. Rob echoed this sentiment, finding the whole thing quite amusing. Eric agreed, and expressed a particular fondness for the part with the train. Rob laughed and commented that no one communicates with the machine the way it was shown. Eric then asked if this was the only stand-up performance of this kind. Rob admitted he wasn\\'t sure but promised to check his work schedule. He later confirmed that there were more stand-up performances by the same performer available on YouTube. Eric was excited to hear this and said he would watch them immediately. Rob agreed to do the same. Both exchanged a mutual cheer of \"MACHINE. before Eric suggested they should talk later, to which Rob agreed', [(\"Rob admitted he wasn't sure but promised to check his work schedule\", 'his work schedule')])\n"
     ]
    }
   ],
   "source": [
    "text = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]\n",
    "synthetic_generator = SyntheticPrompt()\n",
    "corrupted_summ_sent_spans = synthetic_generator.make_single_error_samples(dlg, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "55a04907-2f98-4e90-ab7b-540dd829531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_examples = []\n",
    "for summ_spans in corrupted_summ_sent_spans:\n",
    "    list_errors = '\\n\\n'.join([f' { each[1]}' for each in summ_spans[1]])\n",
    "    ic_ex = f'Summary: {summ_spans[1][0][0],}\\nInconsistent sentence and span: {list_errors}'\n",
    "    # print(ic_ex)\n",
    "    ic_examples += [ic_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f3189926-0c4e-40fb-918c-959e42525cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Summary: ('Rob echoed this sentiment, finding the whole thing quite amusing despite the seriousness of the situation',)\\nInconsistent sentence and span:  despite seriousness of situation\",\n",
       " 'Summary: (\"Rob admitted he wasn\\'t sure but promised to check his work schedule\",)\\nInconsistent sentence and span:  his work schedule',\n",
       " \"Summary: ('The machine agreed and expressed a particular fondness for the part with the train',)\\nInconsistent sentence and span:  machine\",\n",
       " \"Summary: ('Eric was excited to hear this and said he would watch them annually',)\\nInconsistent sentence and span:  annually\",\n",
       " \"Summary: ('He later confirmed that more dance-up performances by the same performer were available on YouTube',)\\nInconsistent sentence and span:  dance-up\",\n",
       " \"Summary: ('He later confirmed that no other stand-up performances by the same performer were available on YouTube',)\\nInconsistent sentence and span:  no other stand-up\"]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6453906e-7a6c-453e-bd11-b764f5fb09cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the dialogue into indirect speech without introducing any unsupported information or inferences\n",
      "Dialogue: Eric: MACHINE!\n",
      "Rob: That''s so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it''s really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I''ll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I''ll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "Eric and Rob are discussing a stand-up comedy routine they both enjoyed, particularly a segment involving a train and a character referred to as MACHINE.\n",
      "ANSWER None\n",
      "They find humor in the exaggerated portrayal of a Russian character and decide to look up more of the comedian''s work on Youtube.\n",
      "ANSWER None\n",
      "They affirm their enjoyment by repeating the phrase \"MACHINE!\"\n",
      "ANSWER They affirm their enjoyment by repeating the phrase \"MACHINE!\"\n",
      "before signing off.\n",
      "ANSWER None\n"
     ]
    }
   ],
   "source": [
    "inconsistent_instruction = 'Find all spans in the summary that is inconsistent with the source. Note that consistency means all information in the summary is supported by the source.' \n",
    "ic_examples = '\\n'.join(ic_examples)\n",
    "# atomic_facts = self.get_atomic_facts('', dlg)\n",
    "atomic_facts = SyntheticPrompt().get_atomic_facts('gpt-4-32k-0613', dlg)\n",
    "atomic_facts = '. '.join(atomic_facts)\n",
    "for txt in nltk.sent_tokenize(text):\n",
    "    prompt_template = f'Source: {atomic_facts}\\n{inconsistent_instruction}\\n{ic_examples}\\nSummary: {txt}\\nInconsistent sentence/spans:'\n",
    "\n",
    "    # print(prompt_template)\n",
    "    print(txt)\n",
    "    print('ANSWER', GPTInference().get_chatgpt_response(prompt_template, model = \"gpt-4-32k-0613\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "93b7721b-7806-402c-913a-6195330e1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the dialogue into indirect speech without introducing any unsupported information or inferences\n",
      "Dialogue: Julie: hey guys... could you just talk to me for a bit? I just watched this Japanese horror movie and I''m home alone and a little uneasy (aka scared shitless)\n",
      "Rose: Jesus, why on earth would you watch a Japanese horror, home alone at this hour?\n",
      "Julie: Cause I''m a fucking moron?\n",
      "Rose: Cause you''re a fuckin moron. \n",
      "Paula: 5 point for Gryffindor, my friend. But in your defense, I always thought you were quite unaffected by horror movies.\n",
      "Julie: That''s what I thought too!\n",
      "Paula: So what kinda movie was it?\n",
      "Julie: <file_other>\n",
      "Rose: seems pretty generic\n",
      "Julie: It''s scarier than it looks.\n",
      "Rose: you know that japanese horror are the worst ones, right?\n",
      "Julie: I know that now.\n",
      "Paula: If... you want me to come over I can.\n",
      "Julie: omg really? <3\n",
      "Paula: Yeah, sure, it''s like 20 minutes by bike to your house, we can drink cocoa and watch \"when harry met Sally\" until we fall asleep ;)\n",
      "Julie: Omg Thank you so much, I love you!\n",
      "Rose: I wish I lived in your neighborhood :(\n",
      "Paula: We can chip in for an Uber for you :D\n",
      "Julie: Let''s have a spontaneous sleepover :D\n",
      "Rose: Oh, man it''s late, but why the hell not.\n",
      "Rose: I''ll bring cookies for the cocoa :D\n",
      "Julie: yay :D\n",
      "After watching a Japanese horror movie late at night while home alone, Julie is left feeling scared and reaches out to her friends Rose and Paula for comfort.\n",
      "ANSWER No inconsistent sentence/spans.\n",
      "==========================\n",
      "Rose criticizes Julie for watching a horror movie alone, despite being aware of their intensity.\n",
      "ANSWER Rose criticizes Julie for watching a horror movie alone, despite being aware of their intensity.\n",
      "==========================\n",
      "Paula offers to come over to Julie''s house to keep her company, suggesting they watch a non-scary movie and have some cocoa.\n",
      "ANSWER None\n",
      "==========================\n",
      "Julie expresses gratitude and invites Rose over as well for a spontaneous sleepover.\n",
      "ANSWER \"Julie expresses gratitude and invites Rose over as well for a spontaneous sleepover.\"\n",
      "==========================\n",
      "Despite the late hour, Rose agrees to come, promising to bring cookies.\n",
      "ANSWER None\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "inconsistent_instruction = 'Find spans in the summary that is inconsistent with the source. Note that consistency means all information in the summary is supported by the source.' \n",
    "# ic_examples = '\\n'.join(ic_examples)\n",
    "# atomic_facts = self.get_atomic_facts('', dlg)\n",
    "text = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]\n",
    "atomic_facts = SyntheticPrompt().get_atomic_facts('gpt-4-32k-0613', dlg)\n",
    "atomic_facts = '. '.join(atomic_facts)\n",
    "for txt in nltk.sent_tokenize(text):\n",
    "    prompt_template = f'Source: {atomic_facts}\\n{inconsistent_instruction}\\nSummary: {txt}\\nInconsistent sentence/spans:'\n",
    "\n",
    "    print(txt)\n",
    "    # print(prompt_template)\n",
    "    print('ANSWER', GPTInference().get_chatgpt_response(prompt_template, model = \"gpt-4-32k-0613\"))\n",
    "    print('==' * 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d3aa459a-9bbc-4192-bf9e-3214f653c40b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[375], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprompt\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "84f3a1ec-d516-4458-9be6-caa06194f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sent = \"They find humor in the exaggerated portrayal of a Russian <BLANK> and decide to look up more of the comedian''s work on Youtube.\"\n",
    "# List top 10 words to fill in the <BLANK>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "dc6f5a34-f5a3-4ae8-86a6-8b12614fd0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eric excitedly mentioned something called the \"machine\", to which Rob agreed was great. Eric then expressed his views that the machine shows how Americans perceive Russians, to which Rob added that he found the concept hilariously funny. Eric agreed again and added that he particularly enjoyed the part concerning the train. They both then laughed about how no one talks to the machine like that. Eric inquired if this machine was part of a stand-up, and Rob admitted his ignorance and promised to check. After checking, Rob informed Eric that there were indeed additional stand-ups available on YouTube. Thrilled, Eric declared he\\'d watch them right away, a sentiment Rob shared. They finished the conversation by repeating the word \"machine\" and agreed to talk at a later time'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "93520aca-94e2-43d3-84a5-c5c9694db827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "def logprob_to_prob(logprob: float) -> float:\n",
    "    return np.exp(logprob)\n",
    "    \n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=f\"Source:{dlg}Summary:{masked_sent}Complete the summary by filling in the blanks\",\n",
    "  max_tokens=100,\n",
    "  temperature=0,\n",
    "    logprobs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c312a595-a741-40a7-bbfb-05b84f58feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They find humor in the exaggerated portrayal of a Russian <BLANK> and decide to look up more of the comedian''s work on Youtube.\""
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d0d37cca-2991-4b25-8531-dd470bef92cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter 0.3657226206440408\n",
      "person 0.18828358911214307\n",
      "man 0.17113341876537475\n",
      "con 0.05134731151828027\n",
      "character 0.046407857101559105\n"
     ]
    }
   ],
   "source": [
    "for k , v in response['choices'][0]['logprobs']['top_logprobs'][1].items():\n",
    "    print(k, logprob_to_prob(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a217f9fd-66b7-4553-81bf-e8a0a53f18f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Julie had requested her friends to chat with her as she had just finished watching a Japanese horror movie and was home alone, feeling very frightened. Rose wondered why Julie would choose to watch such a movie so late at night while being by herself. Julie confessed she had been foolish to do so, and Rose agreed. Paula made a light-hearted reference to a popular fantasy series and defended Julie by stating she believed Julie was generally unphased by horror films. Julie admitted she had thought the same. In their conversation, Paula asked Julie about the kind of movie she had watched. Julie responded, and while Rose commented that it seemed rather standard, Julie maintained it was more terrifying than it appeared. Rose reminded Julie of the often intense nature of Japanese horror films, a fact Julie confessed she only now realized. Paula offered to cycle over to Julie's house, suggesting they drink cocoa and watch a more lighthearted movie until they fall asleep. Overjoyed, Julie expressed her gratitude and admitted she was very fond of Paula. Hearing this, Rose expressed longing to live closer to where they were. Paula proposed they all contribute towards Rose's Uber cost, enabling a spontaneous sleepover. Despite it being late, Rose agreed and decided to bring cookies to pair with the cocoa. Julie and her friends became excited at this arrangement\n",
      "Find spans in the summary that is inconsistent with the source. Note that consistency means all information in the summary is supported by the source.\n",
      "Summary: After watching a Japanese horror movie late at night while home alone, Julie is left feeling scared and reaches out to her friends Rose and Paula for comfort. Rose criticizes Julie for watching a horror movie alone, despite being aware of their intensity. Paula offers to come over to Julie''s house to keep her company, suggesting they watch a non-scary movie and have some cocoa. Julie expresses gratitude and invites Rose over as well for a spontaneous sleepover. Despite the late hour, Rose agrees to come, promising to bring cookies.\n",
      "Inconsistent sentence/spans:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Rose criticizes Julie for watching a horror movie alone, despite being aware of their intensity.\"'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent_instruction = 'Find spans in the summary that is inconsistent with the source. Note that consistency means all information in the summary is supported by the source.'\n",
    "ic_examples = '\\n'.join(ic_examples)\n",
    "\n",
    "prompt_template = f'Source: {atomic_facts}\\n{inconsistent_instruction}\\nSummary: {text}\\nInconsistent sentence/spans:'\n",
    "\n",
    "print(prompt_template)\n",
    "GPTInference().get_chatgpt_response(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25a27a69-e557-4ac5-8524-b936742e9285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"on their success tonight\"'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPTInference().get_chatgpt_response(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc50a920-107d-4832-843b-3f72672712f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Greg', 'subjobj'), (1, 'needs', 'predicate'), (3, 'stay', 'predicate'), (4, 'after', 'circumstance'), (5, 'hours', 'subjobj'), (6, 'at', 'circumstance'), (7, 'work', 'subjobj')]\n",
      "[(0, 'Betsy', 'subjobj'), (1, 'expresses', 'predicate'), (2, 'frustration', 'subjobj'), (3, 'at', 'circumstance'), (5, 'repeated', 'predicate'), (6, 'situation', 'subjobj')]\n",
      "[(0, 'Johnny', 'subjobj'), (1, 'needs', 'predicate'), (4, 'picked', 'predicate'), (5, 'up', 'circumstance'), (6, 'from', 'circumstance'), (7, 'kindergarten', 'subjobj')]\n",
      "[(0, 'Greg', 'subjobj'), (1, 'asks', 'predicate'), (2, 'Betsy', 'subjobj'), (4, 'she', 'subjobj'), (6, 'pick', 'predicate'), (7, 'up', 'circumstance'), (8, 'Johnny', 'subjobj')]\n",
      "[(0, 'Betsy', 'subjobj'), (3, 'pick', 'predicate'), (4, 'up', 'circumstance'), (5, 'Johnny', 'subjobj'), (7, 'she', 'subjobj'), (8, 'also', 'circumstance'), (9, 'needs', 'predicate'), (11, 'work', 'predicate')]\n",
      "[(0, 'Tuesdays', 'subjobj'), (2, 'designated', 'predicate'), (3, 'as', 'circumstance'), (6, 'days', 'subjobj'), (8, 'handle', 'predicate'), (10, 'pick', 'predicate'), (12, 'up', 'subjobj')]\n",
      "[(0, 'Greg', 'subjobj'), (1, 'agrees', 'predicate'), (3, 'find', 'predicate'), (5, 'solution', 'subjobj'), (6, 'for', 'circumstance'), (7, 'picking', 'predicate'), (8, 'up', 'circumstance'), (9, 'Johnny', 'subjobj')]\n"
     ]
    }
   ],
   "source": [
    "masked_atomic_facts_map = {}\n",
    "for atomic_fact in texts:\n",
    "    masked_results = mask_all_errtypes(atomic_fact)\n",
    "    for sent, ans, err_type in masked_results:\n",
    "        if err_type not in masked_atomic_facts_map:\n",
    "            masked_atomic_facts_map[err_type] = []\n",
    "        masked_atomic_facts_map[err_type].append((atomic_fact, sent, ans, err_type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "757687b2-b078-43e0-bd9a-953522be4184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subjobj': [('Greg needs to stay after hours at work',\n",
       "   '<BLANK> needs to stay after hours at work',\n",
       "   'Greg',\n",
       "   'subjobj'),\n",
       "  ('Greg needs to stay after hours at work',\n",
       "   'Greg needs to stay after <BLANK> at work',\n",
       "   'hours',\n",
       "   'subjobj'),\n",
       "  ('Greg needs to stay after hours at work',\n",
       "   'Greg needs to stay after hours at <BLANK>',\n",
       "   'work',\n",
       "   'subjobj'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   '<BLANK> expresses frustration at the repeated situation',\n",
       "   'Betsy',\n",
       "   'subjobj'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   'Betsy expresses <BLANK> at the repeated situation',\n",
       "   'frustration',\n",
       "   'subjobj'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   'Betsy expresses frustration at the repeated <BLANK>',\n",
       "   'situation',\n",
       "   'subjobj'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   '<BLANK> needs to be picked up from kindergarten',\n",
       "   'Johnny',\n",
       "   'subjobj'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   'Johnny needs to be picked up from <BLANK>',\n",
       "   'kindergarten',\n",
       "   'subjobj'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   '<BLANK> asks Betsy if she can pick up Johnny',\n",
       "   'Greg',\n",
       "   'subjobj'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg asks <BLANK> if she can pick up Johnny',\n",
       "   'Betsy',\n",
       "   'subjobj'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg asks Betsy if <BLANK> can pick up Johnny',\n",
       "   'she',\n",
       "   'subjobj'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg asks Betsy if she can pick up <BLANK>',\n",
       "   'Johnny',\n",
       "   'subjobj'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   '<BLANK> can not pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy',\n",
       "   'subjobj'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick up <BLANK> because she also needs to work long hours',\n",
       "   'Johnny',\n",
       "   'subjobj'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick up Johnny because <BLANK> also needs to work long hours',\n",
       "   'she',\n",
       "   'subjobj'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"<BLANK> are designated as Greg 's days to handle kindergarten pick - up\",\n",
       "   'Tuesdays',\n",
       "   'subjobj'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are designated as Greg 's <BLANK> to handle kindergarten pick - up\",\n",
       "   'days',\n",
       "   'subjobj'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are designated as Greg 's days to handle kindergarten pick - <BLANK>\",\n",
       "   'up',\n",
       "   'subjobj'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   '<BLANK> agrees to find a solution for picking up Johnny',\n",
       "   'Greg',\n",
       "   'subjobj'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to find a <BLANK> for picking up Johnny',\n",
       "   'solution',\n",
       "   'subjobj'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to find a solution for picking up <BLANK>',\n",
       "   'Johnny',\n",
       "   'subjobj')],\n",
       " 'predicate': [('Greg needs to stay after hours at work',\n",
       "   'Greg <BLANK> to stay after hours at work',\n",
       "   'needs',\n",
       "   'predicate'),\n",
       "  ('Greg needs to stay after hours at work',\n",
       "   'Greg needs to <BLANK> after hours at work',\n",
       "   'stay',\n",
       "   'predicate'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   'Betsy <BLANK> frustration at the repeated situation',\n",
       "   'expresses',\n",
       "   'predicate'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   'Betsy expresses frustration at the <BLANK> situation',\n",
       "   'repeated',\n",
       "   'predicate'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   'Johnny <BLANK> to be picked up from kindergarten',\n",
       "   'needs',\n",
       "   'predicate'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   'Johnny needs to be <BLANK> up from kindergarten',\n",
       "   'picked',\n",
       "   'predicate'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg <BLANK> Betsy if she can pick up Johnny',\n",
       "   'asks',\n",
       "   'predicate'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg asks Betsy if she can <BLANK> up Johnny',\n",
       "   'pick',\n",
       "   'predicate'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not <BLANK> up Johnny because she also needs to work long hours',\n",
       "   'pick',\n",
       "   'predicate'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick up Johnny because she also <BLANK> to work long hours',\n",
       "   'needs',\n",
       "   'predicate'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick up Johnny because she also needs to <BLANK> long hours',\n",
       "   'work',\n",
       "   'predicate'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are <BLANK> as Greg 's days to handle kindergarten pick - up\",\n",
       "   'designated',\n",
       "   'predicate'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are designated as Greg 's days to <BLANK> kindergarten pick - up\",\n",
       "   'handle',\n",
       "   'predicate'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are designated as Greg 's days to handle kindergarten <BLANK> - up\",\n",
       "   'pick',\n",
       "   'predicate'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg <BLANK> to find a solution for picking up Johnny',\n",
       "   'agrees',\n",
       "   'predicate'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to <BLANK> a solution for picking up Johnny',\n",
       "   'find',\n",
       "   'predicate'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to find a solution for <BLANK> up Johnny',\n",
       "   'picking',\n",
       "   'predicate')],\n",
       " 'circumstance': [('Greg needs to stay after hours at work',\n",
       "   'Greg needs to stay <BLANK> hours at work',\n",
       "   'after',\n",
       "   'circumstance'),\n",
       "  ('Greg needs to stay after hours at work',\n",
       "   'Greg needs to stay after hours <BLANK> work',\n",
       "   'at',\n",
       "   'circumstance'),\n",
       "  ('Betsy expresses frustration at the repeated situation',\n",
       "   'Betsy expresses frustration <BLANK> the repeated situation',\n",
       "   'at',\n",
       "   'circumstance'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   'Johnny needs to be picked <BLANK> from kindergarten',\n",
       "   'up',\n",
       "   'circumstance'),\n",
       "  ('Johnny needs to be picked up from kindergarten',\n",
       "   'Johnny needs to be picked up <BLANK> kindergarten',\n",
       "   'from',\n",
       "   'circumstance'),\n",
       "  ('Greg asks Betsy if she can pick up Johnny',\n",
       "   'Greg asks Betsy if she can pick <BLANK> Johnny',\n",
       "   'up',\n",
       "   'circumstance'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick <BLANK> Johnny because she also needs to work long hours',\n",
       "   'up',\n",
       "   'circumstance'),\n",
       "  ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "   'Betsy can not pick up Johnny because she <BLANK> needs to work long hours',\n",
       "   'also',\n",
       "   'circumstance'),\n",
       "  (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "   \"Tuesdays are designated <BLANK> Greg 's days to handle kindergarten pick - up\",\n",
       "   'as',\n",
       "   'circumstance'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to find a solution <BLANK> picking up Johnny',\n",
       "   'for',\n",
       "   'circumstance'),\n",
       "  ('Greg agrees to find a solution for picking up Johnny',\n",
       "   'Greg agrees to find a solution for picking <BLANK> Johnny',\n",
       "   'up',\n",
       "   'circumstance')]}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_atomic_facts_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "71fed4d2-7f59-48f1-8067-57c273a4cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "sample_facts = []\n",
    "for k , v in masked_atomic_facts_map.items():\n",
    "    num_samples = 3 if len(v) >=3 else len(v)\n",
    "    sample_facts += sample(v, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ac557c62-883c-4247-a4d0-8a668ba0fe11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "  'Betsy can not pick up <BLANK> because she also needs to work long hours',\n",
       "  'Johnny',\n",
       "  'subjobj'),\n",
       " ('Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       "  'Betsy can not pick up Johnny because <BLANK> also needs to work long hours',\n",
       "  'she',\n",
       "  'subjobj'),\n",
       " (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "  \"<BLANK> are designated as Greg 's days to handle kindergarten pick - up\",\n",
       "  'Tuesdays',\n",
       "  'subjobj'),\n",
       " ('Johnny needs to be picked up from kindergarten',\n",
       "  'Johnny needs to be <BLANK> up from kindergarten',\n",
       "  'picked',\n",
       "  'predicate'),\n",
       " ('Greg agrees to find a solution for picking up Johnny',\n",
       "  'Greg agrees to find a solution for <BLANK> up Johnny',\n",
       "  'picking',\n",
       "  'predicate'),\n",
       " (\"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       "  \"Tuesdays are <BLANK> as Greg 's days to handle kindergarten pick - up\",\n",
       "  'designated',\n",
       "  'predicate'),\n",
       " ('Greg asks Betsy if she can pick up Johnny',\n",
       "  'Greg asks Betsy if she can pick <BLANK> Johnny',\n",
       "  'up',\n",
       "  'circumstance'),\n",
       " ('Betsy expresses frustration at the repeated situation',\n",
       "  'Betsy expresses frustration <BLANK> the repeated situation',\n",
       "  'at',\n",
       "  'circumstance'),\n",
       " ('Johnny needs to be picked up from kindergarten',\n",
       "  'Johnny needs to be picked <BLANK> from kindergarten',\n",
       "  'up',\n",
       "  'circumstance')]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f8da0582-83ac-427b-a1e2-8db49fa7e1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIONS ['1. groceries', '2. her sister', '3. the dry cleaning', '4. their dog', '5. dinner']\n",
      "Betsy can not pick up <BLANK> because she also needs to work long hours\n",
      "Betsy cannot pick up groceries because she also needs to work long hours no\n",
      "cannot groceries\n",
      "----\n",
      "Betsy can not pick up <BLANK> because she also needs to work long hours\n",
      "Betsy cannot pick up her sister because she also needs to work long hours no\n",
      "cannot her sister\n",
      "----\n",
      "Betsy can not pick up <BLANK> because she also needs to work long hours\n",
      "Betsy cannot pick up the dry cleaning because she also needs to work long hours no\n",
      "cannot the dry cleaning\n",
      "----\n",
      "Betsy can not pick up <BLANK> because she also needs to work long hours\n",
      "Betsy cannot pick up their dog because she also needs to work long hours no\n",
      "cannot their dog\n",
      "----\n",
      "Betsy can not pick up <BLANK> because she also needs to work long hours\n",
      "Betsy cannot pick up dinner because she also needs to work long hours no\n",
      "cannot dinner\n",
      "----\n",
      "subjobj [('Betsy cannot pick up groceries because she also needs to work long hours', 'cannot groceries'), ('Betsy cannot pick up her sister because she also needs to work long hours', 'cannot her sister'), ('Betsy cannot pick up the dry cleaning because she also needs to work long hours', 'cannot the dry cleaning'), ('Betsy cannot pick up their dog because she also needs to work long hours', 'cannot their dog'), ('Betsy cannot pick up dinner because she also needs to work long hours', 'cannot dinner')]\n",
      "*****\n",
      "OPTIONS ['Greg', ' Johnny', ' their neighbor', ' the babysitter', ' the teacher']\n",
      "Betsy can not pick up Johnny because <BLANK> also needs to work long hours\n",
      "Betsy cannot pick up Johnny because Greg also needs to work long hours no\n",
      "cannot Greg\n",
      "----\n",
      "Betsy can not pick up Johnny because <BLANK> also needs to work long hours\n",
      "Betsy cannot pick up Johnny because Johnny also needs to work long hours no\n",
      "cannot\n",
      "----\n",
      "Betsy can not pick up Johnny because <BLANK> also needs to work long hours\n",
      "Betsy cannot pick up Johnny because their neighbor also needs to work long hours no\n",
      "cannot their neighbor\n",
      "----\n",
      "Betsy can not pick up Johnny because <BLANK> also needs to work long hours\n",
      "Betsy cannot pick up Johnny because the babysitter also needs to work long hours no\n",
      "cannot the babysitter\n",
      "----\n",
      "Betsy can not pick up Johnny because <BLANK> also needs to work long hours\n",
      "Betsy cannot pick up Johnny because the teacher also needs to work long hours no\n",
      "cannot the teacher\n",
      "----\n",
      "subjobj [('Betsy cannot pick up Johnny because Greg also needs to work long hours', 'cannot Greg'), ('Betsy cannot pick up Johnny because Johnny also needs to work long hours', 'cannot'), ('Betsy cannot pick up Johnny because their neighbor also needs to work long hours', 'cannot their neighbor'), ('Betsy cannot pick up Johnny because the babysitter also needs to work long hours', 'cannot the babysitter'), ('Betsy cannot pick up Johnny because the teacher also needs to work long hours', 'cannot the teacher')]\n",
      "*****\n",
      "OPTIONS ['Mondays', ' Wednesdays', ' Thursdays', ' Fridays', ' weekends']\n",
      "subjobj []\n",
      "*****\n",
      "ANSWER VERB 1. dropped\n",
      "2. enrolled\n",
      "3. left\n",
      "4. signed\n",
      "5. ignored\n",
      "6. expelled\n",
      "7. forgotten\n",
      "ANSWER TENSE pick, picking, will pick, had picked, has picked\n",
      "ANSWER NEGATION dropped, left, forgotten, skipped, ignored, abandoned\n",
      "OPTIONS ['1. dropped', '2. enrolled', '3. left', '4. signed', '5. ignored', '6. expelled', '7. forgotten', 'pick', ' picking', ' will pick', ' had picked', ' has picked', 'dropped', ' left', ' forgotten', ' skipped', ' ignored', ' abandoned']\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be dropped off at kindergarten no\n",
      "dropped off at\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be enrolled in grade up from kindergarten no\n",
      "enrolled in grade\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten at yes\n",
      "picked at\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be signed up for kindergarten no\n",
      "signed for\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be moved up from kindergarten to grade no\n",
      "moved grade\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be expelled from kindergarten no\n",
      "expelled\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten at yes\n",
      "picked at\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "Johnny needs to be <BLANK> up from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "picked\n",
      "----\n",
      "predicate [('Johnny needs to be dropped off at kindergarten', 'dropped off at'), ('Johnny needs to be enrolled in grade up from kindergarten', 'enrolled in grade'), ('Johnny needs to be signed up for kindergarten', 'signed for'), ('Johnny needs to be moved up from kindergarten to grade', 'moved grade'), ('Johnny needs to be expelled from kindergarten', 'expelled')]\n",
      "*****\n",
      "ANSWER VERB 1. dropping\n",
      "2. signing\n",
      "3. giving\n",
      "4. leaving\n",
      "5. checking\n",
      "6. registering\n",
      "7. enrolling\n",
      "ANSWER TENSE 1. dropped\n",
      "2. not picking\n",
      "3. never picking\n",
      "4. leaving\n",
      "5. avoiding picking\n",
      "ANSWER NEGATION neglecting, skipping, avoiding, ignoring, forgetting, abandoning\n",
      "OPTIONS ['1. dropping', '2. signing', '3. giving', '4. leaving', '5. checking', '6. registering', '7. enrolling', '1. dropped', '2. not picking', '3. never picking', '4. leaving', '5. avoiding picking', 'neglecting', ' skipping', ' avoiding', ' ignoring', ' forgetting', ' abandoning']\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for dropping off Johnny no\n",
      "dropping off\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for signing up Johnny no\n",
      "signing\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for giving up Johnny no\n",
      "giving\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for leaving Johnny up at yes\n",
      "leaving at\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for checking up on Johnny yes\n",
      "checking on\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for registering Johnny up for no\n",
      "registering\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for enrolling Johnny in no\n",
      "enrolling in\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for Johnny who dropped out no\n",
      "who dropped out\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for not picking up Johnny no\n",
      "not picking\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for never picking up Johnny three times no\n",
      "never picking three times\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for leaving Johnny up yes\n",
      "leaving\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution to avoid picking up Johnny no\n",
      "avoid picking\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for making up to Johnny for neglecting him no\n",
      "making neglecting him\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for Johnny to skip up no\n",
      "skip\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for avoiding Johnny no\n",
      "avoiding\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for not ignoring Johnny yes\n",
      "not ignoring\n",
      "----\n",
      "Greg agrees to find a solution for <BLANK> up Johnny\n",
      "Greg agrees to find a solution for not abandoning Johnny yes\n",
      "not abandoning\n",
      "----\n",
      "predicate [('Greg agrees to find a solution for dropping off Johnny', 'dropping off'), ('Greg agrees to find a solution for signing up Johnny', 'signing'), ('Greg agrees to find a solution for giving up Johnny', 'giving'), ('Greg agrees to find a solution for registering Johnny up for', 'registering'), ('Greg agrees to find a solution for enrolling Johnny in', 'enrolling in'), ('Greg agrees to find a solution for Johnny who dropped out', 'who dropped out'), ('Greg agrees to find a solution for not picking up Johnny', 'not picking'), ('Greg agrees to find a solution for never picking up Johnny three times', 'never picking three times'), ('Greg agrees to find a solution to avoid picking up Johnny', 'avoid picking'), ('Greg agrees to find a solution for making up to Johnny for neglecting him', 'making neglecting him'), ('Greg agrees to find a solution for Johnny to skip up', 'skip'), ('Greg agrees to find a solution for avoiding Johnny', 'avoiding')]\n",
      "*****\n",
      "ANSWER VERB 1. unscheduled\n",
      "2. undefined\n",
      "3. avoided\n",
      "4. excluded\n",
      "5. disregarded\n",
      "ANSWER TENSE misassigned, ignored, avoided, neglected, skipped, mistaken, overruled\n",
      "ANSWER NEGATION excluded, avoided, skipped, disregarded, discarded, ignored, dismissed\n",
      "OPTIONS ['1. unscheduled', '2. undefined', '3. avoided', '4. excluded', '5. disregarded', 'misassigned', ' ignored', ' avoided', ' neglected', ' skipped', ' mistaken', ' overruled', 'excluded', ' avoided', ' skipped', ' disregarded', ' discarded', ' ignored', ' dismissed']\n",
      "predicate []\n",
      "*****\n",
      "OPTIONS ['1. on', '2. out', '3. apart', '4. away', '5. over']\n",
      "Greg asks Betsy if she can pick <BLANK> Johnny\n",
      "Greg asks Betsy if she can pick up Johnny yes\n",
      "up\n",
      "----\n",
      "Greg asks Betsy if she can pick <BLANK> Johnny\n",
      "Greg asks Betsy if she can pick Johnny out yes\n",
      "out\n",
      "----\n",
      "Greg asks Betsy if she can pick <BLANK> Johnny\n",
      "Greg asks Betsy if she can pick Johnny apart no\n",
      "apart\n",
      "----\n",
      "Greg asks Betsy if she can pick <BLANK> Johnny\n",
      "Greg asks Betsy if she can pick Johnny up at yes\n",
      "up at\n",
      "----\n",
      "Greg asks Betsy if she can pick <BLANK> Johnny\n",
      "Greg asks Betsy if she can pick over Johnny yes\n",
      "over\n",
      "----\n",
      "circumstance [('Greg asks Betsy if she can pick Johnny apart', 'apart')]\n",
      "*****\n",
      "OPTIONS ['1. Betsy expresses frustration before the repeated situation', '2. Betsy expresses frustration during the repeated situation', '3. Betsy expresses frustration due to the repeated situation', \"4. Betsy expresses frustration with Greg's response to the repeated situation\", '5. Betsy expresses frustration regarding the repeated situation but not because of it']\n",
      "Betsy expresses frustration <BLANK> the repeated situation\n",
      "Betsy expresses frustration before the repeated situation no\n",
      "before\n",
      "----\n",
      "Betsy expresses frustration <BLANK> the repeated situation\n",
      "Betsy expresses frustration during the repeated situation yes\n",
      "during\n",
      "----\n",
      "Betsy expresses frustration <BLANK> the repeated situation\n",
      "Betsy expresses frustration due to the repeated situation yes\n",
      "due to\n",
      "----\n",
      "Betsy expresses frustration <BLANK> the repeated situation\n",
      "Betsy expresses frustration with Greg's response to the repeated situation yes\n",
      "with Greg's response to\n",
      "----\n",
      "Betsy expresses frustration <BLANK> the repeated situation\n",
      "Betsy expresses frustration regarding the repeated situation but not because of the repeated situation itself no\n",
      "regarding but not because of itself\n",
      "----\n",
      "circumstance [('Betsy expresses frustration before the repeated situation', 'before'), ('Betsy expresses frustration regarding the repeated situation but not because of the repeated situation itself', 'regarding but not because of itself')]\n",
      "*****\n",
      "OPTIONS ['1. off', '2. out', '3. apart', '4. by', '5. over', '6. around']\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up from kindergarten at yes\n",
      "up at\n",
      "----\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up from kindergarten yes\n",
      "up\n",
      "----\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up at from kindergarten yes\n",
      "up at\n",
      "----\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up from kindergarten at yes\n",
      "up at\n",
      "----\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up from kindergarten at yes\n",
      "up at\n",
      "----\n",
      "Johnny needs to be picked <BLANK> from kindergarten\n",
      "Johnny needs to be picked up around from kindergarten yes\n",
      "up around\n",
      "----\n",
      "circumstance []\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "atomic_fact_map = {}\n",
    "facts = '\\n'.join(texts)\n",
    "for atomic_fact, atomic_fact_blank, answer, err_type in sample_facts:\n",
    "# for atomic_fact in texts:\n",
    "#     atomic_fact_blanks = mask_all_errtypes(atomic_fact)\n",
    "    atomic_fact_corrupted = make_corrupted_summary(gpt_model_corruptor, dlg, atomic_fact_blank, answer, err_type, facts)\n",
    "    print(err_type, atomic_fact_corrupted)\n",
    "    print('*****')\n",
    "    if atomic_fact not in atomic_fact_map:\n",
    "        atomic_fact_map[atomic_fact] = {}\n",
    "    \n",
    "    for corrupted_summary, replaced_span in atomic_fact_corrupted:\n",
    "        if err_type not in atomic_fact_map[atomic_fact]:\n",
    "            atomic_fact_map[atomic_fact][err_type] = []\n",
    "        atomic_fact_map[atomic_fact][err_type] += [(corrupted_summary, replaced_span)]\n",
    "    # atomic_fact_map[atomic_fact] += atomic_fact_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0279b595-abfa-4f28-8fa6-256d760050f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Betsy cannot pick up Johnny because she also needs to work long hours': {'subjobj': [('Betsy cannot pick up groceries because she also needs to work long hours',\n",
       "    'cannot groceries'),\n",
       "   ('Betsy cannot pick up her sister because she also needs to work long hours',\n",
       "    'cannot her sister'),\n",
       "   ('Betsy cannot pick up the dry cleaning because she also needs to work long hours',\n",
       "    'cannot the dry cleaning'),\n",
       "   ('Betsy cannot pick up their dog because she also needs to work long hours',\n",
       "    'cannot their dog'),\n",
       "   ('Betsy cannot pick up dinner because she also needs to work long hours',\n",
       "    'cannot dinner'),\n",
       "   ('Betsy cannot pick up Johnny because Greg also needs to work long hours',\n",
       "    'cannot Greg'),\n",
       "   ('Betsy cannot pick up Johnny because Johnny also needs to work long hours',\n",
       "    'cannot'),\n",
       "   ('Betsy cannot pick up Johnny because their neighbor also needs to work long hours',\n",
       "    'cannot their neighbor'),\n",
       "   ('Betsy cannot pick up Johnny because the babysitter also needs to work long hours',\n",
       "    'cannot the babysitter'),\n",
       "   ('Betsy cannot pick up Johnny because the teacher also needs to work long hours',\n",
       "    'cannot the teacher')]},\n",
       " \"Tuesdays are designated as Greg's days to handle kindergarten pick-up\": {},\n",
       " 'Johnny needs to be picked up from kindergarten': {'predicate': [('Johnny needs to be dropped off at kindergarten',\n",
       "    'dropped off at'),\n",
       "   ('Johnny needs to be enrolled in grade up from kindergarten',\n",
       "    'enrolled in grade'),\n",
       "   ('Johnny needs to be signed up for kindergarten', 'signed for'),\n",
       "   ('Johnny needs to be moved up from kindergarten to grade', 'moved grade'),\n",
       "   ('Johnny needs to be expelled from kindergarten', 'expelled')]},\n",
       " 'Greg agrees to find a solution for picking up Johnny': {'predicate': [('Greg agrees to find a solution for dropping off Johnny',\n",
       "    'dropping off'),\n",
       "   ('Greg agrees to find a solution for signing up Johnny', 'signing'),\n",
       "   ('Greg agrees to find a solution for giving up Johnny', 'giving'),\n",
       "   ('Greg agrees to find a solution for registering Johnny up for',\n",
       "    'registering'),\n",
       "   ('Greg agrees to find a solution for enrolling Johnny in', 'enrolling in'),\n",
       "   ('Greg agrees to find a solution for Johnny who dropped out',\n",
       "    'who dropped out'),\n",
       "   ('Greg agrees to find a solution for not picking up Johnny', 'not picking'),\n",
       "   ('Greg agrees to find a solution for never picking up Johnny three times',\n",
       "    'never picking three times'),\n",
       "   ('Greg agrees to find a solution to avoid picking up Johnny',\n",
       "    'avoid picking'),\n",
       "   ('Greg agrees to find a solution for making up to Johnny for neglecting him',\n",
       "    'making neglecting him'),\n",
       "   ('Greg agrees to find a solution for Johnny to skip up', 'skip'),\n",
       "   ('Greg agrees to find a solution for avoiding Johnny', 'avoiding')]},\n",
       " 'Greg asks Betsy if she can pick up Johnny': {'circumstance': [('Greg asks Betsy if she can pick Johnny apart',\n",
       "    'apart')]},\n",
       " 'Betsy expresses frustration at the repeated situation': {'circumstance': [('Betsy expresses frustration before the repeated situation',\n",
       "    'before'),\n",
       "   ('Betsy expresses frustration regarding the repeated situation but not because of the repeated situation itself',\n",
       "    'regarding but not because of itself')]}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_fact_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2acb0830-c812-40fc-82ce-433cbdde0463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Greg needs to stay after hours at work',\n",
       " 'Betsy expresses frustration at the repeated situation',\n",
       " 'Johnny needs to be picked up from kindergarten',\n",
       " 'Greg asks Betsy if she can pick up Johnny',\n",
       " 'Betsy cannot pick up Johnny because she also needs to work long hours',\n",
       " \"Tuesdays are designated as Greg's days to handle kindergarten pick-up\",\n",
       " 'Greg agrees to find a solution for picking up Johnny']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "09afc1f4-1615-437d-b31c-e455da037d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_single_err_samples = 1\n",
    "corrupted_summ_sent_spans = []\n",
    "all_summary_sents = list(atomic_fact_map.keys())\n",
    "picked_sents = sample(all_summary_sents, num_single_err_samples)\n",
    "for picked_sent in picked_sents:\n",
    "    picked_sent_idx = texts.index(picked_sent)\n",
    "    for k , v in atomic_fact_map[picked_sent].items():\n",
    "        corrupted_pick_sent_span = sample(v, 1)[0]\n",
    "        corrupted_summary = texts[:picked_sent_idx] + [corrupted_pick_sent_span[0]] + texts[picked_sent_idx + 1:]\n",
    "        corrupted_summ_sent_spans.append(('. '.join(corrupted_summary), \n",
    "                                              [(corrupted_pick_sent_span[0], \n",
    "                                              corrupted_pick_sent_span[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2f64362b-c2ac-44af-880c-a49ea270f89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Greg needs to stay after hours at work. Betsy expresses frustration at the repeated situation. Johnny needs to be picked up from kindergarten. Greg asks Betsy if she can pick up Johnny. Betsy cannot pick up Johnny because she also needs to work long hours. Tuesdays are designated as Greg's days to handle kindergarten pick-up. Greg agrees to find a solution for giving up Johnny\",\n",
       " [('Greg agrees to find a solution for giving up Johnny', 'giving')])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_summ_sent_spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e5ff40e3-e9eb-43dd-a098-136e94419003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicate': [('Their child Johnny needs to be dropped off at kindergarten',\n",
       "   'dropped off at'),\n",
       "  ('Their child Johnny needs to be moved up from kindergarten', 'moved'),\n",
       "  ('Their child Johnny needs to not be picked up from kindergarten',\n",
       "   'not picked')],\n",
       " 'coreference': [(\"Somebody else's child Johnny needs to be picked up from kindergarten\",\n",
       "   \"Somebody else's\"),\n",
       "  (\"An unrelated family's child Johnny needs to be picked up from kindergarten\",\n",
       "   \"An unrelated family's\")]}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_fact_map[picked_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "764b121a-d37a-4b72-a4a6-760eec9683ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def get_single_err_samples(num_single_err_samples, atomic_fact_map, facts_list):\n",
    "    corrupted_summ_sent_spans = []\n",
    "    all_summary_sents = list(atomic_fact_map.keys())\n",
    "    picked_sents = sample(all_summary_sents, num_single_err_samples)\n",
    "    for picked_sent in picked_sents:\n",
    "        picked_sent_idx = facts_list.index(picked_sent)\n",
    "        for k , v in atomic_fact_map[picked_sent].items():\n",
    "            corrupted_pick_sent_span = sample(v, 1)[0]\n",
    "            corrupted_summary = texts[:picked_sent_idx] + [corrupted_pick_sent_span[0]] + texts[picked_sent_idx + 1:]\n",
    "            corrupted_summ_sent_spans.append(('. '.join(corrupted_summary), \n",
    "                                              [(corrupted_pick_sent_span[0], \n",
    "                                              corrupted_pick_sent_span[1])]))\n",
    "    return corrupted_summ_sent_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7084280f-babb-464d-9a3f-9c5a1a094743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Greg needs to stay after hours at work. Betsy expresses frustration at the repeated situation. Johnny needs to be picked up from kindergarten. Greg asks Betsy if she can pick up Johnny. Betsy cannot pick up her sister because she also needs to work long hours. Tuesdays are designated as Greg's days to handle kindergarten pick-up. Greg agrees to find a solution for picking up Johnny\",\n",
       "  [('Betsy cannot pick up her sister because she also needs to work long hours',\n",
       "    'cannot her sister')]),\n",
       " (\"Greg needs to stay after hours at work. Betsy expresses frustration at the repeated situation. Johnny needs to be moved up from kindergarten to grade. Greg asks Betsy if she can pick up Johnny. Betsy cannot pick up Johnny because she also needs to work long hours. Tuesdays are designated as Greg's days to handle kindergarten pick-up. Greg agrees to find a solution for picking up Johnny\",\n",
       "  [('Johnny needs to be moved up from kindergarten to grade', 'moved grade')]),\n",
       " (\"Greg needs to stay after hours at work. Betsy expresses frustration at the repeated situation. Johnny needs to be picked up from kindergarten. Greg asks Betsy if she can pick Johnny apart. Betsy cannot pick up Johnny because she also needs to work long hours. Tuesdays are designated as Greg's days to handle kindergarten pick-up. Greg agrees to find a solution for picking up Johnny\",\n",
       "  [('Greg asks Betsy if she can pick Johnny apart', 'apart')])]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_single_err_samples(4, atomic_fact_map, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a0a82-0c93-4a9a-b870-c3a9ae25e161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
