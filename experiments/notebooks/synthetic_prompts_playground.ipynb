{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e91bb70c-23fc-4db4-87ef-227651b14dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GPTModel import GPTInference\n",
    "import spacy\n",
    "import re, string\n",
    "import nltk\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0b3fce5-95fb-4276-9859-4cb7c9d5089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mask_all_errtypes(text):\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            \n",
    "        elif 'VERB' == token.pos_:\n",
    "            append = True \n",
    "            token_type = 'predicate'\n",
    "\n",
    "        elif 'ADV' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'ADP' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'circumstance'\n",
    "\n",
    "        elif 'PRON' == token.pos_:\n",
    "            append = True\n",
    "            token_type = 'coreference'\n",
    "\n",
    "        \n",
    "\n",
    "        if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "    # print([])\n",
    "    # print(mask_tokens)  \n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results\n",
    "\n",
    "\n",
    "def make_masked_sentences(atomic_facts):\n",
    "        masked_atomic_facts_map = {}\n",
    "        for atomic_fact in atomic_facts:\n",
    "            masked_results = mask_all_errtypes(atomic_fact)\n",
    "            for sent, ans, err_type in masked_results:\n",
    "                if err_type not in masked_atomic_facts_map:\n",
    "                    masked_atomic_facts_map[err_type] = []\n",
    "                masked_atomic_facts_map[err_type].append((atomic_fact, sent, ans, err_type))\n",
    "            \n",
    "        return masked_atomic_facts_map\n",
    "\n",
    "\n",
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def make_corrupted_summary(gpt_model_corruptor, dlg, atomic_fact_blank, answer, err_type, facts):\n",
    "    corrupted_err_type = []\n",
    "    \n",
    "    if err_type == 'predicate':\n",
    "            corrupted_answer = get_predicate_answer(gpt_model_corruptor, dlg, facts, atomic_fact_blank, answer)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        corrupted_answer = get_generic_answer(gpt_model_corruptor, dlg, facts, atomic_fact_blank, answer)\n",
    "    \n",
    "        \n",
    "    options = corrupted_answer.split(',') \n",
    "    options = sample(options, 8) if len(options) >= 8 else options\n",
    "    options = [re.sub('[1-9]', '', each) for each in options]\n",
    "\n",
    "    corrupted_facts = []\n",
    "    for option in options:\n",
    "            corrupted_summary = atomic_fact_blank.replace('<BLANK>', option.strip())\n",
    "            corrected_summary = check_sentence_validity(gpt_model_sentence_checker, corrupted_summary)\n",
    "            \n",
    "            corrected_summary = [each.strip(string.punctuation) for each in corrected_summary.split(' ') ]\n",
    "            corrupted_summary = [each.strip(string.punctuation) for each in corrupted_summary.split(' ')]\n",
    "            \n",
    "            replaced_word = ' '.join([each for each in corrected_summary if each.strip(string.punctuation).lower() not in atomic_fact_blank.lower()])\n",
    "    \n",
    "            corrected_summary = ' '.join(corrected_summary)\n",
    "            corrupted_summary = ' '.join(corrupted_summary)\n",
    "           \n",
    "            entailment = check_entailment(gpt_model_nli, dlg, facts, corrected_summary)\n",
    "                \n",
    "           \n",
    "            if entailment == 'no' and replaced_word in corrected_summary:\n",
    "                    corrupted_err_type += [(corrected_summary, replaced_word)]\n",
    "    return corrupted_err_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2493bf82-ad15-4a69-a0b3-30e1aac055c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_atomic_facts_gpt(gpt_model_atomic, model, text, text_type):\n",
    "    instr = f'Convert the {text_type} into facts without adding any unsupported details.'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    print(prompt)\n",
    "    gpt_response = gpt_model_atomic.get_chatgpt_response(prompt, model = model)\n",
    "    # print(nltk.sent_tokenize(gpt_response))\n",
    "    return gpt_response\n",
    "    \n",
    "class SyntheticPrompt:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gpt_model_corruptor = GPTInference()\n",
    "        self.gpt_model_sentence_checker = GPTInference()\n",
    "        self.gpt_model_atomic = GPTInference()\n",
    "        self.gpt_model_nli = GPTInference()\n",
    "\n",
    "    def make_masked_sentences(self, atomic_facts):\n",
    "        masked_atomic_facts_map = {}\n",
    "        for atomic_fact in atomic_facts:\n",
    "            masked_results = mask_all_errtypes(atomic_fact)\n",
    "            for sent, ans, err_type in masked_results:\n",
    "                if err_type not in masked_atomic_facts_map:\n",
    "                    masked_atomic_facts_map[err_type] = []\n",
    "                masked_atomic_facts_map[err_type].append((atomic_fact, sent, ans, err_type))\n",
    "\n",
    "        return masked_atomic_facts_map\n",
    "\n",
    "    def get_atomic_facts(self, gpt_model_type, dlg):\n",
    "        atomic_facts = get_atomic_facts_gpt(self.gpt_model_atomic, gpt_model_type, dlg, 'dialogue')\n",
    "        # print(atomic_facts)\n",
    "        atomic_facts = nltk.sent_tokenize(atomic_facts)\n",
    "        atomic_facts = [re.sub('[0-9]', '', each) for each in atomic_facts]\n",
    "        atomic_facts = [each.strip(string.punctuation).strip() for each in atomic_facts]\n",
    "        atomic_facts = [each for each in atomic_facts if each]\n",
    "        return atomic_facts \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90f92f20-b2b8-4172-8f90-4066b0c1bba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Model</th>\n",
       "      <th>Summary</th>\n",
       "      <th>origin</th>\n",
       "      <th>Annotations</th>\n",
       "      <th>Reference_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Natacha: hi, i can come and pick you up at the...</td>\n",
       "      <td>gpt3_finetune</td>\n",
       "      <td>Charles will probably arrive at the train stat...</td>\n",
       "      <td>SAMSum</td>\n",
       "      <td>{'Charles will probably arrive at the train st...</td>\n",
       "      <td>Charles has just landed and he will be at RER ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Dialogue  \\\n",
       "0           0  Natacha: hi, i can come and pick you up at the...   \n",
       "\n",
       "           Model                                            Summary  origin  \\\n",
       "0  gpt3_finetune  Charles will probably arrive at the train stat...  SAMSum   \n",
       "\n",
       "                                         Annotations  \\\n",
       "0  {'Charles will probably arrive at the train st...   \n",
       "\n",
       "                                   Reference_Summary  \n",
       "0  Charles has just landed and he will be at RER ...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_finegrained_aggrefact.csv')\n",
    "df.head()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75cea94d-af75-42d5-85f3-f1fbcf0d0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[[13]]\n",
    "dialogue = row['Dialogue'].values[0]\n",
    "summary = row['Summary'].values[0]\n",
    "annotations = eval(row['Annotations'].values[0])\n",
    "\n",
    "synthetic_gen = SyntheticPrompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ada6d6f5-6ed4-4f7f-b936-3a0122478791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert the dialogue into facts without adding any unsupported details.\n",
      "Dialogue: Alan: <file_photo>\n",
      "Alan: look what I just found :)\n",
      "Robert: dude, that's just nasty and you know it :)\n",
      "Robert: it has no sugar, no taste, and additional cinnamon flavoring\n",
      "Alan: yeah, I know - that's awesome :)\n",
      "Robert: you sir have a very strange tastes :P\n",
      "Alan: well, and I found a perfect company for it <file_photo>\n",
      "Robert: oh, that's more like it!\n",
      "Robert: but does the whiskey go well with the cinnamon? flavored whiskey is the worst...\n",
      "Alan: Actually it does taste surprisingly well. The cinnamon is not overpowering. If you put enough whiskey that is :)\n",
      "Rob: Lol, thought so :)\n",
      "Rob: I just wish the brought the old cherry flavor back...\n",
      "Rob: not the useless no-sugar stuff\n",
      "Alan: Ah, that is true :)\n"
     ]
    }
   ],
   "source": [
    "gpt_model_type = 'gpt-4-32k-0613'\n",
    "atomic_facts = synthetic_gen.get_atomic_facts(gpt_model_type, dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67242f28-76c8-4a3b-80a8-57950a932be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan found something which he seemed excited about',\n",
       " \"Robert thought that Alan's finding was unappealing and explicitly mentioned it had no sugar, no taste, and an additional cinnamon flavor\",\n",
       " 'Alan admitted that he is aware of these attributes and finds them appealing',\n",
       " \"Robert commented on Alan's unique taste preference\",\n",
       " 'Alan found a whisky that he thinks goes well with the item he found',\n",
       " 'Robert questioned the compatibility of the whisky and cinnamon flavor and expressed his dislike for flavored whisky',\n",
       " 'Alan reassured Robert that the combination tasted good, with the cinnamon not being overpowering if enough whisky is used',\n",
       " 'Robert expressed his longing for the old cherry flavor and his dislike for no-sugar options',\n",
       " \"Alan agreed with Robert's sentiment about the old cherry flavor\"]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a0f6257-edd4-482f-a3ff-32182b3105f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subjobj': [('Alan found something which he seemed excited about',\n",
       "   '<BLANK> found something which he seemed excited about',\n",
       "   'Alan',\n",
       "   'subjobj'),\n",
       "  ('Alan found something which he seemed excited about',\n",
       "   'Alan found <BLANK> which he seemed excited about',\n",
       "   'something',\n",
       "   'subjobj'),\n",
       "  ('Alan found something which he seemed excited about',\n",
       "   'Alan found something <BLANK> he seemed excited about',\n",
       "   'which',\n",
       "   'subjobj'),\n",
       "  ('Alan found something which he seemed excited about',\n",
       "   'Alan found something which <BLANK> seemed excited about',\n",
       "   'he',\n",
       "   'subjobj')],\n",
       " 'predicate': [('Alan found something which he seemed excited about',\n",
       "   'Alan <BLANK> something which he seemed excited about',\n",
       "   'found',\n",
       "   'predicate'),\n",
       "  ('Alan found something which he seemed excited about',\n",
       "   'Alan found something which he <BLANK> excited about',\n",
       "   'seemed',\n",
       "   'predicate')],\n",
       " 'circumstance': [('Alan found something which he seemed excited about',\n",
       "   'Alan found something which he seemed excited <BLANK>',\n",
       "   'about',\n",
       "   'circumstance')]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_atomic_facts_map = synthetic_gen.make_masked_sentences(atomic_facts[:1])\n",
    "masked_atomic_facts_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f8270-62d5-4d6a-bca7-b1b97148830f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
