{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3178534e-1632-42fc-ad44-d87162e780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from experiments.models.GPTModel import GPTInference\n",
    "from tqdm import tqdm\n",
    "import re, string\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3352b6-ae0f-40b4-8794-40f623d7758d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm = pd.read_csv('/home/sanjana/factual_evaluation_source_based/annotations/round1_aggredialfact_annotated/dialoguefact_two_annotators_round1.csv')\n",
    "df_llm = df_llm[df_llm['user_id'] == 'ann_wjbp']\n",
    "df_sota = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_finegrained_aggrefact.csv')\n",
    "len(df_llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9db02a83-e2ae-4b80-8d4b-8e4394a6b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rashi, a student, expresses her confusion about choosing a career to her teacher. After a discussion, the teacher advises Rashi to follow her interests and passions, and not only focus on earning potential, while further suggesting that balance is key in any career. She suggests that Rashi should gain experience in her field of interest and then work to widen her scope with time, making it a blend of earning and learning. Rashi acknowledges the advice as helpful.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_idx = 5\n",
    "row = df_llm.iloc[[row_idx]]\n",
    "summ = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]\n",
    "nonfactual_span = row['nonfactual_spans'].values[0]\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2cdd8f1-fd57-46ec-9fe2-8d2a64b1263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not only focus on earning potential'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonfactual_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7bb160a7-7f9b-43db-beb8-f97ce442929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rashi, a student, expresses her confusion about choosing a career to her teacher.\n",
      "After a discussion, the teacher advises Rashi to follow her interests and passions, and not only focus on earning potential, while further suggesting that balance is key in any career.\n",
      "She suggests that Rashi should gain experience in her field of interest and then work to widen her scope with time, making it a blend of earning and learning.\n",
      "Rashi acknowledges the advice as helpful.\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def check_membership(token, compare_list):\n",
    "    for each in compare_list:\n",
    "        \n",
    "        if token == each:\n",
    "            return True\n",
    "    return False \n",
    "    \n",
    "def get_mask_infill(doc):\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    pos_tags = {\n",
    "        'noun': ['PROPN', 'NOUN'],\n",
    "        'verb': ['VERB'],\n",
    "        'adjective': ['ADJ'],\n",
    "        'adposition': ['ADP'],\n",
    "        'pronoun': ['PRON'],\n",
    "        'adverb': ['ADV']\n",
    "                    \n",
    "    }\n",
    "    \n",
    "    dep_tags = {\n",
    "        'subjobj': ['nsubj', 'dobj', 'pobj'], \n",
    "        'negation': ['neg'],\n",
    "        'preposition': ['prep'],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tags = {\n",
    "        'verb': ['VBZ', 'VBG', 'VB'],\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        # print(token.tag_, check_membership(token.tag_, tags['verb']))\n",
    "        \n",
    "        if check_membership(token.dep_, dep_tags['subjobj']) and check_membership(token.pos_, pos_tags['noun']):\n",
    "            # print('SUBJOBJ')\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "        elif check_membership(token.pos_, pos_tags['adjective']):\n",
    "            append = True\n",
    "            token_type = 'attr'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.tag_, tags['verb']) or check_membership(token.pos_, pos_tags['verb']):\n",
    "            append = True\n",
    "            token_type = 'pred'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "        elif check_membership(token.dep_, dep_tags['negation']):\n",
    "            append = True\n",
    "            token_type = 'neg'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.pos_, pos_tags['pronoun']):\n",
    "            append = True\n",
    "            token_type = 'coref'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.dep_, dep_tags['preposition']) or \\\n",
    "        check_membership(token.pos_, pos_tags['adverb']) :\n",
    "            append = True\n",
    "            token_type = 'circ'\n",
    "        \n",
    "        if append:\n",
    "                mask_idx.append(idx)\n",
    "                mask_tokens.append((idx, token.text, token_type))\n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "            if err_type not in error_types_indices_map:\n",
    "                error_types_indices_map[err_type] = []\n",
    "            error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "            for idx in err_indices:\n",
    "                masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "                masked_text = ' '.join(masked_text)\n",
    "                all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results\n",
    "\n",
    "\n",
    "summ_doc =nlp(summ)\n",
    "summ_sent_mask_infill = []\n",
    "for summ_sent in summ_doc.sents:\n",
    "    print(summ_sent)\n",
    "    summ_sent = summ_sent.text\n",
    "    doc = nlp(summ_sent)\n",
    "    origin_tokens = [token for token in doc]\n",
    "    summ_sent_mask_infill.append(get_mask_infill(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5020f0f3-b507-4cec-89c0-24176007c26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BLANK> a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'After',\n",
       "  'circ'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not <BLANK> focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'only',\n",
       "  'circ'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus <BLANK> earning potential , while further suggesting that balance is key in any career .',\n",
       "  'on',\n",
       "  'circ'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while <BLANK> suggesting that balance is key in any career .',\n",
       "  'further',\n",
       "  'circ'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key <BLANK> any career .',\n",
       "  'in',\n",
       "  'circ'),\n",
       " ('After a <BLANK> , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'discussion',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the <BLANK> advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'teacher',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher advises <BLANK> to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'Rashi',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her <BLANK> and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'interests',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning <BLANK> , while further suggesting that balance is key in any career .',\n",
       "  'potential',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that <BLANK> is key in any career .',\n",
       "  'balance',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any <BLANK> .',\n",
       "  'career',\n",
       "  'subjobj'),\n",
       " ('After a discussion , the teacher <BLANK> Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'advises',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to <BLANK> her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'follow',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only <BLANK> on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'focus',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on <BLANK> potential , while further suggesting that balance is key in any career .',\n",
       "  'earning',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further <BLANK> that balance is key in any career .',\n",
       "  'suggesting',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance <BLANK> key in any career .',\n",
       "  'is',\n",
       "  'pred'),\n",
       " ('After a discussion , the teacher advises Rashi to follow <BLANK> interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career .',\n",
       "  'her',\n",
       "  'coref'),\n",
       " ('After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is <BLANK> in any career .',\n",
       "  'key',\n",
       "  'attr')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_sent_mask_infill[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "10cd30d3-a202-4516-9f06-b0620e17720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string \n",
    "\n",
    "def get_atomic_facts_gpt( text, text_type):\n",
    "    instr = f'Write the {text_type} into indirect speech without introducing any unsupported information or inferences'\n",
    "    prompt = f'{instr}\\nDialogue: {text}'\n",
    "    # print(prompt)\n",
    "    gpt_response = GPTInference().get_chatgpt_response(prompt)\n",
    "    # print(nltk.sent_tokenize(gpt_response))\n",
    "    return gpt_response\n",
    "    \n",
    "def get_atomic_facts( dlg):\n",
    "        atomic_facts = get_atomic_facts_gpt( dlg, 'dialogue')\n",
    "        atomic_facts = nltk.sent_tokenize(atomic_facts)\n",
    "        atomic_facts = [re.sub('[1-9]', '', each) for each in atomic_facts]\n",
    "        atomic_facts = [each.strip(string.punctuation).strip() for each in atomic_facts]\n",
    "        return atomic_facts\n",
    "    \n",
    "def get_nonfactual_comparators(all_masked_results):\n",
    "    atomic_facts = ' '.join(get_atomic_facts(dlg))\n",
    "    instruction = '''\n",
    "    List the most appropriate answer that can fill in the <BLANK> in the sentence by extracting from the source. Ensure the sentence is consistent with source.\n",
    "    If there are no appropriate answers reply \"None\"'''\n",
    "    answers = []\n",
    "    nonfactual_sent_span = []\n",
    "    for sentence, answer, err_type in all_masked_results:   \n",
    "        prompt = f'{instruction}\\nSource: {atomic_facts}\\nSentence: {sentence}'\n",
    "        response = GPTInference().get_chatgpt_response(prompt)\n",
    "        \n",
    "        if \"None\" in response:\n",
    "            response = [response]\n",
    "        elif len(response.split('\\n')) > 1:\n",
    "            response = response.split('\\n')\n",
    "        elif len(response.split(',')) > 1:\n",
    "            response = response.split(',')\n",
    "        else:\n",
    "            response = [response]\n",
    "        response = [re.sub('[1-9]', '', each) for each in response]\n",
    "        response = [each.strip(string.punctuation).strip() for each in response]\n",
    "        \n",
    "        if not check_membership(answer, response):\n",
    "            print(sentence, answer, response)\n",
    "            print('===')\n",
    "        answers += [response]\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c09f0e-963c-404c-9c3b-a9c52b735952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "42e54df9-927d-427d-9aa4-2e6ad2c79346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not <BLANK> focus on earning potential , while further suggesting that balance is key in any career . only ['solely']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus <BLANK> earning potential , while further suggesting that balance is key in any career . on ['on her']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while <BLANK> suggesting that balance is key in any career . further ['also']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key <BLANK> any career . in ['in choosing']\n",
      "===\n",
      "After a <BLANK> , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career . discussion ['discussion about her confusion regarding her career options']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that <BLANK> is key in any career . balance [\"passion for one's work and balancing duties and success at some point in life\"]\n",
      "===\n",
      "After a discussion , the teacher <BLANK> Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career . advises ['advised']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to <BLANK> her interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career . follow ['base her decision on']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on <BLANK> potential , while further suggesting that balance is key in any career . earning ['earnings']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow <BLANK> interests and passions , and not only focus on earning potential , while further suggesting that balance is key in any career . her ['her own']\n",
      "===\n",
      "After a discussion , the teacher advises Rashi to follow her interests and passions , and not only focus on earning potential , while further suggesting that balance is <BLANK> in any career . key ['important']\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "for mask_infill in [summ_sent_mask_infill[1]]:\n",
    "    get_nonfactual_comparators(mask_infill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d830c7e-8422-4aac-b81d-770435216312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f7fd62ab-b27e-4c44-8bd9-a72d8057343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_facts = ' '.join(get_atomic_facts(dlg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bdf7a5b0-1930-4383-9516-9a72a900ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The teacher noticed that Rashi seemed to be a bit down and asked her why Rashi admitted that she was feeling confused about her career When the teacher asked for clarification, Rashi explained that she\\'d been discussing career options with her friends, but there were too many options to choose from Encouragingly, the teacher advised Rashi to base her career choice on what truly interested her Rashi confessed that she had multiple interests and didn\\'t understand how they would determine her career The teacher explained that it was Rashi\\'s passion that would lead her to success When Rashi questioned the factor of earnings, the teacher reminded her that at some point, everyone must learn to balance their duties and success Wondering how to achieve that, Rashi questioned further The teacher advised her to choose a career that interested her, to gain experience in that field and try to progress and expand her scope over time Arguing that it was like an \"earn and learn\" sort of thing, the teacher guided Rashi further Upon realization, Rashi agreed with the teacher\\'s guidance and promised to remember it Feeling relieved, the teacher asked Rashi if she was satisfied with the answers to her questions With a heartful gratitude, Rashi confirmed and thanked the teacher, who responded warmly that she was most welcome'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18c15a81-ece4-43d2-8946-0b9fb641abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>docid</th>\n",
       "      <th>model</th>\n",
       "      <th>nonfactual_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>02f228f5-435e-4906-bb98-1452bd51d708</td>\n",
       "      <td>ann_wjbp</td>\n",
       "      <td>13611508</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>the products</td>\n",
       "      <td>I'll check them</td>\n",
       "      <td>Extrinsic_Error</td>\n",
       "      <td>Martha, seeing Ophelia''s profile picture, is ...</td>\n",
       "      <td>Martha: Hey, can I ask you a question?\\r\\nOphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid   user_id     docid  \\\n",
       "9           9  02f228f5-435e-4906-bb98-1452bd51d708  ann_wjbp  13611508   \n",
       "\n",
       "           model nonfactual_spans         evidence       error_type  \\\n",
       "9  gpt4-32k-0613     the products  I'll check them  Extrinsic_Error   \n",
       "\n",
       "                                             summary  \\\n",
       "9  Martha, seeing Ophelia''s profile picture, is ...   \n",
       "\n",
       "                                            dialogue  \n",
       "9  Martha: Hey, can I ask you a question?\\r\\nOphe...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f0985-039d-4905-9f1f-3c6de696990c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4483f8e5ab457aa1000c45755a63b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)lve/main/config.json', max=1048.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ffed9e5c0247b3ab9c52c3317553dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)model.bin.index.json', max=16924.0, style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2537258c492e48a383a6cb8b29fcd059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading shards', max=2.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5292ab4fcf48a2b330df248f516002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)l-00001-of-00002.bin', max=9951028193.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c25dc0a450423e905fe8cf2ab68d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading (…)l-00002-of-00002.bin', max=4483421659.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, FalconForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\")\n",
    "model = FalconForCausalLM.from_pretrained(\"tiiuae/falcon-7b\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5a4bf2-71a7-4aaa-a880-8b6f368e4846",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': Can't extract `str` to `Vec`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/eval_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3698\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3675\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3676\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3679\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3680\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3682\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3683\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3696\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   3699\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m   3700\u001b[0m             seq,\n\u001b[1;32m   3701\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3702\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3703\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3704\u001b[0m         )\n\u001b[1;32m   3705\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3706\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/envs/eval_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3699\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3675\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3676\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3679\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3680\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3682\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3683\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3696\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3705\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3706\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/envs/eval_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3738\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3735\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3736\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3742\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3743\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/eval_env/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:625\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    624\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 625\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    628\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': Can't extract `str` to `Vec`"
     ]
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c8712-a30b-465e-8b21-c053125c9944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
