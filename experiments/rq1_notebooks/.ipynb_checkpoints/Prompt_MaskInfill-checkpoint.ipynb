{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3178534e-1632-42fc-ad44-d87162e780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from experiments.models.GPTModel import GPTInference\n",
    "from tqdm import tqdm\n",
    "import re, string\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3352b6-ae0f-40b4-8794-40f623d7758d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm = pd.read_csv('/home/sanjana/factual_evaluation_source_based/annotations/round1_aggredialfact_annotated/dialoguefact_two_annotators_round1.csv')\n",
    "df_llm = df_llm[df_llm['user_id'] == 'ann_wjbp']\n",
    "df_sota = pd.read_csv('/home/sanjana/factual_evaluation_source_based/datasets/sota_annotations/dialogue_finegrained_aggrefact.csv')\n",
    "len(df_llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9db02a83-e2ae-4b80-8d4b-8e4394a6b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Martha, seeing Ophelia''s profile picture, is intrigued by her lenses and queries about where she got them from. Ophelia reveals they''re from Crazy Lenses, mentioning their cost-effectiveness and swift delivery. Martha expresses gratitude and intends to check out the products.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_idx = 3\n",
    "row = df_llm.iloc[[row_idx]]\n",
    "summ = row['summary'].values[0]\n",
    "dlg = row['dialogue'].values[0]\n",
    "nonfactual_span = row['nonfactual_spans'].values[0]\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bb160a7-7f9b-43db-beb8-f97ce442929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Martha, seeing Ophelia''s profile picture, is intrigued by her lenses and queries about where she got them from. Ophelia reveals they''re from Crazy Lenses, mentioning their cost-effectiveness and swift delivery. Martha expresses gratitude and intends to check out the products.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def check_membership(token, compare_list):\n",
    "    for each in compare_list:\n",
    "        if token in each.split():\n",
    "            return True\n",
    "    return False \n",
    "    \n",
    "def get_mask_infill(doc):\n",
    "    all_masked_results = []\n",
    "    mask_idx = []\n",
    "    mask_tokens = []\n",
    "    pos_tags = {\n",
    "        'noun': ['PROPN', 'NOUN'],\n",
    "        'verb': ['VERB'],\n",
    "        'adjective': ['ADJ'],\n",
    "        'adposition': ['ADP'],\n",
    "        'pronoun': ['PRON'],\n",
    "        'adverb': ['ADV']\n",
    "                    \n",
    "    }\n",
    "    \n",
    "    dep_tags = {\n",
    "        'subjobj': ['nsubj', 'dobj', 'pobj'], \n",
    "        'negation': ['neg'],\n",
    "        'preposition': ['prep'],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tags = {\n",
    "        'verb': ['VBZ', 'VBG', 'VB'],\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    for idx, token in enumerate(doc):\n",
    "        append = False\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "        if check_membership(token.dep_, dep_tags['subjobj']) and check_membership(token.pos_, pos_tags['noun']):\n",
    "            # print('SUBJOBJ')\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            append = True\n",
    "            token_type = 'subjobj'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "        elif check_membership(token.pos_, pos_tags['adjective']):\n",
    "            append = True\n",
    "            token_type = 'attr'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.tag_, tags['verb']) or check_membership(token.pos_, pos_tags['verb']):\n",
    "            append = True\n",
    "            token_type = 'pred'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "        elif check_membership(token.dep_, dep_tags['negation']):\n",
    "            append = True\n",
    "            token_type = 'neg'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.pos_, pos_tags['pronoun']):\n",
    "            append = True\n",
    "            token_type = 'coref'\n",
    "            # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "            \n",
    "        elif check_membership(token.dep_, dep_tags['preposition']) or \\\n",
    "        check_membership(token.pos_, pos_tags['adverb']) or \\\n",
    "        check_membership(token.pos_, pos_tags['adposition']):\n",
    "            append = True\n",
    "            token_type = 'circ'\n",
    "        \n",
    "        if append:\n",
    "                mask_idx.append(idx)\n",
    "                mask_tokens.append((idx, token.text, token_type))\n",
    "\n",
    "    error_types_indices_map = {}\n",
    "    for token_idx, token_text, err_type in mask_tokens:\n",
    "            if err_type not in error_types_indices_map:\n",
    "                error_types_indices_map[err_type] = []\n",
    "            error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "    for err_type, err_indices in error_types_indices_map.items():\n",
    "            for idx in err_indices:\n",
    "                masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "                masked_text = ' '.join(masked_text)\n",
    "                all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "    return all_masked_results\n",
    "\n",
    "\n",
    "summ_doc =nlp(summ)\n",
    "\n",
    "for summ_sent in summ_doc.sents:\n",
    "    summ_sent = summ_sent.text\n",
    "    doc = nlp(text)\n",
    "    origin_tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10cd30d3-a202-4516-9f06-b0620e17720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "summ_doc =nlp(summ)\n",
    "\n",
    "sents = [sent.text for sent in summ_doc.sents]\n",
    "\n",
    "text = sents[1]\n",
    "doc = nlp(text)\n",
    "origin_tokens = [token for token in doc]\n",
    "\n",
    "def check_membership(token, compare_list):\n",
    "    for each in compare_list:\n",
    "        if token in each.split():\n",
    "            return True\n",
    "    return False \n",
    "    \n",
    "# origin_tokens = [token for token in doc]\n",
    "all_masked_results = []\n",
    "mask_idx = []\n",
    "mask_tokens = []\n",
    "pos_tags = {\n",
    "    'noun': ['PROPN', 'NOUN'],\n",
    "    'verb': ['VERB'],\n",
    "    'adjective': ['ADJ'],\n",
    "    'adposition': ['ADP'],\n",
    "    'pronoun': ['PRON'],\n",
    "    'adverb': ['ADV']\n",
    "                \n",
    "}\n",
    "\n",
    "dep_tags = {\n",
    "    'subjobj': ['nsubj', 'dobj', 'pobj'], \n",
    "    'negation': ['neg'],\n",
    "    'preposition': ['prep'],\n",
    "    \n",
    "}\n",
    "\n",
    "tags = {\n",
    "    'verb': ['VBZ', 'VBG', 'VB'],\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for idx, token in enumerate(doc):\n",
    "    append = False\n",
    "    # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    \n",
    "    if check_membership(token.dep_, dep_tags['subjobj']) and check_membership(token.pos_, pos_tags['noun']):\n",
    "        # print('SUBJOBJ')\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        append = True\n",
    "        token_type = 'subjobj'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "\n",
    "    elif check_membership(token.pos_, pos_tags['adjective']):\n",
    "        append = True\n",
    "        token_type = 'attr'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.tag_, tags['verb']) or check_membership(token.pos_, pos_tags['verb']):\n",
    "        append = True\n",
    "        token_type = 'pred'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "\n",
    "    elif check_membership(token.dep_, dep_tags['negation']):\n",
    "        append = True\n",
    "        token_type = 'neg'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.pos_, pos_tags['pronoun']):\n",
    "        append = True\n",
    "        token_type = 'coref'\n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "        \n",
    "    elif check_membership(token.dep_, dep_tags['preposition']) or \\\n",
    "    check_membership(token.pos_, pos_tags['adverb']) or \\\n",
    "    check_membership(token.pos_, pos_tags['adposition']):\n",
    "        append = True\n",
    "        token_type = 'circ'\n",
    "        \n",
    "        # print(token.text, token.pos_, token.dep_ , token.tag_)\n",
    "    if append:\n",
    "            mask_idx.append(idx)\n",
    "            mask_tokens.append((idx, token.text, token_type))\n",
    "\n",
    "error_types_indices_map = {}\n",
    "for token_idx, token_text, err_type in mask_tokens:\n",
    "        if err_type not in error_types_indices_map:\n",
    "            error_types_indices_map[err_type] = []\n",
    "        error_types_indices_map[err_type] += [token_idx]\n",
    "        \n",
    "for err_type, err_indices in error_types_indices_map.items():\n",
    "        for idx in err_indices:\n",
    "            masked_text = [each.text for each in origin_tokens[:idx]] + ['<BLANK>'] + [each.text for each in origin_tokens[idx+1:]]\n",
    "            masked_text = ' '.join(masked_text)\n",
    "            all_masked_results.append((masked_text, origin_tokens[idx].text, err_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42e54df9-927d-427d-9aa4-2e6ad2c79346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martha: Hey, can I ask you a question?\n",
      "Ophelia: Do we know each other?\n",
      "Martha: We don''t, but do you mind if I ask you about the lenses from your profile picture? they are awesome and I would like to buy the similar ones\n",
      "Ophelia: it''s from Crazy Lenses. They have quite reasonable prices and very fast shipping.\n",
      "Martha: Thanks!!! I''ll check them :)\n",
      "Ophelia: No problem :)\n"
     ]
    }
   ],
   "source": [
    "print(dlg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d830c7e-8422-4aac-b81d-770435216312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7fd62ab-b27e-4c44-8bd9-a72d8057343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martha , <BLANK> Ophelia ' 's profile picture , is intrigued by her lenses and queries about where she got them from . seeing ['who saw', 'after looking at', 'upon noticing']\n",
      "Martha , seeing Ophelia ' 's profile picture , <BLANK> intrigued by her lenses and queries about where she got them from . is ['was', 'became', 'got']\n",
      "Martha , seeing Ophelia ' 's profile picture , is <BLANK> by her lenses and queries about where she got them from . intrigued ['impressed', 'intrigued', 'attracted']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries about where she <BLANK> them from . got ['bought', 'got', 'purchased']\n",
      "Martha , seeing Ophelia ' 's profile <BLANK> , is intrigued by her lenses and queries about where she got them from . picture ['picture', 'photo', 'image']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her <BLANK> and queries about where she got them from . lenses ['lenses', 'eyewear', 'glasses']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued <BLANK> her lenses and queries about where she got them from . by ['by', 'with', 'about']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries <BLANK> where she got them from . about ['Ophelia', 'her', 'the woman in the profile picture']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries about <BLANK> she got them from . where ['where', 'the place', 'which store']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries about where she got them <BLANK> . from ['from Crazy Lenses', 'from a company called Crazy Lenses', 'at a store known as Crazy Lenses']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by <BLANK> lenses and queries about where she got them from . her [\"Ophelia's\", 'the unique', 'the awesome']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries about where <BLANK> got them from . she ['Ophelia', 'she', 'Ophelia, the woman in the profile picture']\n",
      "Martha , seeing Ophelia ' 's profile picture , is intrigued by her lenses and queries about where she got <BLANK> from . them ['them', 'the lenses', 'her lenses']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string \n",
    "\n",
    "instruction = '''\n",
    "List the 3 most appropriate answer that can fill in the <BLANK> in the sentence based on information extracted from the dialogue snippet. Ensure the sentence is consistent with dialogue.\n",
    "If there are no appropriate answers reply \"None\"'''\n",
    "answers = []\n",
    "nonfactual_sent_span = []\n",
    "for sentence, answer, err_type in all_masked_results:   \n",
    "    prompt = f'{instruction}\\nSource: {dlg}\\nSentence: {sentence}'\n",
    "    response = GPTInference().get_chatgpt_response(prompt)\n",
    "    if \"None\" in response:\n",
    "        response = [response]\n",
    "    elif len(response.split('\\n')) > 1:\n",
    "        response = response.split('\\n')\n",
    "    elif len(response.split(',')) > 1:\n",
    "        response = response.split(',')\n",
    "        \n",
    "    response = [re.sub('[1-9]', '', each) for each in response]\n",
    "    response = [each.strip(string.punctuation).strip() for each in response]\n",
    "    # if not check_membership(answer, response):\n",
    "    print(sentence, answer, response)\n",
    "    answers += [response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdf7a5b0-1930-4383-9516-9a72a900ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Martha, seeing Ophelia''s profile picture, is intrigued by her lenses and queries about where she got them from. Ophelia reveals they''re from Crazy Lenses, mentioning their cost-effectiveness and swift delivery. Martha expresses gratitude and intends to check out the products.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18c15a81-ece4-43d2-8946-0b9fb641abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>docid</th>\n",
       "      <th>model</th>\n",
       "      <th>nonfactual_spans</th>\n",
       "      <th>evidence</th>\n",
       "      <th>error_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>02f228f5-435e-4906-bb98-1452bd51d708</td>\n",
       "      <td>ann_wjbp</td>\n",
       "      <td>13611508</td>\n",
       "      <td>gpt4-32k-0613</td>\n",
       "      <td>the products</td>\n",
       "      <td>I'll check them</td>\n",
       "      <td>Extrinsic_Error</td>\n",
       "      <td>Martha, seeing Ophelia''s profile picture, is ...</td>\n",
       "      <td>Martha: Hey, can I ask you a question?\\r\\nOphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  uuid   user_id     docid  \\\n",
       "9           9  02f228f5-435e-4906-bb98-1452bd51d708  ann_wjbp  13611508   \n",
       "\n",
       "           model nonfactual_spans         evidence       error_type  \\\n",
       "9  gpt4-32k-0613     the products  I'll check them  Extrinsic_Error   \n",
       "\n",
       "                                             summary  \\\n",
       "9  Martha, seeing Ophelia''s profile picture, is ...   \n",
       "\n",
       "                                            dialogue  \n",
       "9  Martha: Hey, can I ask you a question?\\r\\nOphe...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f0985-039d-4905-9f1f-3c6de696990c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eval_env)",
   "language": "python",
   "name": "eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
